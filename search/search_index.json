{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":true,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Data Controller Documentation \u00b6 Overview \u00b6 The Data Controller for SAS\u00ae enables users to self serve their data changes, and for data owners to retain control over those updates by reviewing and approving them. Online resources \u00b6 The following resources contain additional information on the Data Controller: DC Overview Presentation Data Controller LinkedIn page Data Controller website Data Controller flyer ( front / back ) Data Controller videos Data Controller SAS Code Data Controller Download Product Features \u00b6 Data Controller is regularly updated with new features. If you see something that is not listed, and we agree it would be useful, you can engage us with Developer Days to build the feature in. Excel uploads - drag & drop directly into SAS. All versions of excel supported. Data Lineage - at both table and column level, export as image or CSV Data Validation Rules - both automatic and user defined Data Dictionary - map data definitions and ownership Data Catalog - including primary key extraction DDL generator - in SAS, TSQL and PGSQL flavours Workflow - run a SAS program before or after an edit or approval Role based security - editors, approvers, administrators Data Models supported: SCD2, Bitemporal, composite keys, retained keys, update and full replace Email Alerts for data changes Row Level Security Excel formula support Dynamic cell dropdown Works on ALL flavours of SAS (Foundation, EBI, Viya)","title":"Home"},{"location":"#data-controller-documentation","text":"","title":"Data Controller Documentation"},{"location":"#overview","text":"The Data Controller for SAS\u00ae enables users to self serve their data changes, and for data owners to retain control over those updates by reviewing and approving them.","title":"Overview"},{"location":"#online-resources","text":"The following resources contain additional information on the Data Controller: DC Overview Presentation Data Controller LinkedIn page Data Controller website Data Controller flyer ( front / back ) Data Controller videos Data Controller SAS Code Data Controller Download","title":"Online resources"},{"location":"#product-features","text":"Data Controller is regularly updated with new features. If you see something that is not listed, and we agree it would be useful, you can engage us with Developer Days to build the feature in. Excel uploads - drag & drop directly into SAS. All versions of excel supported. Data Lineage - at both table and column level, export as image or CSV Data Validation Rules - both automatic and user defined Data Dictionary - map data definitions and ownership Data Catalog - including primary key extraction DDL generator - in SAS, TSQL and PGSQL flavours Workflow - run a SAS program before or after an edit or approval Role based security - editors, approvers, administrators Data Models supported: SCD2, Bitemporal, composite keys, retained keys, update and full replace Email Alerts for data changes Row Level Security Excel formula support Dynamic cell dropdown Works on ALL flavours of SAS (Foundation, EBI, Viya)","title":"Product Features"},{"location":"admin-services/","text":"Admin Services \u00b6 Several web services have been defined to provide additional functionality outside of the user interface. These somewhat-hidden services must be called directly, using a web browser. In a future version, these features will be made available from an Admin screen (so, no need to manually modify URLs). The URL is made up of several components: SERVERURL -> the domain (and port) on which your SAS server resides EXECUTOR -> Either SASStoredProcess for SAS 9, else SASJobExecution for Viya APPLOC -> The root folder location in which the Data Controller backend services were deployed SERVICE -> The actual Data Controller service being described. May include additional parameters. To illustrate the above, consider the following URL: https://viya.4gl.io/SASJobExecution/?_program=/Public/app/viya/services/admin/exportdb&flavour=PGSQL This is broken down into: $SERVERURL = https://sas.analytium.co.uk $EXECUTOR = SASJobExecution $APPLOC = /Public/app/dc $SERVICE = services/admin/exportdb&flavour=PGSQL The below sections will only describe the $SERVICE component - you may construct this into a URL as follows: $SERVERURL/$EXECUTOR?_program=$APPLOC/$SERVICE Export Config \u00b6 This service will provide a zip file containing the current database configuration. This is useful for migrating to a different data controller database instance. EXAMPLE: services/admin/exportconfig Export Database \u00b6 Exports the data controller control library in DB specific DDL. The following URL parameters may be added: &flavour= (only PGSQL supported at this time) &schema= (optional, if target schema is needed) EXAMPLES: services/admin/exportdb&flavour=PGSQL&schema=DC services/admin/exportdb&flavour=PGSQL Refresh Data Catalog \u00b6 In any SAS estate, it's unlikely the size & shape of data will remain static. By running a regular Catalog Scan, you can track changes such as: Library Properties (size, schema, path, number of tables) Table Properties (size, number of columns, primary keys) Variable Properties (presence in a primary key, constraints, position in the dataset) The data is stored with SCD2 so you can actually track changes to your model over time ! Curious when that new column appeared? Just check the history in MPE_DATACATALOG_TABS . To run the refresh process, just trigger the stored process, eg below: services/admin/refreshcatalog services/admin/refreshcatalog&libref=MYLIB The optional &libref= parameter allows you to run the process for a single library. Just provide the libref. When doing a full scan, the following LIBREFS are ignored: 'CASUSER' 'MAPSGFK' 'SASUSER' 'SASWORK 'STPSAMP' 'TEMP' `WORK' Additional LIBREFs can be excluded by adding them to the DCXXXX.MPE_CONFIG table (where var_scope='DC_CATALOG' and var_name='DC_IGNORELIBS' ). Use a pipe ( | ) symbol to seperate them. This can be useful where there are connection issues for a particular library. Be aware that the scan process can take a long time if you have a lot of tables! Output tables (all SCD2): MPE_DATACATALOG_LIBS - Library attributes MPE_DATACATALOG_TABS - Table attributes MPE_DATACATALOG_VARS - Column attributes MPE_DATASTATUS_LIBS - Frequently changing library attributes (such as size & number of tables) MPE_DATASTATUS_TABS - Frequently changing table attributes (such as size & number of rows) Update Licence Key \u00b6 Whenever navigating Data Controller, there is always a hash ( # ) in the URL. To access the licence key screen, remove all content to the RIGHT of the hash and add the following string: /licensing/update . If you are using https protocol, you will have 2 keys (licence key / activation key). In http mode, there is just one key (licence key) for both boxes.","title":"Admin Services"},{"location":"admin-services/#admin-services","text":"Several web services have been defined to provide additional functionality outside of the user interface. These somewhat-hidden services must be called directly, using a web browser. In a future version, these features will be made available from an Admin screen (so, no need to manually modify URLs). The URL is made up of several components: SERVERURL -> the domain (and port) on which your SAS server resides EXECUTOR -> Either SASStoredProcess for SAS 9, else SASJobExecution for Viya APPLOC -> The root folder location in which the Data Controller backend services were deployed SERVICE -> The actual Data Controller service being described. May include additional parameters. To illustrate the above, consider the following URL: https://viya.4gl.io/SASJobExecution/?_program=/Public/app/viya/services/admin/exportdb&flavour=PGSQL This is broken down into: $SERVERURL = https://sas.analytium.co.uk $EXECUTOR = SASJobExecution $APPLOC = /Public/app/dc $SERVICE = services/admin/exportdb&flavour=PGSQL The below sections will only describe the $SERVICE component - you may construct this into a URL as follows: $SERVERURL/$EXECUTOR?_program=$APPLOC/$SERVICE","title":"Admin Services"},{"location":"admin-services/#export-config","text":"This service will provide a zip file containing the current database configuration. This is useful for migrating to a different data controller database instance. EXAMPLE: services/admin/exportconfig","title":"Export Config"},{"location":"admin-services/#export-database","text":"Exports the data controller control library in DB specific DDL. The following URL parameters may be added: &flavour= (only PGSQL supported at this time) &schema= (optional, if target schema is needed) EXAMPLES: services/admin/exportdb&flavour=PGSQL&schema=DC services/admin/exportdb&flavour=PGSQL","title":"Export Database"},{"location":"admin-services/#refresh-data-catalog","text":"In any SAS estate, it's unlikely the size & shape of data will remain static. By running a regular Catalog Scan, you can track changes such as: Library Properties (size, schema, path, number of tables) Table Properties (size, number of columns, primary keys) Variable Properties (presence in a primary key, constraints, position in the dataset) The data is stored with SCD2 so you can actually track changes to your model over time ! Curious when that new column appeared? Just check the history in MPE_DATACATALOG_TABS . To run the refresh process, just trigger the stored process, eg below: services/admin/refreshcatalog services/admin/refreshcatalog&libref=MYLIB The optional &libref= parameter allows you to run the process for a single library. Just provide the libref. When doing a full scan, the following LIBREFS are ignored: 'CASUSER' 'MAPSGFK' 'SASUSER' 'SASWORK 'STPSAMP' 'TEMP' `WORK' Additional LIBREFs can be excluded by adding them to the DCXXXX.MPE_CONFIG table (where var_scope='DC_CATALOG' and var_name='DC_IGNORELIBS' ). Use a pipe ( | ) symbol to seperate them. This can be useful where there are connection issues for a particular library. Be aware that the scan process can take a long time if you have a lot of tables! Output tables (all SCD2): MPE_DATACATALOG_LIBS - Library attributes MPE_DATACATALOG_TABS - Table attributes MPE_DATACATALOG_VARS - Column attributes MPE_DATASTATUS_LIBS - Frequently changing library attributes (such as size & number of tables) MPE_DATASTATUS_TABS - Frequently changing table attributes (such as size & number of rows)","title":"Refresh Data Catalog"},{"location":"admin-services/#update-licence-key","text":"Whenever navigating Data Controller, there is always a hash ( # ) in the URL. To access the licence key screen, remove all content to the RIGHT of the hash and add the following string: /licensing/update . If you are using https protocol, you will have 2 keys (licence key / activation key). In http mode, there is just one key (licence key) for both boxes.","title":"Update Licence Key"},{"location":"api/","text":"Warning Work in Progress! API \u00b6 Where a project has a requirement to load Excel Files automatically into SAS, from a remote machine, an API approach is desirable for many reasons: Security. Client access can be limited to just the endpoints they need (rather than being granted full server access). Flexibility. Well documented, stable APIs allow consumers to build and extend additional products and solutions. Cost. API solutions are typically self-contained, quick to implement, and easy to learn. A Data Controller API would enable teams across an entire enterprise to easily and securely send data to SAS in a transparent and fully automated fashion. The API would also benefit from all of Data Controllers existing data validation logic (both frontend and backend), data auditing, alerts , and security control features. It is however, a significant departure from the existing \"SAS Content\" based deployment, in the following ways: Server Driven. A machine is required on which to launch, and run, the API application itself. Fully Automated. There is no browser, or interface, or - human, involved. Extends outside of SAS. There are firewalls, and authentication methods, to consider. The Data Controller technical solution will differ, depending on the type of SAS Platform being used. There are three types of SAS Platform: Foundation SAS - regular, Base SAS. SAS EBI - with Metadata. SAS Viya - cloud enabled. And there are three main options when it comes to building APIs on SAS: Standalone DC API (Viya Only). Viya comes with REST APIs out of the box, no middleware needed. SAS 9 API . This is an open-source Java Application, using SAS Authentication. SASjs Server . An open source NodeJS application, compatible with all major authentication methods and all versions of SAS An additional REST API option for SAS EBI might have been BI Web Services , however - it requires platform changes and is not highly secure. The compatibility matrix is therefore as follows: Product Foundation SAS SAS EBI SAS VIYA DCAPI \u274c \u274c \u2705 DCAPI + SASjs Server \u2705 \u2705 \u2705 DCAPI + SAS 9 API \u274c \u2705 \u274c In all cases, a Data Controller API will be surfaced, that makes use of the underlying (raw) API server. The following sections break down these options, and the work remaining to make them a reality. Standalone DC API (Viya Only) \u00b6 For Viya, the investment necessary is relatively low, thanks to the API-first nature of the platform. In addition, the SASjs framework already provides most of the necessary functionality - such as authentication, service execution, handling results & logs, etc. Finally, the Data Controller team have already built an API Bridge (specific to another customer, hence the building blocks are in place). The work to complete the Viya version of the API is as follows: Authorisation interface Creation of API services Tests & Automated Deployments Developer docs Swagger API Public Documentation Cost to complete - \u00a35,000 (Viya Only) SASjs Server (Foundation SAS) \u00b6 SASjs Server already provides an API interface over Foundation SAS. An example of building a web app using SASjs Server can be found here . In order for it to fulfill the role as the engine behind the Data Controller API, additional work is needed - specifically: Secure (Enterprise) Authentication Users & Groups Feature configuration (ability to restrict features to different groups) On top of this, the DC API part would cover: Authorisation interface Creation of API services Tests & Automated Deployments Developer docs Swagger API Public Documentation Cost to complete - \u00a310,000 (fixed) Given that all three SAS platforms have Foundation SAS available, this option will work everywhere. The only restriction is that the sasjs/server instance must be located on the same server as SAS. ` SAS 9 API (SAS EBI) \u00b6 This product has one major benefit - there is nothing to install on the SAS Platform itself. It connects to SAS in much the same way as Enterprise Guide (using the SAS IOM). Website: https://sas9api.io Github: https://github.com/analytium/sas9api The downside is that the features needed by Data Controller are not present in the API. Furthermore, the tool is not under active development. To build out the necessary functionality, it will require us to source a senior Java developer on a short term contract to first, understand the tool, and secondly, to update it in a sustainable way. We estimate the cost to build Data Controller API on this mechanism at \u00a320,000 - but it could be higher.","title":"DC API"},{"location":"api/#api","text":"Where a project has a requirement to load Excel Files automatically into SAS, from a remote machine, an API approach is desirable for many reasons: Security. Client access can be limited to just the endpoints they need (rather than being granted full server access). Flexibility. Well documented, stable APIs allow consumers to build and extend additional products and solutions. Cost. API solutions are typically self-contained, quick to implement, and easy to learn. A Data Controller API would enable teams across an entire enterprise to easily and securely send data to SAS in a transparent and fully automated fashion. The API would also benefit from all of Data Controllers existing data validation logic (both frontend and backend), data auditing, alerts , and security control features. It is however, a significant departure from the existing \"SAS Content\" based deployment, in the following ways: Server Driven. A machine is required on which to launch, and run, the API application itself. Fully Automated. There is no browser, or interface, or - human, involved. Extends outside of SAS. There are firewalls, and authentication methods, to consider. The Data Controller technical solution will differ, depending on the type of SAS Platform being used. There are three types of SAS Platform: Foundation SAS - regular, Base SAS. SAS EBI - with Metadata. SAS Viya - cloud enabled. And there are three main options when it comes to building APIs on SAS: Standalone DC API (Viya Only). Viya comes with REST APIs out of the box, no middleware needed. SAS 9 API . This is an open-source Java Application, using SAS Authentication. SASjs Server . An open source NodeJS application, compatible with all major authentication methods and all versions of SAS An additional REST API option for SAS EBI might have been BI Web Services , however - it requires platform changes and is not highly secure. The compatibility matrix is therefore as follows: Product Foundation SAS SAS EBI SAS VIYA DCAPI \u274c \u274c \u2705 DCAPI + SASjs Server \u2705 \u2705 \u2705 DCAPI + SAS 9 API \u274c \u2705 \u274c In all cases, a Data Controller API will be surfaced, that makes use of the underlying (raw) API server. The following sections break down these options, and the work remaining to make them a reality.","title":"API"},{"location":"api/#standalone-dc-api-viya-only","text":"For Viya, the investment necessary is relatively low, thanks to the API-first nature of the platform. In addition, the SASjs framework already provides most of the necessary functionality - such as authentication, service execution, handling results & logs, etc. Finally, the Data Controller team have already built an API Bridge (specific to another customer, hence the building blocks are in place). The work to complete the Viya version of the API is as follows: Authorisation interface Creation of API services Tests & Automated Deployments Developer docs Swagger API Public Documentation Cost to complete - \u00a35,000 (Viya Only)","title":"Standalone DC API (Viya Only)"},{"location":"api/#sasjs-server-foundation-sas","text":"SASjs Server already provides an API interface over Foundation SAS. An example of building a web app using SASjs Server can be found here . In order for it to fulfill the role as the engine behind the Data Controller API, additional work is needed - specifically: Secure (Enterprise) Authentication Users & Groups Feature configuration (ability to restrict features to different groups) On top of this, the DC API part would cover: Authorisation interface Creation of API services Tests & Automated Deployments Developer docs Swagger API Public Documentation Cost to complete - \u00a310,000 (fixed) Given that all three SAS platforms have Foundation SAS available, this option will work everywhere. The only restriction is that the sasjs/server instance must be located on the same server as SAS. `","title":"SASjs Server (Foundation SAS)"},{"location":"api/#sas-9-api-sas-ebi","text":"This product has one major benefit - there is nothing to install on the SAS Platform itself. It connects to SAS in much the same way as Enterprise Guide (using the SAS IOM). Website: https://sas9api.io Github: https://github.com/analytium/sas9api The downside is that the features needed by Data Controller are not present in the API. Furthermore, the tool is not under active development. To build out the necessary functionality, it will require us to source a senior Java developer on a short term contract to first, understand the tool, and secondly, to update it in a sustainable way. We estimate the cost to build Data Controller API on this mechanism at \u00a320,000 - but it could be higher.","title":"SAS 9 API (SAS EBI)"},{"location":"column-level-security/","text":"Column Level Security \u00b6 Column level security is implemented by mapping allowed columns to a list of SAS groups. In VIEW mode, only allowed columns are visible. In EDIT mode, allowed columns are editable - the remaining columns are read-only. Below is an example of an EDIT table with only one column enabled for editing: See also: Row Level Security . Configuration \u00b6 The variables in MPE_COLUMN_LEVEL_SECURITY should be configured as follows: CLS_SCOPE \u00b6 Determines whether the rule applies to the VIEW page, the EDIT page, or ALL pages. The impact of the rule varies as follows: VIEW Scope \u00b6 When CLS_SCOPE in ('VIEW','ALL') then only the listed columns are visible (unless CLS_HIDE=1 ) EDIT Scope \u00b6 When CLS_SCOPE in ('EDIT','ALL') then only the listed columns are editable (the remaining columns are read-only, and visible). Furthermore: The user will be unable to ADD or DELETE records. Primary Key values are always read only Primary Key values cannot be hidden ( CLS_HIDE=1 will have no effect) CLS_GROUP \u00b6 The SAS Group to which the rule applies. The user could also be a member of a DC group . If a user is in ANY of the groups, the columns will be restricted. If a user is in NONE of the groups, no restrictions apply (all columns available). If a user is in MULTIPLE groups, they will see all allowed columns across all groups. If a user is in the Data Controller Admin Group , CLS rules DO NOT APPLY. CLS_LIBREF \u00b6 The library of the target table against which the security rule will be applied CLS_TABLE \u00b6 The target table against which the security rule will be applied CLS_VARIABLE_NM \u00b6 This is the name of the variable against which the security rule will be applied. Note that CLS_ACTIVE \u00b6 If you would like this rule to be applied, be sure this value is set to 1. CLS_HIDE \u00b6 This variable can be set to 1 to hide specific variables, which allows greater control over the EDIT screen in particular. CLS_SCOPE behaviour is impacted as follows: ALL - the variable will not be visible in either VIEW or EDIT. EDIT - the variable will not be visible. Cannot be applied to a primary key column . VIEW - the variable will not be visible. Can be applied to a primary key column. Simply omitting the row, or setting CLS_ACTIVE to 0, would result in the same behaviour. It is possible that a variable can have multiple values for CLS_HIDE, eg if a user is in multiple groups, or if different rules apply for different scopes. In this case, if the user is any group where this variable is NOT hidden, then it will be displayed. Example Config \u00b6 Example values as follows: CLS_SCOPE:$4 CLS_GROUP:$64 CLS_LIBREF:$8 CLS_TABLE:$32 CLS_VARIABLE_NM:$32 CLS_ACTIVE:8. CLS_HIDE:8. EDIT Group 1 MYLIB MYDS VAR_1 1 ALL Group 1 MYLIB MYDS VAR_2 1 ALL Group 2 MYLIB MYDS VAR_3 1 VIEW Group 1 MYLIB MYDS VAR_4 1 EDIT Group 1 MYLIB MYDS VAR_5 1 1 If a user is in Group 1, and viewing MYLIB.MYDS in EDIT mode, all columns will be visible but only the following columns will be editable: VAR_1 VAR_2 The user will be unable to add or delete rows. If the user is in both Group 1 AND Group 2, viewing MYLIB.MYDS in VIEW mode, only the following columns will be visible: VAR_2 VAR_3 VAR_4 Video Example \u00b6 This short video does a walkthrough of applying Column Level Security from end to end.","title":"Column Level Security"},{"location":"column-level-security/#column-level-security","text":"Column level security is implemented by mapping allowed columns to a list of SAS groups. In VIEW mode, only allowed columns are visible. In EDIT mode, allowed columns are editable - the remaining columns are read-only. Below is an example of an EDIT table with only one column enabled for editing: See also: Row Level Security .","title":"Column Level Security"},{"location":"column-level-security/#configuration","text":"The variables in MPE_COLUMN_LEVEL_SECURITY should be configured as follows:","title":"Configuration"},{"location":"column-level-security/#cls_scope","text":"Determines whether the rule applies to the VIEW page, the EDIT page, or ALL pages. The impact of the rule varies as follows:","title":"CLS_SCOPE"},{"location":"column-level-security/#view-scope","text":"When CLS_SCOPE in ('VIEW','ALL') then only the listed columns are visible (unless CLS_HIDE=1 )","title":"VIEW Scope"},{"location":"column-level-security/#edit-scope","text":"When CLS_SCOPE in ('EDIT','ALL') then only the listed columns are editable (the remaining columns are read-only, and visible). Furthermore: The user will be unable to ADD or DELETE records. Primary Key values are always read only Primary Key values cannot be hidden ( CLS_HIDE=1 will have no effect)","title":"EDIT Scope"},{"location":"column-level-security/#cls_group","text":"The SAS Group to which the rule applies. The user could also be a member of a DC group . If a user is in ANY of the groups, the columns will be restricted. If a user is in NONE of the groups, no restrictions apply (all columns available). If a user is in MULTIPLE groups, they will see all allowed columns across all groups. If a user is in the Data Controller Admin Group , CLS rules DO NOT APPLY.","title":"CLS_GROUP"},{"location":"column-level-security/#cls_libref","text":"The library of the target table against which the security rule will be applied","title":"CLS_LIBREF"},{"location":"column-level-security/#cls_table","text":"The target table against which the security rule will be applied","title":"CLS_TABLE"},{"location":"column-level-security/#cls_variable_nm","text":"This is the name of the variable against which the security rule will be applied. Note that","title":"CLS_VARIABLE_NM"},{"location":"column-level-security/#cls_active","text":"If you would like this rule to be applied, be sure this value is set to 1.","title":"CLS_ACTIVE"},{"location":"column-level-security/#cls_hide","text":"This variable can be set to 1 to hide specific variables, which allows greater control over the EDIT screen in particular. CLS_SCOPE behaviour is impacted as follows: ALL - the variable will not be visible in either VIEW or EDIT. EDIT - the variable will not be visible. Cannot be applied to a primary key column . VIEW - the variable will not be visible. Can be applied to a primary key column. Simply omitting the row, or setting CLS_ACTIVE to 0, would result in the same behaviour. It is possible that a variable can have multiple values for CLS_HIDE, eg if a user is in multiple groups, or if different rules apply for different scopes. In this case, if the user is any group where this variable is NOT hidden, then it will be displayed.","title":"CLS_HIDE"},{"location":"column-level-security/#example-config","text":"Example values as follows: CLS_SCOPE:$4 CLS_GROUP:$64 CLS_LIBREF:$8 CLS_TABLE:$32 CLS_VARIABLE_NM:$32 CLS_ACTIVE:8. CLS_HIDE:8. EDIT Group 1 MYLIB MYDS VAR_1 1 ALL Group 1 MYLIB MYDS VAR_2 1 ALL Group 2 MYLIB MYDS VAR_3 1 VIEW Group 1 MYLIB MYDS VAR_4 1 EDIT Group 1 MYLIB MYDS VAR_5 1 1 If a user is in Group 1, and viewing MYLIB.MYDS in EDIT mode, all columns will be visible but only the following columns will be editable: VAR_1 VAR_2 The user will be unable to add or delete rows. If the user is in both Group 1 AND Group 2, viewing MYLIB.MYDS in VIEW mode, only the following columns will be visible: VAR_2 VAR_3 VAR_4","title":"Example Config"},{"location":"column-level-security/#video-example","text":"This short video does a walkthrough of applying Column Level Security from end to end.","title":"Video Example"},{"location":"dc-overview/","text":"Data Controller for SAS\u00ae: Overview \u00b6 What does the Data Controller do? \u00b6 The Data Controller allows users to add, modify, and delete data. All changes are staged and approved before being applied to the target table. The review process, as well as using generic and repeatable code to perform updates, works to ensure data integrity. What is a Target Table? \u00b6 A Target Table is a physical table, such as a SAS dataset or a Table in a database. The attributes of this table (eg Primary Key, loadtype, library, SCD variables etc) will have been predefined by your administrator so that you can change the data in that table safely and easily. How does it work? \u00b6 From the Editor tab, a user selects a library and table for editing. Data can then be edited directly, or a uploaded from a file. After submitting the change, the data is loaded to a secure staging area, and the approvers are notified. The approver (which may also be the editor, depending on configuration) reviews the changes and accepts / or rejects them. If accepted, the changes are applied to the target table by the system account, and the history of that change is recorded. Who is it for? \u00b6 There are 5 roles identified for users of the Data Controller: Viewer . A viewer uses the Data Controller as a means to explore data without risk of locking datasets. By using the Data Controller to view data, it also becomes possible to 'link' to data (eg copy the url to share a table with a colleague). Editor . An editor makes changes to data in a table (add, modify, delete) and submits those changes to the approver(s) for acceptance. Approver . An approver accepts / rejects proposed changes to data under their control. If accepted, the change is applied to the target table. Auditor . An auditor has the ability to review the history of changes to a particular table. Administrator . An administrator has the ability to add new tables to the Data Controller, and to configure the security settings (at metadata group level) as required. What is a submission? \u00b6 The submission is the data that has been staged for approval. Note - submissions are never applied automatically! They must always be approved by 1 or more approvers first. The process of submission varies according to the type of submit. Web Submission \u00b6 When using the Web editor, a frontend check is made against the subset of data that was filtered for editing to see which rows are new / modified / marked deleted. Only those changed rows (from the extract) are submitted to the staging area. Excel Submission \u00b6 When importing an excel file, all rows are loaded into the web page. You have an option to edit those records. If you edit them, the original excel is discarded, and only changed rows are submitted (it becomes a web submission). If you hit SUBMIT immediately, then ALL rows are staged, and a copy of the excel file is uploaded for audit purposes. CSV submission \u00b6 A CSV upload bypasses the part where the records are loaded into the web page, and ALL rows are sent to the staging area directly. This makes it suitable for larger uploads. Edit Stage Approve Workflow \u00b6 Up to 500 rows can be edited (in the web editor) at one time. These edits are submitted to a staging area. After one or more approvals (acceptances) the changes are applied to the source table. Use Case Diagram \u00b6 There are five roles (Viewer, Editor, Approver, Auditor, Administrator) which correspond to 5 primary use cases (View Table, Edit Table, Approve Change, View Change History, Configure Table)","title":"Overview"},{"location":"dc-overview/#data-controller-for-sas-overview","text":"","title":"Data Controller for SAS\u00ae: Overview"},{"location":"dc-overview/#what-does-the-data-controller-do","text":"The Data Controller allows users to add, modify, and delete data. All changes are staged and approved before being applied to the target table. The review process, as well as using generic and repeatable code to perform updates, works to ensure data integrity.","title":"What does the Data Controller do?"},{"location":"dc-overview/#what-is-a-target-table","text":"A Target Table is a physical table, such as a SAS dataset or a Table in a database. The attributes of this table (eg Primary Key, loadtype, library, SCD variables etc) will have been predefined by your administrator so that you can change the data in that table safely and easily.","title":"What is a Target Table?"},{"location":"dc-overview/#how-does-it-work","text":"From the Editor tab, a user selects a library and table for editing. Data can then be edited directly, or a uploaded from a file. After submitting the change, the data is loaded to a secure staging area, and the approvers are notified. The approver (which may also be the editor, depending on configuration) reviews the changes and accepts / or rejects them. If accepted, the changes are applied to the target table by the system account, and the history of that change is recorded.","title":"How does it work?"},{"location":"dc-overview/#who-is-it-for","text":"There are 5 roles identified for users of the Data Controller: Viewer . A viewer uses the Data Controller as a means to explore data without risk of locking datasets. By using the Data Controller to view data, it also becomes possible to 'link' to data (eg copy the url to share a table with a colleague). Editor . An editor makes changes to data in a table (add, modify, delete) and submits those changes to the approver(s) for acceptance. Approver . An approver accepts / rejects proposed changes to data under their control. If accepted, the change is applied to the target table. Auditor . An auditor has the ability to review the history of changes to a particular table. Administrator . An administrator has the ability to add new tables to the Data Controller, and to configure the security settings (at metadata group level) as required.","title":"Who is it for?"},{"location":"dc-overview/#what-is-a-submission","text":"The submission is the data that has been staged for approval. Note - submissions are never applied automatically! They must always be approved by 1 or more approvers first. The process of submission varies according to the type of submit.","title":"What is a submission?"},{"location":"dc-overview/#web-submission","text":"When using the Web editor, a frontend check is made against the subset of data that was filtered for editing to see which rows are new / modified / marked deleted. Only those changed rows (from the extract) are submitted to the staging area.","title":"Web Submission"},{"location":"dc-overview/#excel-submission","text":"When importing an excel file, all rows are loaded into the web page. You have an option to edit those records. If you edit them, the original excel is discarded, and only changed rows are submitted (it becomes a web submission). If you hit SUBMIT immediately, then ALL rows are staged, and a copy of the excel file is uploaded for audit purposes.","title":"Excel Submission"},{"location":"dc-overview/#csv-submission","text":"A CSV upload bypasses the part where the records are loaded into the web page, and ALL rows are sent to the staging area directly. This makes it suitable for larger uploads.","title":"CSV submission"},{"location":"dc-overview/#edit-stage-approve-workflow","text":"Up to 500 rows can be edited (in the web editor) at one time. These edits are submitted to a staging area. After one or more approvals (acceptances) the changes are applied to the source table.","title":"Edit Stage Approve Workflow"},{"location":"dc-overview/#use-case-diagram","text":"There are five roles (Viewer, Editor, Approver, Auditor, Administrator) which correspond to 5 primary use cases (View Table, Edit Table, Approve Change, View Change History, Configure Table)","title":"Use Case Diagram"},{"location":"dc-userguide/","text":"Data Controller for SAS: User Guide \u00b6 Interface \u00b6 The Data Controller has 5 tabs, as follows: Viewer . This tab lets users view any table to which they have been granted access in metadata. They can also download the data as csv, excel, or as a SAS program (datalines). Primary key fields are coloured green. Editor . This tab enables users to add, modify or delete data. This can be done directly in the browser, or by uploading a CSV file. Values can also be copy-pasted from a spreadsheet. Once changes are ready, they can be submitted, with a corresponding reason. Submitted . This shows and editor the outstanding changes that have been submitted for approval (but have not yet been approved or rejected). Approvals . This shows an approver all their outstanding approval requests. History . This shows an auditor, or other interested party, what changes have been submitted for each table. Viewer \u00b6 Overview \u00b6 The viewer screen provides users with a raw view of underlying data. It is only possible to view tables that have been registered in metadata. Advantages of using the viewer (over client tools) for browsing data include: Ability to provide links to tables / filtered views of tables (just copy url) In the case of SAS datasets, prevent file locks from ocurring Ability to quickly download a CSV / Excel / SAS Cards program for that table Usage \u00b6 Choose a library, then a table, and click view to see the first 5000 rows. A filter option is provided should you wish to view a different section of rows. The Download button gives three options for obtaining the current view of data: 1) CSV. This provides a comma delimited file. 2) Excel. This provides a tab delimited file. 3) SAS. This provides a SAS program with data as datalines, so that the data can be rebuilt as a SAS table. Note - if the table is registered in Data Controller as being TXTEMPORAL (SCD2) then the download option will prefilter for the current records and removes the valid from / valid to variables. This makes the CSV a suitable format for subsequent DC file upload, if desired. Editor \u00b6 The Editor screen lets users who have been pre-authorised (via the DATACTRL.MPE_SECURITY table) to edit a particular table. A user selects a particular library, and table and then has 3 options: 1 - Filter . The user can filter before proceeding to perform edits. 2 - Upload . If you have a lot of data, you can upload it directly . The changes are then approved in the usual way. 3 - Edit . This is the main interface, data is displayed in tabular format. The first column is always \"Delete?\", as this allows you to mark rows for deletion. Note that removing a row from display does not mark it for deletion! It simply means that this row is not part of the changeset being submitted. The next set of columns are the Primary Key, and are shaded grey. If the table has a surrogate / retained key, then it is the Business Key that is shown here (the RK field is calculated / updated at the backend). For SCD2 type tables, the 'validity' fields are not shown. It is assumed that the user is always working with the current version of the data, and the view is filtered as such. After this, remaining columns are shown. Dates / datetime fields have appropriate datepickers. Other fields may also have dropdowns to ensure entry of standard values, these can be configured in the DATACTRL.MPE_SELECTBOX table. New rows can be added using the right click context menu, or the 'Add Row' button. The data can also be sorted by clicking on the column headers. When ready to submit, hit the SUBMIT button and enter a reason for the change. The owners of the data are now alerted (so long as their email addresses are in metadata) with a link to the approve screen. If you are also an approver you can approve this change yourself. Special Missings \u00b6 Data Controller supports special missing numerics, ie - a single letter or underscore. These should be submitted without the leading period. The letters are not case sensitive. BiTemporal Tables \u00b6 The Data Controller only permits BiTemporal data uploads at a single point in time - so for convenience, when viewing data in the edit screen, only the most recent records are displayed. To edit earlier records, either use file upload, or apply a filter. Submitted \u00b6 This page shows a list of the changes you have submitted (that are not yet approved). Approvals \u00b6 This shows the list of changes that have been submitted to you (or your groups) for approval. History \u00b6 View the list of changes to each table, who made the change, when, etc.","title":"DC User Guide"},{"location":"dc-userguide/#data-controller-for-sas-user-guide","text":"","title":"Data Controller for SAS: User Guide"},{"location":"dc-userguide/#interface","text":"The Data Controller has 5 tabs, as follows: Viewer . This tab lets users view any table to which they have been granted access in metadata. They can also download the data as csv, excel, or as a SAS program (datalines). Primary key fields are coloured green. Editor . This tab enables users to add, modify or delete data. This can be done directly in the browser, or by uploading a CSV file. Values can also be copy-pasted from a spreadsheet. Once changes are ready, they can be submitted, with a corresponding reason. Submitted . This shows and editor the outstanding changes that have been submitted for approval (but have not yet been approved or rejected). Approvals . This shows an approver all their outstanding approval requests. History . This shows an auditor, or other interested party, what changes have been submitted for each table.","title":"Interface"},{"location":"dc-userguide/#viewer","text":"","title":"Viewer"},{"location":"dc-userguide/#overview","text":"The viewer screen provides users with a raw view of underlying data. It is only possible to view tables that have been registered in metadata. Advantages of using the viewer (over client tools) for browsing data include: Ability to provide links to tables / filtered views of tables (just copy url) In the case of SAS datasets, prevent file locks from ocurring Ability to quickly download a CSV / Excel / SAS Cards program for that table","title":"Overview"},{"location":"dc-userguide/#usage","text":"Choose a library, then a table, and click view to see the first 5000 rows. A filter option is provided should you wish to view a different section of rows. The Download button gives three options for obtaining the current view of data: 1) CSV. This provides a comma delimited file. 2) Excel. This provides a tab delimited file. 3) SAS. This provides a SAS program with data as datalines, so that the data can be rebuilt as a SAS table. Note - if the table is registered in Data Controller as being TXTEMPORAL (SCD2) then the download option will prefilter for the current records and removes the valid from / valid to variables. This makes the CSV a suitable format for subsequent DC file upload, if desired.","title":"Usage"},{"location":"dc-userguide/#editor","text":"The Editor screen lets users who have been pre-authorised (via the DATACTRL.MPE_SECURITY table) to edit a particular table. A user selects a particular library, and table and then has 3 options: 1 - Filter . The user can filter before proceeding to perform edits. 2 - Upload . If you have a lot of data, you can upload it directly . The changes are then approved in the usual way. 3 - Edit . This is the main interface, data is displayed in tabular format. The first column is always \"Delete?\", as this allows you to mark rows for deletion. Note that removing a row from display does not mark it for deletion! It simply means that this row is not part of the changeset being submitted. The next set of columns are the Primary Key, and are shaded grey. If the table has a surrogate / retained key, then it is the Business Key that is shown here (the RK field is calculated / updated at the backend). For SCD2 type tables, the 'validity' fields are not shown. It is assumed that the user is always working with the current version of the data, and the view is filtered as such. After this, remaining columns are shown. Dates / datetime fields have appropriate datepickers. Other fields may also have dropdowns to ensure entry of standard values, these can be configured in the DATACTRL.MPE_SELECTBOX table. New rows can be added using the right click context menu, or the 'Add Row' button. The data can also be sorted by clicking on the column headers. When ready to submit, hit the SUBMIT button and enter a reason for the change. The owners of the data are now alerted (so long as their email addresses are in metadata) with a link to the approve screen. If you are also an approver you can approve this change yourself.","title":"Editor"},{"location":"dc-userguide/#special-missings","text":"Data Controller supports special missing numerics, ie - a single letter or underscore. These should be submitted without the leading period. The letters are not case sensitive.","title":"Special Missings"},{"location":"dc-userguide/#bitemporal-tables","text":"The Data Controller only permits BiTemporal data uploads at a single point in time - so for convenience, when viewing data in the edit screen, only the most recent records are displayed. To edit earlier records, either use file upload, or apply a filter.","title":"BiTemporal Tables"},{"location":"dc-userguide/#submitted","text":"This page shows a list of the changes you have submitted (that are not yet approved).","title":"Submitted"},{"location":"dc-userguide/#approvals","text":"This shows the list of changes that have been submitted to you (or your groups) for approval.","title":"Approvals"},{"location":"dc-userguide/#history","text":"View the list of changes to each table, who made the change, when, etc.","title":"History"},{"location":"dcc-dates/","text":"Data Controller for SAS\u00ae - Dates & Datetimes \u00b6 Overview \u00b6 Dates & datetimes are actually stored as plain numerics in regular SAS tables. In order for the Data Controller to recognise these values as dates / datetimes a format must be applied. Supported date formats: DATE. DDMMYY. MMDDYY. YYMMDD. E8601DA. B8601DA. Supported datetime formats: DATETIME. Supported time formats: TIME. HHMM. In SAS 9, this format must also be present / updated in the metadata view of the (physical) table to be displayed properly. This can be done using DI Studio, or by running the following (template) code: proc metalib; omr (library= \"Your Library\" ); folder= \"/Shared Data/table storage location\" ; update_rule=( delete ) ; run; If you have other dates / datetimes / times you would like us to support, do get in touch !","title":"Dates / Datetimes"},{"location":"dcc-dates/#data-controller-for-sas-dates-datetimes","text":"","title":"Data Controller for SAS\u00ae - Dates &amp; Datetimes"},{"location":"dcc-dates/#overview","text":"Dates & datetimes are actually stored as plain numerics in regular SAS tables. In order for the Data Controller to recognise these values as dates / datetimes a format must be applied. Supported date formats: DATE. DDMMYY. MMDDYY. YYMMDD. E8601DA. B8601DA. Supported datetime formats: DATETIME. Supported time formats: TIME. HHMM. In SAS 9, this format must also be present / updated in the metadata view of the (physical) table to be displayed properly. This can be done using DI Studio, or by running the following (template) code: proc metalib; omr (library= \"Your Library\" ); folder= \"/Shared Data/table storage location\" ; update_rule=( delete ) ; run; If you have other dates / datetimes / times you would like us to support, do get in touch !","title":"Overview"},{"location":"dcc-groups/","text":"Adding Groups \u00b6 Overview \u00b6 By default, Data Controller will work with the SAS Groups defined in Viya, Metadata, or SASjs Server. It is also possible to define custom groups with Data Controller itself - to do this simply add the user and group name (and optionally, a group description) in the DATACTRL.MPE_GROUPS table. Data Controller Admin Group \u00b6 When configuring Data Controller for the first time, a group is designated as the 'admin' group. This group has unrestricted access to Data Controller. To change this group, modify the %let dc_admin_group= entry in the settings program. To prevent others from changing this group, ensure the containing folder is write-protected!","title":"Groups"},{"location":"dcc-groups/#adding-groups","text":"","title":"Adding Groups"},{"location":"dcc-groups/#overview","text":"By default, Data Controller will work with the SAS Groups defined in Viya, Metadata, or SASjs Server. It is also possible to define custom groups with Data Controller itself - to do this simply add the user and group name (and optionally, a group description) in the DATACTRL.MPE_GROUPS table.","title":"Overview"},{"location":"dcc-groups/#data-controller-admin-group","text":"When configuring Data Controller for the first time, a group is designated as the 'admin' group. This group has unrestricted access to Data Controller. To change this group, modify the %let dc_admin_group= entry in the settings program. To prevent others from changing this group, ensure the containing folder is write-protected!","title":"Data Controller Admin Group"},{"location":"dcc-options/","text":"Data Controller for SAS\u00ae - Options \u00b6 The MPE_CONFIG table provides a number of system options, which apply to all users. The table may be re-purposed for other applications, so long as scopes beginning with \"DC_\" are avoided. Currently used scopes include: DC DC_CATALOG DC Scope \u00b6 DC_EMAIL_ALERTS \u00b6 Set to YES or NO to enable email alerts. This requires email options to be preconfigured (mail server etc). DC_MAXOBS_WEBEDIT \u00b6 By default, a maximum of 100 observations can be edited in the browser at one time. This number can be increased, but note that the following factors will impact performance: Number of configured Validations Browser type and version (works best in Chrome) Number (and size) of columns Speed of client machine (laptop/desktop) DC_RESTRICT_EDITRECORD \u00b6 Setting YES will prevent the EDIT RECORD dialog appearing in the EDIT screen by removing the \"Edit Row\" option in the right click menu, and the \"ADD RECORD\" button in the bottom left. Anything other than YES will mean that the modal is available. Default=NO DC_RESTRICT_VIEWER \u00b6 Set to YES to restrict the list of libraries and tables in VIEWER to only those explicitly set to VIEW in the MPE_SECURITY table. The default is NO (users can see all tables they already have permission to see). DC_VIEWLIB_CHECK \u00b6 Set to YES to enable library validity checking in viewLibs service. This means that on first load, SAS will attempt to open each library to see if it is possible to do so. This reduces the number of libraries in the list, but means that it is slow to load the first time around. The default is NO. DC_LOCALE \u00b6 Set to a locale (such as en_gb or en_be ) to override the system value (which may be derived from client browser settings). This feature is useful when importing ambiguous dates from CSV or Excel (eg 1/2/20 vs 2/1/20) as DC uses the anydtdtm. informats for import. Default=SYSTEM. Note If you have clients in different geographies loading excel in local formats, you can also address this issue by ensuring the locale of the windows user profile is not set to the default (eg English (United States) ). When leaving the DC_LOCALE as SYSTEM, the locale settings in SAS are not added or modified. DC_CATALOG Scope \u00b6 DC_IGNORELIBS \u00b6 When running the Refresh Data Catalog service, it is often that case the the process will fail due to being unable to assign a library. To avoid the need to resolve the connection issue elsewhere in SAS, you can simply exclude it from the Data Catalog, by including the LIBREF in this field (pipe-separated) DC_REVIEW Scope \u00b6 HISTORY_ROWS \u00b6 Number of rows to return for each HISTORY page. Default - 100. Increasing this will increase for all users. Using very large numbers here can result in a sluggish page load time. If you need large amounts of HISTORY data, it is generally better to extract it directly from the MPE_REVIEW table.","title":"Options"},{"location":"dcc-options/#data-controller-for-sas-options","text":"The MPE_CONFIG table provides a number of system options, which apply to all users. The table may be re-purposed for other applications, so long as scopes beginning with \"DC_\" are avoided. Currently used scopes include: DC DC_CATALOG","title":"Data Controller for SAS\u00ae - Options"},{"location":"dcc-options/#dc-scope","text":"","title":"DC Scope"},{"location":"dcc-options/#dc_email_alerts","text":"Set to YES or NO to enable email alerts. This requires email options to be preconfigured (mail server etc).","title":"DC_EMAIL_ALERTS"},{"location":"dcc-options/#dc_maxobs_webedit","text":"By default, a maximum of 100 observations can be edited in the browser at one time. This number can be increased, but note that the following factors will impact performance: Number of configured Validations Browser type and version (works best in Chrome) Number (and size) of columns Speed of client machine (laptop/desktop)","title":"DC_MAXOBS_WEBEDIT"},{"location":"dcc-options/#dc_restrict_editrecord","text":"Setting YES will prevent the EDIT RECORD dialog appearing in the EDIT screen by removing the \"Edit Row\" option in the right click menu, and the \"ADD RECORD\" button in the bottom left. Anything other than YES will mean that the modal is available. Default=NO","title":"DC_RESTRICT_EDITRECORD"},{"location":"dcc-options/#dc_restrict_viewer","text":"Set to YES to restrict the list of libraries and tables in VIEWER to only those explicitly set to VIEW in the MPE_SECURITY table. The default is NO (users can see all tables they already have permission to see).","title":"DC_RESTRICT_VIEWER"},{"location":"dcc-options/#dc_viewlib_check","text":"Set to YES to enable library validity checking in viewLibs service. This means that on first load, SAS will attempt to open each library to see if it is possible to do so. This reduces the number of libraries in the list, but means that it is slow to load the first time around. The default is NO.","title":"DC_VIEWLIB_CHECK"},{"location":"dcc-options/#dc_locale","text":"Set to a locale (such as en_gb or en_be ) to override the system value (which may be derived from client browser settings). This feature is useful when importing ambiguous dates from CSV or Excel (eg 1/2/20 vs 2/1/20) as DC uses the anydtdtm. informats for import. Default=SYSTEM. Note If you have clients in different geographies loading excel in local formats, you can also address this issue by ensuring the locale of the windows user profile is not set to the default (eg English (United States) ). When leaving the DC_LOCALE as SYSTEM, the locale settings in SAS are not added or modified.","title":"DC_LOCALE"},{"location":"dcc-options/#dc_catalog-scope","text":"","title":"DC_CATALOG Scope"},{"location":"dcc-options/#dc_ignorelibs","text":"When running the Refresh Data Catalog service, it is often that case the the process will fail due to being unable to assign a library. To avoid the need to resolve the connection issue elsewhere in SAS, you can simply exclude it from the Data Catalog, by including the LIBREF in this field (pipe-separated)","title":"DC_IGNORELIBS"},{"location":"dcc-options/#dc_review-scope","text":"","title":"DC_REVIEW Scope"},{"location":"dcc-options/#history_rows","text":"Number of rows to return for each HISTORY page. Default - 100. Increasing this will increase for all users. Using very large numbers here can result in a sluggish page load time. If you need large amounts of HISTORY data, it is generally better to extract it directly from the MPE_REVIEW table.","title":"HISTORY_ROWS"},{"location":"dcc-security/","text":"Data Controller for SAS\u00ae - Security \u00b6 Summary \u00b6 DC security is applied at the level of Table and Group. Permissions can only be set at group level. There are two parts to adding a user: 1 - Adding the user to the relevant group 2 - Ensuring that group has the appropriate access level in the MPE_SECURITY table For guidance with adding SAS users in SAS 9, see SAS Documentation . Details \u00b6 In order to surface a table to a new group, simply add a record to the DATACTRL.MPE_SECURITY table. The library.dataset value should go in the BASE_TABLE field, the level of access (either EDIT or APPROVE ) should go in the ACCESS_LEVEL field, and the exact name of the relevant metadata group should go in the SAS_GROUP field. The change should then be submitted, and approved, at which point the new security setting will be applied. ACCESS_LEVEL \u00b6 EDIT \u00b6 The EDIT permission determines which groups will be able to upload CSVs and submit changes via the web interface for that table. APPROVE \u00b6 The APPROVE permission determines which groups will be able to approve those changes, and hence enable the target table to be loaded. If you wish to have members of a particular group both edit AND approve, then two lines (one for each group) must be entered, per table. VIEW \u00b6 The default behaviour when installing Data Controller is that the viewer lets all SAS Users see all the tables that they are authorised to view in SAS. However there may be reasons to further restrict the tables in this component. There is a global setting that will disable ALL tables in VIEWER unless explicitly authorised - this is available in MPE_CONFIG. Set DC_RESTRICT_VIEWER=YES , submit, and approve. If authorising groups without this setting, it means that tables will be restricted only in that library (the rest will still be visible). Groups can be given VIEW access for all libraries or all tables within a library by using the keyword *ALL* instead of the libref / tablename. It's also worth being aware of the DC_VIEWLIB_CHECK option in MPE_CONFIG. When this is switched on, SAS will confirm that the library is valid and contains tables, before adding to the list. This can sometimes be slow (depending on your library configurations), hence disabled - but as the list is actually cached on frontend (until the next hard refresh) the impact may worth it. Determining Group Members \u00b6 Before adding a group to Data Controller, it helps to know the members of that group! A User navigator is available in both the SAS 9 and Viya version of Data Controller. You can navigate Users, Groups and Roles (roles are only visible in the SAS 9 version). This means you do not need SAS Management Console or SAS Environment Manager to manage Data Controller users. However you will need those tools for managing SAS Groups, unless you define your own groups in the MPE_GROUPS table.","title":"Security"},{"location":"dcc-security/#data-controller-for-sas-security","text":"","title":"Data Controller for SAS\u00ae - Security"},{"location":"dcc-security/#summary","text":"DC security is applied at the level of Table and Group. Permissions can only be set at group level. There are two parts to adding a user: 1 - Adding the user to the relevant group 2 - Ensuring that group has the appropriate access level in the MPE_SECURITY table For guidance with adding SAS users in SAS 9, see SAS Documentation .","title":"Summary"},{"location":"dcc-security/#details","text":"In order to surface a table to a new group, simply add a record to the DATACTRL.MPE_SECURITY table. The library.dataset value should go in the BASE_TABLE field, the level of access (either EDIT or APPROVE ) should go in the ACCESS_LEVEL field, and the exact name of the relevant metadata group should go in the SAS_GROUP field. The change should then be submitted, and approved, at which point the new security setting will be applied.","title":"Details"},{"location":"dcc-security/#access_level","text":"","title":"ACCESS_LEVEL"},{"location":"dcc-security/#edit","text":"The EDIT permission determines which groups will be able to upload CSVs and submit changes via the web interface for that table.","title":"EDIT"},{"location":"dcc-security/#approve","text":"The APPROVE permission determines which groups will be able to approve those changes, and hence enable the target table to be loaded. If you wish to have members of a particular group both edit AND approve, then two lines (one for each group) must be entered, per table.","title":"APPROVE"},{"location":"dcc-security/#view","text":"The default behaviour when installing Data Controller is that the viewer lets all SAS Users see all the tables that they are authorised to view in SAS. However there may be reasons to further restrict the tables in this component. There is a global setting that will disable ALL tables in VIEWER unless explicitly authorised - this is available in MPE_CONFIG. Set DC_RESTRICT_VIEWER=YES , submit, and approve. If authorising groups without this setting, it means that tables will be restricted only in that library (the rest will still be visible). Groups can be given VIEW access for all libraries or all tables within a library by using the keyword *ALL* instead of the libref / tablename. It's also worth being aware of the DC_VIEWLIB_CHECK option in MPE_CONFIG. When this is switched on, SAS will confirm that the library is valid and contains tables, before adding to the list. This can sometimes be slow (depending on your library configurations), hence disabled - but as the list is actually cached on frontend (until the next hard refresh) the impact may worth it.","title":"VIEW"},{"location":"dcc-security/#determining-group-members","text":"Before adding a group to Data Controller, it helps to know the members of that group! A User navigator is available in both the SAS 9 and Viya version of Data Controller. You can navigate Users, Groups and Roles (roles are only visible in the SAS 9 version). This means you do not need SAS Management Console or SAS Environment Manager to manage Data Controller users. However you will need those tools for managing SAS Groups, unless you define your own groups in the MPE_GROUPS table.","title":"Determining Group Members"},{"location":"dcc-selectbox/","text":"Data Controller for SAS\u00ae - Selectboxes \u00b6 Overview \u00b6 To ensure data validity and to improve user experience, it is possible to predesignate specific values for data entry. These appear to the user as a selectbox within the editor interface. Configuration \u00b6 Values are added by populating the DATACTRL.MPE_SELECTBOX table, eg below: BASE_LIBDS \u00b6 The library.dataset to which the selectbox needs to be applied BASE_COLUMN \u00b6 The column in which the selectbox values will be entered SELECTBOX_VALUE \u00b6 The actual values to be shown in the selectbox SELECTBOX_ORDER \u00b6 The order in which the selectbox values should be displayed SELECTBOX_TYPE \u00b6 Reserved for future use.","title":"Selectboxes"},{"location":"dcc-selectbox/#data-controller-for-sas-selectboxes","text":"","title":"Data Controller for SAS\u00ae - Selectboxes"},{"location":"dcc-selectbox/#overview","text":"To ensure data validity and to improve user experience, it is possible to predesignate specific values for data entry. These appear to the user as a selectbox within the editor interface.","title":"Overview"},{"location":"dcc-selectbox/#configuration","text":"Values are added by populating the DATACTRL.MPE_SELECTBOX table, eg below:","title":"Configuration"},{"location":"dcc-selectbox/#base_libds","text":"The library.dataset to which the selectbox needs to be applied","title":"BASE_LIBDS"},{"location":"dcc-selectbox/#base_column","text":"The column in which the selectbox values will be entered","title":"BASE_COLUMN"},{"location":"dcc-selectbox/#selectbox_value","text":"The actual values to be shown in the selectbox","title":"SELECTBOX_VALUE"},{"location":"dcc-selectbox/#selectbox_order","text":"The order in which the selectbox values should be displayed","title":"SELECTBOX_ORDER"},{"location":"dcc-selectbox/#selectbox_type","text":"Reserved for future use.","title":"SELECTBOX_TYPE"},{"location":"dcc-tables/","text":"Data Controller for SAS\u00ae - Adding Tables \u00b6 Overview \u00b6 Adding tables to the Data Controller is a matter of configuration, specifically the addition of a new record to the DATACTRL.MPE_TABLES table, and corresponding entries in the DATACTRL.MPE_SECURITY table. Note In order to surface the table to (non admin) users, appropriate groups should be configured as per security settings. MPE_TABLES Configuration Details \u00b6 Each table to be edited in the Data Controller is represented by one record in DATACTRL.MPE_TABLES . The fields should be populated as follows: LIBREF \u00b6 The libref of the table. If not pre-assigned, and the serverType is SAS 9 (EBI), DC will assign it at runtime using the first definition found in metadata, using this macro . DSN \u00b6 The dataset (table) name as visible when assigning a direct libref connection to LIBREF . If the target is a format catalog, it should have a \"-FC\" suffice (eg FORMATS-FC ). More info on formats here . NUM_OF_APPROVALS_REQUIRED \u00b6 This is an integer representing the number of approvals required before a table is updated. This mechanism lets you insist on, for example, 2 or 3 approvals before sensitive data is updated following a submission. Note that only one rejection is ever necessary to remove the submission. This is a required field. LOADTYPE \u00b6 The loadtype determines the nature of the update to be applied. Valid values are as follows: FORMAT_CAT. For updating Format Catalogs, the BUSKEY should be FMTNAME START . See formats . UPDATE. This is the most basic type, and any updates will happen 'in place'. Simply provide the primary key fields in the BUSKEY column. TXTEMPORAL. This signifies an SCD2 type load. For this type the validity fields (valid from, valid to) should be specified in the VAR_TXFROM and VAR_TXTO fields. The table itself should include VAR_TXFROM in the physical key. The remainder of the primary key fields (not including VAR_TXFROM ) should be specified in BUSKEY . BITEMPORAL. These tables have two time dimensions - a version history, and a business history. The version history (SCD2) fields should be specified in VAR_TXFROM and VAR_TXTO and the business history fields should be specified in VAR_BUSFROM and VAR_BUSTO . Both the VAR_TXFROM and VAR_BUSFROM fields should be in the physical key of the actual table, but should NOT be specified in the BUSKEY field. This is a required field. Note The support for BITEMPORAL loads is restricted, in the sense it is only possible to load data at a single point in time (no support for loading multiple business date ranges for a specific BUSKEY). The workaround is simply to load each date range separately. As a result of this restriction, the EDIT page will only show the latest business date range for each key. To modify earlier values, a filter should be applied. BUSKEY \u00b6 The business (natural) key of the table. For SCD2 / Bitemporal, this does NOT include the validity dates. For Retained / Surrogate key tables, this contains the actual surrogate key - the underlying fields that are used to create the surrogate key are specified in RK_UNDERLYING . This is a required field. VAR_TXFROM / VAR_TXTO \u00b6 The SCD2 type validity dates, representing the point in time at which the field was created ( VAR_TXFROM ) and when it was closed out ( VAR_TXTO ) from a change or deletion. If the record is active, the VAR_TXTO field would contain a high value. VAR_TXFROM is a part of the physical key of the underlying table. These fields should contain the NAME of the variables which contain the open / close timestamps in the underlying table. Leave blank if not required. VAR_BUSFROM / VAR_BUSTO \u00b6 The BITEMPORAL business dates which represent the reporting period to which the record is valid. Typically these contain date values (rather than datetime values). If variables are specified here, then the LOADTYPE should be BITEMPORAL . Leave blank if not required. VAR_PROCESSED \u00b6 Set the name of a variable (eg processed_dttm ) which should be given a current timestamp whenever the table is updated. Leave blank if not required. CLOSE_VARS \u00b6 By default, the Data Controller will only process the records that are part of a changeset. This means that records should be explicity marked for deletion. But what if you are performing a reload of a monthly batch, and the absence of a record implies that it is no longer required? For this scenario, it is necessary to specify the range within a 'complete' load is expected. For instance, by reporting month, or month + product. When performing loads, the DC will then first extract a distinct list of values for this key and close them out in the target table, before performing the upload. The CLOSE_VARS are typically a subset of the BUSKEY fields. Leave blank if not required. PRE_EDIT_HOOK \u00b6 Hook script to execute prior to an edit being made. This allows data to be modified before being presented for editing. Leave blank if not required. SAS Developer Notes: Target dataset: work.OUT Filters will have been applied, and table sorted on BUSKEY Base libref.table or catalog variable: &orig_libds POST_EDIT_HOOK \u00b6 Hook script to execute after an edit has been made. Useful when there is a need to augment data, or perform advanced data quality checks prior to approval. Leave blank if not required. SAS Developer Notes: Target dataset: work.STAGING_DS Base libref.table or catalog variable: &orig_libds If your DQ check means that the program should not be submitted, then simply exit with &syscc > 4 . You can even set a message to go back to the user by using the mp_abort macro: %mp_abort(iftrue= (&syscc ne 0) /* if this condition is true, the process will exit */ ,msg=%str(YOUR MESSAGE GOES HERE) ) PRE_APPROVE_HOOK \u00b6 Hook script to execute before the approval diff is generated. It can be used to modify the values presented to an approver on the approve screen. This can be helpful in order to present the data in way that can be easily consumed by approvers. Leave blank if not required. SAS Developer Notes: Target dataset: work.STAGING_DS Base libref.table or catalog variable: &orig_libds POST_APPROVE_HOOK \u00b6 This hook script is %inc 'd after an approval is made. This is the most common type of hook script, and is useful for, say, running a SAS job after a mapping table is updated, or running a model after changing a parameter. Leave blank if not required. SAS Developer Notes: At the point of running this script, the data has already been loaded (successfully) to the target table. Therefore the target is typically the base libref.table (or format catalog) itself and can be referenced directly (YOURLIB.YOURDATASET), or using either of the following macro variable: &orig_libds &libref..&ds The staged table is also available, as work.STAGING_DS . If you are making changes to the target table as part of the hook, then in order to prevent contention from other users making concurrent edits, you are advised to \"LOCK\" and \"UNLOCK\" it using the mp_lockanytable macro: /* lock SOMELIB.SOMETABLE */ %mp_lockanytable(LOCK, lib=SOMELIB, ds=SOMETABLE, ref=Locking table to peform a post approve hook action ctl_ds=&mpelib..mpe_lockanytable ) /* do stuff */ proc sort data=somelib.sometable; run; /* unlock */ %mp_lockanytable(UNLOCK, lib=SOMELIB, ds=SOMETABLE, ctl_ds=&mpelib..mpe_lockanytable ) The SAS session will already contain the mp_lockanytable macro definition. SIGNOFF_COLS \u00b6 Used to determine a range (eg reporting month) to which a 'final version' can be marked. This allows a particular version of data to be marked as final, meaning that the data can continue to change afterwards (reports can simply query for the timestamp of the 'final' version of the data). Leave blank if not required. SIGNOFF_HOOK \u00b6 This hook script is %inc 'd after a 'final version' has been signed off. Leave blank if not required. NOTES \u00b6 Content entered here will be displayed to the approver on signoff. Not required, but recommended. RK_UNDERLYING \u00b6 For retained / surrogate keys, an auto-incrementing field is used to represent each unique record. In this case, the RK (integer) field itself should be added in the BUSKEY column, and the natural / underlying key should be added here. Leave blank unless using retained / surrogate keys. AUDIT_LIBDS \u00b6 If this field is blank (ie empty, missing), every change is captured in the MPE_AUDIT . This can result in large data volumes for frequently changing tables. Alternative options are: Enter a zero ( 0 ) to switch off audit logging completely Enter a library.dataset reference of an alternative audit table in which to capture the change history. For option 2, the base table structure can be generated using this macro: https://core.sasjs.io/mddl__dc__difftable_8sas_source.html . HOOK Scripts \u00b6 Data Controller allows SAS programs to be executed at certain points in the ingestion lifecycle, such as: Before an edit (to control the edit screen) After an edit (perform complex data quality) Before an approval (control the approve screen) After an approval (trigger downstream jobs with new data) The code is simply %include 'd at the relevant point during backend execution. The program may be: Physical, ie the full path to a .sas program on the physical server directory Logical, ie a Viya Job (SAS Drive), SAS 9 Stored Process (Metadata Folder) or SASJS Stored Program (SASjs Drive). If the entry ends in \".sas\" it is assumed to be a physical, filesystem file. Otherwise, the source code is extracted from SAS Drive or Metadata. To illustrate: Physical filesystem (ends in .sas): /opt/sas/code/myprogram.sas Logical filesystem: /Shared Data/stored_processes/mydatavalidator","title":"Tables"},{"location":"dcc-tables/#data-controller-for-sas-adding-tables","text":"","title":"Data Controller for SAS\u00ae - Adding Tables"},{"location":"dcc-tables/#overview","text":"Adding tables to the Data Controller is a matter of configuration, specifically the addition of a new record to the DATACTRL.MPE_TABLES table, and corresponding entries in the DATACTRL.MPE_SECURITY table. Note In order to surface the table to (non admin) users, appropriate groups should be configured as per security settings.","title":"Overview"},{"location":"dcc-tables/#mpe_tables-configuration-details","text":"Each table to be edited in the Data Controller is represented by one record in DATACTRL.MPE_TABLES . The fields should be populated as follows:","title":"MPE_TABLES Configuration Details"},{"location":"dcc-tables/#libref","text":"The libref of the table. If not pre-assigned, and the serverType is SAS 9 (EBI), DC will assign it at runtime using the first definition found in metadata, using this macro .","title":"LIBREF"},{"location":"dcc-tables/#dsn","text":"The dataset (table) name as visible when assigning a direct libref connection to LIBREF . If the target is a format catalog, it should have a \"-FC\" suffice (eg FORMATS-FC ). More info on formats here .","title":"DSN"},{"location":"dcc-tables/#num_of_approvals_required","text":"This is an integer representing the number of approvals required before a table is updated. This mechanism lets you insist on, for example, 2 or 3 approvals before sensitive data is updated following a submission. Note that only one rejection is ever necessary to remove the submission. This is a required field.","title":"NUM_OF_APPROVALS_REQUIRED"},{"location":"dcc-tables/#loadtype","text":"The loadtype determines the nature of the update to be applied. Valid values are as follows: FORMAT_CAT. For updating Format Catalogs, the BUSKEY should be FMTNAME START . See formats . UPDATE. This is the most basic type, and any updates will happen 'in place'. Simply provide the primary key fields in the BUSKEY column. TXTEMPORAL. This signifies an SCD2 type load. For this type the validity fields (valid from, valid to) should be specified in the VAR_TXFROM and VAR_TXTO fields. The table itself should include VAR_TXFROM in the physical key. The remainder of the primary key fields (not including VAR_TXFROM ) should be specified in BUSKEY . BITEMPORAL. These tables have two time dimensions - a version history, and a business history. The version history (SCD2) fields should be specified in VAR_TXFROM and VAR_TXTO and the business history fields should be specified in VAR_BUSFROM and VAR_BUSTO . Both the VAR_TXFROM and VAR_BUSFROM fields should be in the physical key of the actual table, but should NOT be specified in the BUSKEY field. This is a required field. Note The support for BITEMPORAL loads is restricted, in the sense it is only possible to load data at a single point in time (no support for loading multiple business date ranges for a specific BUSKEY). The workaround is simply to load each date range separately. As a result of this restriction, the EDIT page will only show the latest business date range for each key. To modify earlier values, a filter should be applied.","title":"LOADTYPE"},{"location":"dcc-tables/#buskey","text":"The business (natural) key of the table. For SCD2 / Bitemporal, this does NOT include the validity dates. For Retained / Surrogate key tables, this contains the actual surrogate key - the underlying fields that are used to create the surrogate key are specified in RK_UNDERLYING . This is a required field.","title":"BUSKEY"},{"location":"dcc-tables/#var_txfrom-var_txto","text":"The SCD2 type validity dates, representing the point in time at which the field was created ( VAR_TXFROM ) and when it was closed out ( VAR_TXTO ) from a change or deletion. If the record is active, the VAR_TXTO field would contain a high value. VAR_TXFROM is a part of the physical key of the underlying table. These fields should contain the NAME of the variables which contain the open / close timestamps in the underlying table. Leave blank if not required.","title":"VAR_TXFROM / VAR_TXTO"},{"location":"dcc-tables/#var_busfrom-var_busto","text":"The BITEMPORAL business dates which represent the reporting period to which the record is valid. Typically these contain date values (rather than datetime values). If variables are specified here, then the LOADTYPE should be BITEMPORAL . Leave blank if not required.","title":"VAR_BUSFROM / VAR_BUSTO"},{"location":"dcc-tables/#var_processed","text":"Set the name of a variable (eg processed_dttm ) which should be given a current timestamp whenever the table is updated. Leave blank if not required.","title":"VAR_PROCESSED"},{"location":"dcc-tables/#close_vars","text":"By default, the Data Controller will only process the records that are part of a changeset. This means that records should be explicity marked for deletion. But what if you are performing a reload of a monthly batch, and the absence of a record implies that it is no longer required? For this scenario, it is necessary to specify the range within a 'complete' load is expected. For instance, by reporting month, or month + product. When performing loads, the DC will then first extract a distinct list of values for this key and close them out in the target table, before performing the upload. The CLOSE_VARS are typically a subset of the BUSKEY fields. Leave blank if not required.","title":"CLOSE_VARS"},{"location":"dcc-tables/#pre_edit_hook","text":"Hook script to execute prior to an edit being made. This allows data to be modified before being presented for editing. Leave blank if not required. SAS Developer Notes: Target dataset: work.OUT Filters will have been applied, and table sorted on BUSKEY Base libref.table or catalog variable: &orig_libds","title":"PRE_EDIT_HOOK"},{"location":"dcc-tables/#post_edit_hook","text":"Hook script to execute after an edit has been made. Useful when there is a need to augment data, or perform advanced data quality checks prior to approval. Leave blank if not required. SAS Developer Notes: Target dataset: work.STAGING_DS Base libref.table or catalog variable: &orig_libds If your DQ check means that the program should not be submitted, then simply exit with &syscc > 4 . You can even set a message to go back to the user by using the mp_abort macro: %mp_abort(iftrue= (&syscc ne 0) /* if this condition is true, the process will exit */ ,msg=%str(YOUR MESSAGE GOES HERE) )","title":"POST_EDIT_HOOK"},{"location":"dcc-tables/#pre_approve_hook","text":"Hook script to execute before the approval diff is generated. It can be used to modify the values presented to an approver on the approve screen. This can be helpful in order to present the data in way that can be easily consumed by approvers. Leave blank if not required. SAS Developer Notes: Target dataset: work.STAGING_DS Base libref.table or catalog variable: &orig_libds","title":"PRE_APPROVE_HOOK"},{"location":"dcc-tables/#post_approve_hook","text":"This hook script is %inc 'd after an approval is made. This is the most common type of hook script, and is useful for, say, running a SAS job after a mapping table is updated, or running a model after changing a parameter. Leave blank if not required. SAS Developer Notes: At the point of running this script, the data has already been loaded (successfully) to the target table. Therefore the target is typically the base libref.table (or format catalog) itself and can be referenced directly (YOURLIB.YOURDATASET), or using either of the following macro variable: &orig_libds &libref..&ds The staged table is also available, as work.STAGING_DS . If you are making changes to the target table as part of the hook, then in order to prevent contention from other users making concurrent edits, you are advised to \"LOCK\" and \"UNLOCK\" it using the mp_lockanytable macro: /* lock SOMELIB.SOMETABLE */ %mp_lockanytable(LOCK, lib=SOMELIB, ds=SOMETABLE, ref=Locking table to peform a post approve hook action ctl_ds=&mpelib..mpe_lockanytable ) /* do stuff */ proc sort data=somelib.sometable; run; /* unlock */ %mp_lockanytable(UNLOCK, lib=SOMELIB, ds=SOMETABLE, ctl_ds=&mpelib..mpe_lockanytable ) The SAS session will already contain the mp_lockanytable macro definition.","title":"POST_APPROVE_HOOK"},{"location":"dcc-tables/#signoff_cols","text":"Used to determine a range (eg reporting month) to which a 'final version' can be marked. This allows a particular version of data to be marked as final, meaning that the data can continue to change afterwards (reports can simply query for the timestamp of the 'final' version of the data). Leave blank if not required.","title":"SIGNOFF_COLS"},{"location":"dcc-tables/#signoff_hook","text":"This hook script is %inc 'd after a 'final version' has been signed off. Leave blank if not required.","title":"SIGNOFF_HOOK"},{"location":"dcc-tables/#notes","text":"Content entered here will be displayed to the approver on signoff. Not required, but recommended.","title":"NOTES"},{"location":"dcc-tables/#rk_underlying","text":"For retained / surrogate keys, an auto-incrementing field is used to represent each unique record. In this case, the RK (integer) field itself should be added in the BUSKEY column, and the natural / underlying key should be added here. Leave blank unless using retained / surrogate keys.","title":"RK_UNDERLYING"},{"location":"dcc-tables/#audit_libds","text":"If this field is blank (ie empty, missing), every change is captured in the MPE_AUDIT . This can result in large data volumes for frequently changing tables. Alternative options are: Enter a zero ( 0 ) to switch off audit logging completely Enter a library.dataset reference of an alternative audit table in which to capture the change history. For option 2, the base table structure can be generated using this macro: https://core.sasjs.io/mddl__dc__difftable_8sas_source.html .","title":"AUDIT_LIBDS"},{"location":"dcc-tables/#hook-scripts","text":"Data Controller allows SAS programs to be executed at certain points in the ingestion lifecycle, such as: Before an edit (to control the edit screen) After an edit (perform complex data quality) Before an approval (control the approve screen) After an approval (trigger downstream jobs with new data) The code is simply %include 'd at the relevant point during backend execution. The program may be: Physical, ie the full path to a .sas program on the physical server directory Logical, ie a Viya Job (SAS Drive), SAS 9 Stored Process (Metadata Folder) or SASJS Stored Program (SASjs Drive). If the entry ends in \".sas\" it is assumed to be a physical, filesystem file. Otherwise, the source code is extracted from SAS Drive or Metadata. To illustrate: Physical filesystem (ends in .sas): /opt/sas/code/myprogram.sas Logical filesystem: /Shared Data/stored_processes/mydatavalidator","title":"HOOK Scripts"},{"location":"dcc-validations/","text":"Data Controller for SAS\u00ae - DQ Validations \u00b6 Overview \u00b6 Quality in, Quality out! Data Controller lets you enforce quality checks at the point of data entry, both directly via the web interface and also via Excel uploads. Default Checks \u00b6 By default, the following frontend rules are always applied: Length checking per target table variable lengths Type checking per target table datatypes (Character, Numeric, Date, Time, Datetime) Not Null check per target table constraints Primary Key checking per business key defined in MPE_TABLES It is possible to configure a number of other rules by updating the MPE_VALIDATIONS table. Simply set the BASE_LIB , BASE_DS and BASE_COL values, and ensure RULE_ACTIVE=1 for it to be applied. Configurable Checks \u00b6 Check back frequently as we plan to keep growing this list of checks. Rule Type Example Value Description CASE UPCASE Will enforce the case of cell values. Valid values: UPCASE, LOWCASE, PROPCASE NOTNULL (defaultval) Will prevent submission if null values are present. Optional - provide a default value. MINVAL 1 Defines a minimum value for a numeric cell MAXVAL 1000000 Defines a maximum value for a numeric cell HARDSELECT sashelp.class.name A distinct list of values (max 1000) are taken from this library.member.column reference, and the value must be in this list. This list may be supplemented by entries in the MPE_SELECTBOX table. SOFTSELECT dcdemo.mpe_tables.libref A distinct list of values (max 1000) are taken from this library.member.column reference, and the user-provided value may (or may not) be in this list. This list may be supplemented by entries in the MPE_SELECTBOX table. HARDSELECT_HOOK /logical/folder/stpname A SAS service (STP or Viya Job) or a path to a SAS program on the filesystem. User provided values must be in this list. Cannot be used alongside a SOFTSELECT_HOOK. SOFTSELECT_HOOK /physical/path/program.sas A SAS service (STP or Viya Job) or a path to a SAS program on the filesystem. User-provided values may (or may not) be in this list. Cannot be used alongside a HARDSELECT_HOOK. Dropdowns \u00b6 There are now actually FIVE places where you can configure dropdowns! The MPE_SELECTBOX table The HARDSELECT validation (library.member.column reference) The SOFTSELECT validation (library.member.column reference) The HARDSELECT_HOOK validation (SAS Program) The SOFTSELECT_HOOK validation (SAS Program) How do these inter-operate? Well - if you have values in MPE_SELECTBOX and/or HARDSELECT / SOFTSELECT tables, they will be merged together, and served in ADDITION to the values provided by any HOOK program. Dropdowns are SOFT by default, unless a HARD rule is present. Data Controller will not let you submit both a HARDSELECT_HOOK and a SOFTSELECT_HOOK on the same variable.","title":"Validations"},{"location":"dcc-validations/#data-controller-for-sas-dq-validations","text":"","title":"Data Controller for SAS\u00ae - DQ Validations"},{"location":"dcc-validations/#overview","text":"Quality in, Quality out! Data Controller lets you enforce quality checks at the point of data entry, both directly via the web interface and also via Excel uploads.","title":"Overview"},{"location":"dcc-validations/#default-checks","text":"By default, the following frontend rules are always applied: Length checking per target table variable lengths Type checking per target table datatypes (Character, Numeric, Date, Time, Datetime) Not Null check per target table constraints Primary Key checking per business key defined in MPE_TABLES It is possible to configure a number of other rules by updating the MPE_VALIDATIONS table. Simply set the BASE_LIB , BASE_DS and BASE_COL values, and ensure RULE_ACTIVE=1 for it to be applied.","title":"Default Checks"},{"location":"dcc-validations/#configurable-checks","text":"Check back frequently as we plan to keep growing this list of checks. Rule Type Example Value Description CASE UPCASE Will enforce the case of cell values. Valid values: UPCASE, LOWCASE, PROPCASE NOTNULL (defaultval) Will prevent submission if null values are present. Optional - provide a default value. MINVAL 1 Defines a minimum value for a numeric cell MAXVAL 1000000 Defines a maximum value for a numeric cell HARDSELECT sashelp.class.name A distinct list of values (max 1000) are taken from this library.member.column reference, and the value must be in this list. This list may be supplemented by entries in the MPE_SELECTBOX table. SOFTSELECT dcdemo.mpe_tables.libref A distinct list of values (max 1000) are taken from this library.member.column reference, and the user-provided value may (or may not) be in this list. This list may be supplemented by entries in the MPE_SELECTBOX table. HARDSELECT_HOOK /logical/folder/stpname A SAS service (STP or Viya Job) or a path to a SAS program on the filesystem. User provided values must be in this list. Cannot be used alongside a SOFTSELECT_HOOK. SOFTSELECT_HOOK /physical/path/program.sas A SAS service (STP or Viya Job) or a path to a SAS program on the filesystem. User-provided values may (or may not) be in this list. Cannot be used alongside a HARDSELECT_HOOK.","title":"Configurable Checks"},{"location":"dcc-validations/#dropdowns","text":"There are now actually FIVE places where you can configure dropdowns! The MPE_SELECTBOX table The HARDSELECT validation (library.member.column reference) The SOFTSELECT validation (library.member.column reference) The HARDSELECT_HOOK validation (SAS Program) The SOFTSELECT_HOOK validation (SAS Program) How do these inter-operate? Well - if you have values in MPE_SELECTBOX and/or HARDSELECT / SOFTSELECT tables, they will be merged together, and served in ADDITION to the values provided by any HOOK program. Dropdowns are SOFT by default, unless a HARD rule is present. Data Controller will not let you submit both a HARDSELECT_HOOK and a SOFTSELECT_HOOK on the same variable.","title":"Dropdowns"},{"location":"dci-deploysas9/","text":"SAS 9 Deployment \u00b6 Deployment Process \u00b6 There are two ways to deploy Data Controller on SAS 9: Full Deployment (preferred) Streaming (for quick demos) Full Deployment \u00b6 1 - Deploy Stored Processes \u00b6 The Stored Processes are deployed using a SAS Program. This should be executed using an account that has WRITE METADATA (WM) permissions to the necessary root folder ( appLoc ) in metadata. %let appLoc=/Shared Data/apps/DataController; /* CHANGE THIS!! */ filename dc url \"https://git.4gl.io/dc/deploy/-/raw/main/s9_noweb.sas\" ; %inc dc; If you don't have internet access from SAS, download this file and change the compiled_apploc on line 2: You can also change the serverName here, which is necessary if you are using any other logical server than SASApp . 2 - Deploy the Frontend \u00b6 The Data Controller frontend comes pre-built, and ready to deploy to the root of the SAS Web Server (mid-tier). Deploy as follows: Download the zip file from: https://git.4gl.io/dc/deploy/-/raw/main/frontend.zip Unzip and place in the htdocs folder of your SAS Web Server - typically !SASCONFIG/LevX/Web/WebServer/htdocs . Open the index.html file and update the values for appLoc (per SAS code above) and serverType (to SAS9 ). You can now open the app at https://YOURWEBSERVER/unzippedfoldername and follow the configuration steps (DC Physical Location and Admin Group) to complete deployment. 3 - Run the Configurator \u00b6 When opening Data Controller for the first time, a configuration screen is presented. Be sure to log in with an account that has WRITE METADATA (WM) on the following metadata folders: services/admin - so the configurator STP can be deleted after being run services/common - so the Data_Controller_Settings STP can be updated Data - so the library and tables can be registered (using proc metalib) There are two things to configure: Path to the designated physical staging area. Make sure that the SAS Spawned Server account (eg sassrv ) has WRITE access to this location. Admin Group. \u26a0\ufe0f Note that anyone in this group will have unrestricted access to Data Controller! \u26a0\ufe0f \"Unrestricted access\" is provided by code logic. Post installation, Data Controller will never update nor modify metadata. Note If you do not see any groups, then it is possible your Stored Process is running from a different metadata repository to the location of your SAS users (eg Foundation). To fix this, update the services/admin/configurator STP with this code: %let dc_repo_users=YOUUSERRMETAREPO; After you click submit, the Stored Process will run, configure the staging area and create the library tables (as datasets). You will then be presented with three further links: Refresh Data Catalog. Run this to scan all available datasets and update the catalog. Refresh Table Metadata. Run this to update the table-level data lineage. Launch. Currently this feature only works for streaming apps - just refresh the page for a full deployment. Streaming \u00b6 The streaming approach is optimised for rapid deployment, and works by bundling the frontend into metadata. This is a highly inefficient way to serve web content, and thus should only really be used for demos / evaluation purposes. Deployment is very easy - just run the SAS code below (after changing the appLoc ): %let appLoc=/Shared Data/apps/DataController; /* CHANGE THIS!! */ filename dc url \"https://git.4gl.io/dc/deploy/-/raw/main/s9.sas\" ; %inc dc; If you don't have internet access from your SAS environment, you can also download the file directly and modify the appLoc on line 2, as follows: After that, continue to the configuration as described above. Deployment Diagram \u00b6 A Full Deployment of Data Controller for SAS 9 consists of: Frontend on the web server Stored Processes (+ Library & Table definitions) in metadata Staging Area on the physical filesystem Database or SAS Base library The below areas of the SAS platform are modified when deploying Data Controller: Client Device \u00b6 Nothing needs to be deployed or modified on the client device. We support a wide range of browsers (the same as SAS). Browsers make requests to the SAS Web Server, and will cache assets such as JS, CSS and images. Some items (such as dropdowns) are kept in local storage to improve responsiveness. SAS Mid Tier \u00b6 A single index.html file plus several CSS / JS / image files are served from a subfolder in the static content area SAS Web Server. This is served up by the existing SAS Web Server, no additional server (running) process is required. If you are running more than one web server, you will need to deploy to them all. SAS Application Server \u00b6 Given the enhanced permissions needed of the system account, a dedicated / secured STP instance is recommended as described here . All deployments of Data Controller also make use of a physical staging directory. This is used to store staged data, logs, plus CSV and Excel files as uploaded by end users. This directory should NOT be accessible by end users - only the SAS system account (eg sassrv ) requires access to this directory. A typical small deployment will grow by a 10-20 mb each month. A very large enterprise customer, with 100 or more editors, might generate up to 1 GB or so per month, depending on the size and frequency of the Excel EUCs and CSVs being uploaded. Web modifications are restricted only to modified rows, so are typically just a few kb in size. SAS Metadata Server \u00b6 The items deployed to metadata include: Folder tree Stored Processes Library Object & tables All SAS code is embedded in Stored Processes (so there is no need to deploy programs to the file system, no SASAUTOs). There is no use of X commands, no use of external internet access, full LOCKDOWN is supported. After the installation process (which updates public/settings and removes the admin/makedata STP), there are no write actions performed against metadata. Databases \u00b6 We strongly recommend that the Data Controller configuration tables are stored in a database for concurrency reasons. We have customers in production using Oracle, Postgres, Netezza, SQL Server to name a few. Contact us for support with DDL and migration steps for your chosen vendor. Note Data Controller does NOT modify schemas! It will not create or drop tables, or add/modify columns or attributes. Only data values (not the model) can be modified using this tool. To caveat the above - it is also quite common for customers to use a BASE engine library. Data Controller ships with mechananisms to handle locking (internally) but it cannot handle external contentions, such as those caused when end users open datasets directly, eg with Enterprise Guide or Base SAS.","title":"SAS 9 Deploy"},{"location":"dci-deploysas9/#sas-9-deployment","text":"","title":"SAS 9 Deployment"},{"location":"dci-deploysas9/#deployment-process","text":"There are two ways to deploy Data Controller on SAS 9: Full Deployment (preferred) Streaming (for quick demos)","title":"Deployment Process"},{"location":"dci-deploysas9/#full-deployment","text":"","title":"Full Deployment"},{"location":"dci-deploysas9/#1-deploy-stored-processes","text":"The Stored Processes are deployed using a SAS Program. This should be executed using an account that has WRITE METADATA (WM) permissions to the necessary root folder ( appLoc ) in metadata. %let appLoc=/Shared Data/apps/DataController; /* CHANGE THIS!! */ filename dc url \"https://git.4gl.io/dc/deploy/-/raw/main/s9_noweb.sas\" ; %inc dc; If you don't have internet access from SAS, download this file and change the compiled_apploc on line 2: You can also change the serverName here, which is necessary if you are using any other logical server than SASApp .","title":"1 - Deploy Stored Processes"},{"location":"dci-deploysas9/#2-deploy-the-frontend","text":"The Data Controller frontend comes pre-built, and ready to deploy to the root of the SAS Web Server (mid-tier). Deploy as follows: Download the zip file from: https://git.4gl.io/dc/deploy/-/raw/main/frontend.zip Unzip and place in the htdocs folder of your SAS Web Server - typically !SASCONFIG/LevX/Web/WebServer/htdocs . Open the index.html file and update the values for appLoc (per SAS code above) and serverType (to SAS9 ). You can now open the app at https://YOURWEBSERVER/unzippedfoldername and follow the configuration steps (DC Physical Location and Admin Group) to complete deployment.","title":"2 - Deploy the Frontend"},{"location":"dci-deploysas9/#3-run-the-configurator","text":"When opening Data Controller for the first time, a configuration screen is presented. Be sure to log in with an account that has WRITE METADATA (WM) on the following metadata folders: services/admin - so the configurator STP can be deleted after being run services/common - so the Data_Controller_Settings STP can be updated Data - so the library and tables can be registered (using proc metalib) There are two things to configure: Path to the designated physical staging area. Make sure that the SAS Spawned Server account (eg sassrv ) has WRITE access to this location. Admin Group. \u26a0\ufe0f Note that anyone in this group will have unrestricted access to Data Controller! \u26a0\ufe0f \"Unrestricted access\" is provided by code logic. Post installation, Data Controller will never update nor modify metadata. Note If you do not see any groups, then it is possible your Stored Process is running from a different metadata repository to the location of your SAS users (eg Foundation). To fix this, update the services/admin/configurator STP with this code: %let dc_repo_users=YOUUSERRMETAREPO; After you click submit, the Stored Process will run, configure the staging area and create the library tables (as datasets). You will then be presented with three further links: Refresh Data Catalog. Run this to scan all available datasets and update the catalog. Refresh Table Metadata. Run this to update the table-level data lineage. Launch. Currently this feature only works for streaming apps - just refresh the page for a full deployment.","title":"3 - Run the Configurator"},{"location":"dci-deploysas9/#streaming","text":"The streaming approach is optimised for rapid deployment, and works by bundling the frontend into metadata. This is a highly inefficient way to serve web content, and thus should only really be used for demos / evaluation purposes. Deployment is very easy - just run the SAS code below (after changing the appLoc ): %let appLoc=/Shared Data/apps/DataController; /* CHANGE THIS!! */ filename dc url \"https://git.4gl.io/dc/deploy/-/raw/main/s9.sas\" ; %inc dc; If you don't have internet access from your SAS environment, you can also download the file directly and modify the appLoc on line 2, as follows: After that, continue to the configuration as described above.","title":"Streaming"},{"location":"dci-deploysas9/#deployment-diagram","text":"A Full Deployment of Data Controller for SAS 9 consists of: Frontend on the web server Stored Processes (+ Library & Table definitions) in metadata Staging Area on the physical filesystem Database or SAS Base library The below areas of the SAS platform are modified when deploying Data Controller:","title":"Deployment Diagram"},{"location":"dci-deploysas9/#client-device","text":"Nothing needs to be deployed or modified on the client device. We support a wide range of browsers (the same as SAS). Browsers make requests to the SAS Web Server, and will cache assets such as JS, CSS and images. Some items (such as dropdowns) are kept in local storage to improve responsiveness.","title":"Client Device"},{"location":"dci-deploysas9/#sas-mid-tier","text":"A single index.html file plus several CSS / JS / image files are served from a subfolder in the static content area SAS Web Server. This is served up by the existing SAS Web Server, no additional server (running) process is required. If you are running more than one web server, you will need to deploy to them all.","title":"SAS Mid Tier"},{"location":"dci-deploysas9/#sas-application-server","text":"Given the enhanced permissions needed of the system account, a dedicated / secured STP instance is recommended as described here . All deployments of Data Controller also make use of a physical staging directory. This is used to store staged data, logs, plus CSV and Excel files as uploaded by end users. This directory should NOT be accessible by end users - only the SAS system account (eg sassrv ) requires access to this directory. A typical small deployment will grow by a 10-20 mb each month. A very large enterprise customer, with 100 or more editors, might generate up to 1 GB or so per month, depending on the size and frequency of the Excel EUCs and CSVs being uploaded. Web modifications are restricted only to modified rows, so are typically just a few kb in size.","title":"SAS Application Server"},{"location":"dci-deploysas9/#sas-metadata-server","text":"The items deployed to metadata include: Folder tree Stored Processes Library Object & tables All SAS code is embedded in Stored Processes (so there is no need to deploy programs to the file system, no SASAUTOs). There is no use of X commands, no use of external internet access, full LOCKDOWN is supported. After the installation process (which updates public/settings and removes the admin/makedata STP), there are no write actions performed against metadata.","title":"SAS Metadata Server"},{"location":"dci-deploysas9/#databases","text":"We strongly recommend that the Data Controller configuration tables are stored in a database for concurrency reasons. We have customers in production using Oracle, Postgres, Netezza, SQL Server to name a few. Contact us for support with DDL and migration steps for your chosen vendor. Note Data Controller does NOT modify schemas! It will not create or drop tables, or add/modify columns or attributes. Only data values (not the model) can be modified using this tool. To caveat the above - it is also quite common for customers to use a BASE engine library. Data Controller ships with mechananisms to handle locking (internally) but it cannot handle external contentions, such as those caused when end users open datasets directly, eg with Enterprise Guide or Base SAS.","title":"Databases"},{"location":"dci-deploysasviya/","text":"SAS Viya Deployment \u00b6 Overview \u00b6 Data Controller for SAS Viya consists of a frontend, a set of Job Execution Services, a staging area, a Compute Context, and a database library. The library can be a SAS Base engine if desired, however this can cause contention (eg table locks) if end users are able to connect to the datasets directly, eg via Enterprise Guide or Base SAS. A database that supports concurrent access is highly recommended. Prerequisites \u00b6 System Account \u00b6 Data Controller makes use of a system account for performing backend data updates and writing to the staging area. This needs to be provisioned in advance using the Viya admin-cli. The process is well described here: https://communities.sas.com/t5/SAS-Communities-Library/SAS-Viya-3-5-Compute-Server-Service-Accounts/ta-p/620992 Database \u00b6 Whilst we do recommend that Data Controller configuration tables are stored in a database for concurrency reasons, it is also possible to use a BASE engine library, which is adequate if you only have a few users. To migrate the control library to a database, first perform a regular deployment, and afterwards you can generate the DDL and update the settings file.. Make sure the system account (see above) has full read / write access. Note \"Modify schema\" privileges are not required. Staging Directory \u00b6 All deployments of Data Controller make use of a physical staging directory. This is used to store logs, as well as CSV and Excel files uploaded by end users. This directory should NOT be accessible by end users - only the SAS system account requires access to this directory. A typical small deployment will grow by a 5-10 mb each month. A very large enterprise customer, with 100 or more editors, might generate up to 0.5 GB or so per month, depending on the size and frequency of the Excel EUCs and CSVs being uploaded. Web modifications are restricted only to modified rows, so are typically just a few kb in size. Deployment Diagram \u00b6 The below areas of the SAS Viya platform are modified when deploying Data Controller: Deployment \u00b6 Data Controller deployment is split between 3 deployment types: Demo version Full Version (manual deploy) Full Version (automated deploy) There are several parts to this proces: Create the Compute Context Deploy Frontend Prepare the database and update settings (optional) Update the Compute Context autoexec Create Compute Context \u00b6 The Viya Compute context is used to spawn the Job Execution Services - such that those services may run under the specified system account, with a particular autoexec. We strongly recommend a dedicated compute context for running Data Controller. The setup requires an Administrator account. Log onto SASEnvironment Manager, select Contexts, View Compute Contexts, and click the Create icon. In the New Compute Context dialog, enter the following attributes: Context Name Launcher Context Attribute pairs: reuseServerProcesses: true runServerAs: {{the account set up earlier }} Save and exit Note XCMD is NOT required to use Data Controller. Deploy frontend \u00b6 Unzip the frontend into your chosen directory (eg /var/www/html/DataController ) on the SAS Web Server. Open index.html and update the following inside dcAdapterSettings : appLoc - this should point to the root folder on SAS Drive where you would like the Job Execution services to be created. This folder should initially, NOT exist (if it is found, the backend will not be deployed) contextName - here you should put the name of the compute context you created in the previous step. dcPath - the physical location on the filesystem to be used for staged data. This is only used at deployment time, it can be configured later in $(appLoc)/services/settings.sas or in the autoexec if used. adminGroup - the name of an existing group, which should have unrestricted access to Data Controller. This is only used at deployment time, it can be configured later in $(appLoc)/services/settings.sas or in the autoexec if used. servertype - should be SASVIYA debug - can stay as false for performance, but could be switched to true for debugging startup issues useComputeApi - use true for best performance. Now, open https://YOURSERVER/DataController (using whichever subfolder you deployed to above) using an account that has the SAS privileges to write to the appLoc location. You will be presented with a deployment screen like the one below. Be sure to check the \"Recreate Database\" option and then click the \"Deploy\" button. Your services are deployed! And the app is operational, albeit still a little sluggish, as every single request is using the APIs to fetch the content of the $(appLoc)/services/settings.sas file. To improve responsiveness by another 700ms we recommend you follow the steps in Update Compute Context Autoexec below. Deploy Database \u00b6 If you have a lot of users, such that concurrency (locked datasets) becomes an issue, you might consider migrating the control library to a database. The first part to this is generating the DDL (and inserts). For this, use the DDL exporter as described here . If you need a flavour of DDL that is not yet supported, contact us . Step 2 is simply to run this DDL in your preferred database. Step 3 is to update the library definition in the $(appLoc)/services/settings.sas file using SAS Studio. Update Compute Context Autoexec \u00b6 First, open the $(appLoc)/services/settings.sas file in SAS Studio, and copy the code. Then, open SASEnvironment Manager, select Contexts, View Compute Contexts, and open the context we created earlier. Switch to the Advanced tab and paste in the SAS code copied from SAS Studio above. It will look similar to: %let DC_LIBREF=DCDBVIYA; %let DC_ADMIN_GROUP={{YOUR DC ADMIN GROUP}}; %let DC_STAGING_AREA={{YOUR DEDICATED FILE SYSTEM DRIVE}}; libname &dc_libref {{YOUR DC DATABASE}}; To explain each of these lines: DC_LIBREF can be any valid 8 character libref. DC_ADMIN_GROUP is the name of the group which will have unrestricted access to Data Controller DC_STAGING_AREA should point to the location on the filesystem where the staging files and logs are be stored The final libname statement can also be configured to point at a database instead of a BASE engine directory (contact us for DDL) If you have additional libraries that you would like to use in Data Controller, they should also be defined here.","title":"SAS Viya Deploy"},{"location":"dci-deploysasviya/#sas-viya-deployment","text":"","title":"SAS Viya Deployment"},{"location":"dci-deploysasviya/#overview","text":"Data Controller for SAS Viya consists of a frontend, a set of Job Execution Services, a staging area, a Compute Context, and a database library. The library can be a SAS Base engine if desired, however this can cause contention (eg table locks) if end users are able to connect to the datasets directly, eg via Enterprise Guide or Base SAS. A database that supports concurrent access is highly recommended.","title":"Overview"},{"location":"dci-deploysasviya/#prerequisites","text":"","title":"Prerequisites"},{"location":"dci-deploysasviya/#system-account","text":"Data Controller makes use of a system account for performing backend data updates and writing to the staging area. This needs to be provisioned in advance using the Viya admin-cli. The process is well described here: https://communities.sas.com/t5/SAS-Communities-Library/SAS-Viya-3-5-Compute-Server-Service-Accounts/ta-p/620992","title":"System Account"},{"location":"dci-deploysasviya/#database","text":"Whilst we do recommend that Data Controller configuration tables are stored in a database for concurrency reasons, it is also possible to use a BASE engine library, which is adequate if you only have a few users. To migrate the control library to a database, first perform a regular deployment, and afterwards you can generate the DDL and update the settings file.. Make sure the system account (see above) has full read / write access. Note \"Modify schema\" privileges are not required.","title":"Database"},{"location":"dci-deploysasviya/#staging-directory","text":"All deployments of Data Controller make use of a physical staging directory. This is used to store logs, as well as CSV and Excel files uploaded by end users. This directory should NOT be accessible by end users - only the SAS system account requires access to this directory. A typical small deployment will grow by a 5-10 mb each month. A very large enterprise customer, with 100 or more editors, might generate up to 0.5 GB or so per month, depending on the size and frequency of the Excel EUCs and CSVs being uploaded. Web modifications are restricted only to modified rows, so are typically just a few kb in size.","title":"Staging Directory"},{"location":"dci-deploysasviya/#deployment-diagram","text":"The below areas of the SAS Viya platform are modified when deploying Data Controller:","title":"Deployment Diagram"},{"location":"dci-deploysasviya/#deployment","text":"Data Controller deployment is split between 3 deployment types: Demo version Full Version (manual deploy) Full Version (automated deploy) There are several parts to this proces: Create the Compute Context Deploy Frontend Prepare the database and update settings (optional) Update the Compute Context autoexec","title":"Deployment"},{"location":"dci-deploysasviya/#create-compute-context","text":"The Viya Compute context is used to spawn the Job Execution Services - such that those services may run under the specified system account, with a particular autoexec. We strongly recommend a dedicated compute context for running Data Controller. The setup requires an Administrator account. Log onto SASEnvironment Manager, select Contexts, View Compute Contexts, and click the Create icon. In the New Compute Context dialog, enter the following attributes: Context Name Launcher Context Attribute pairs: reuseServerProcesses: true runServerAs: {{the account set up earlier }} Save and exit Note XCMD is NOT required to use Data Controller.","title":"Create Compute Context"},{"location":"dci-deploysasviya/#deploy-frontend","text":"Unzip the frontend into your chosen directory (eg /var/www/html/DataController ) on the SAS Web Server. Open index.html and update the following inside dcAdapterSettings : appLoc - this should point to the root folder on SAS Drive where you would like the Job Execution services to be created. This folder should initially, NOT exist (if it is found, the backend will not be deployed) contextName - here you should put the name of the compute context you created in the previous step. dcPath - the physical location on the filesystem to be used for staged data. This is only used at deployment time, it can be configured later in $(appLoc)/services/settings.sas or in the autoexec if used. adminGroup - the name of an existing group, which should have unrestricted access to Data Controller. This is only used at deployment time, it can be configured later in $(appLoc)/services/settings.sas or in the autoexec if used. servertype - should be SASVIYA debug - can stay as false for performance, but could be switched to true for debugging startup issues useComputeApi - use true for best performance. Now, open https://YOURSERVER/DataController (using whichever subfolder you deployed to above) using an account that has the SAS privileges to write to the appLoc location. You will be presented with a deployment screen like the one below. Be sure to check the \"Recreate Database\" option and then click the \"Deploy\" button. Your services are deployed! And the app is operational, albeit still a little sluggish, as every single request is using the APIs to fetch the content of the $(appLoc)/services/settings.sas file. To improve responsiveness by another 700ms we recommend you follow the steps in Update Compute Context Autoexec below.","title":"Deploy frontend"},{"location":"dci-deploysasviya/#deploy-database","text":"If you have a lot of users, such that concurrency (locked datasets) becomes an issue, you might consider migrating the control library to a database. The first part to this is generating the DDL (and inserts). For this, use the DDL exporter as described here . If you need a flavour of DDL that is not yet supported, contact us . Step 2 is simply to run this DDL in your preferred database. Step 3 is to update the library definition in the $(appLoc)/services/settings.sas file using SAS Studio.","title":"Deploy Database"},{"location":"dci-deploysasviya/#update-compute-context-autoexec","text":"First, open the $(appLoc)/services/settings.sas file in SAS Studio, and copy the code. Then, open SASEnvironment Manager, select Contexts, View Compute Contexts, and open the context we created earlier. Switch to the Advanced tab and paste in the SAS code copied from SAS Studio above. It will look similar to: %let DC_LIBREF=DCDBVIYA; %let DC_ADMIN_GROUP={{YOUR DC ADMIN GROUP}}; %let DC_STAGING_AREA={{YOUR DEDICATED FILE SYSTEM DRIVE}}; libname &dc_libref {{YOUR DC DATABASE}}; To explain each of these lines: DC_LIBREF can be any valid 8 character libref. DC_ADMIN_GROUP is the name of the group which will have unrestricted access to Data Controller DC_STAGING_AREA should point to the location on the filesystem where the staging files and logs are be stored The final libname statement can also be configured to point at a database instead of a BASE engine directory (contact us for DDL) If you have additional libraries that you would like to use in Data Controller, they should also be defined here.","title":"Update Compute Context Autoexec"},{"location":"dci-evaluation/","text":"Data Controller for SAS\u00ae - Evaluation Version \u00b6 Overview \u00b6 A free version of Data Controller is available for evaluation purposes. Compiled into a single SPK, it is very easy to install and configure. However it must not be used in production environments for all the reasons mentioned in the caveats section. Installation \u00b6 Deployment \u00b6 Import \u00b6 Simply import the SPK (using SAS Management Console or Data Integration Studio) to the desired location in the metadata tree. During the import (step 5 of the wizard), be sure to change the location of the library (BASE engine) to a physical directory folder to which the Stored Process system account (eg sassrv ) has write access . Permissions \u00b6 Be sure that the user account you will use in the configuration step below has WRITE METADATA (WM) on the /DataController/services/admin and /DataController/Data folders, and that anyone who will use the app has READ. Configuration \u00b6 Navigate to the web application (eg https://[YOURHOST]/SASStoredProcess?_action=1063 ) and find the location where the app was imported. Then run the DataController/services/admin/configurator stored process. Note Use the same user account as you used to import the SPK, to avoid metadata permissions issues! This may mean logging out / logging back in to the web application. This displays a screen with a choice of SAS Metadata Groups (to which your account belongs) can be chosen. Selecting any of these groups will build / rebuild all the configuration tables (placing logs in a subfolder of the previously configured library location) and provide the chosen group with unrestricted access to the tool. If you do not see any groups, then it is possible your Stored Process is running from a different metadata repository to the location of your SAS users (eg Foundation). To fix this, re-run the configuration stp with the &dc_repo_users=YOURMETAREPO url parameter. Note \"Unrestricted access\" is provided by code logic. Once installed, Data Controller does not ever update or modify metadata. During installation, the services in the /services/admin folder are updated (configuration) or removed (to prevent accidental reinstall). Also the tables are registered in the /Data folder using proc metalib . Usage \u00b6 Simply navigate to the imported location from the Stored Process Web App, right click on the 'clickme' stored process, and open in new window! Caveats \u00b6 The demo version has been optimised for a rapid install, and should not be considered for production / commercial use, or for use by more than 2-5 people, for the following reasons: 1) Static content is compiled into SAS web services, which is inefficient (not scalable) 2) Requires BASE engine for config tables, with high risk of table locks 3) Interface is not licenced for commercial (or production) use, and not supported 4) Underlying macros are not licensed for re-use on other (internal) projects 5) The embedded HandsOnTable library is not licenced for commercial use without a licence key Contact us for a full-featured, fully licenced, scalable and supported deployment of Data Controller at your earliest convenience!","title":"Data Controller for SAS\u00ae - Evaluation Version"},{"location":"dci-evaluation/#data-controller-for-sas-evaluation-version","text":"","title":"Data Controller for SAS\u00ae - Evaluation Version"},{"location":"dci-evaluation/#overview","text":"A free version of Data Controller is available for evaluation purposes. Compiled into a single SPK, it is very easy to install and configure. However it must not be used in production environments for all the reasons mentioned in the caveats section.","title":"Overview"},{"location":"dci-evaluation/#installation","text":"","title":"Installation"},{"location":"dci-evaluation/#deployment","text":"","title":"Deployment"},{"location":"dci-evaluation/#import","text":"Simply import the SPK (using SAS Management Console or Data Integration Studio) to the desired location in the metadata tree. During the import (step 5 of the wizard), be sure to change the location of the library (BASE engine) to a physical directory folder to which the Stored Process system account (eg sassrv ) has write access .","title":"Import"},{"location":"dci-evaluation/#permissions","text":"Be sure that the user account you will use in the configuration step below has WRITE METADATA (WM) on the /DataController/services/admin and /DataController/Data folders, and that anyone who will use the app has READ.","title":"Permissions"},{"location":"dci-evaluation/#configuration","text":"Navigate to the web application (eg https://[YOURHOST]/SASStoredProcess?_action=1063 ) and find the location where the app was imported. Then run the DataController/services/admin/configurator stored process. Note Use the same user account as you used to import the SPK, to avoid metadata permissions issues! This may mean logging out / logging back in to the web application. This displays a screen with a choice of SAS Metadata Groups (to which your account belongs) can be chosen. Selecting any of these groups will build / rebuild all the configuration tables (placing logs in a subfolder of the previously configured library location) and provide the chosen group with unrestricted access to the tool. If you do not see any groups, then it is possible your Stored Process is running from a different metadata repository to the location of your SAS users (eg Foundation). To fix this, re-run the configuration stp with the &dc_repo_users=YOURMETAREPO url parameter. Note \"Unrestricted access\" is provided by code logic. Once installed, Data Controller does not ever update or modify metadata. During installation, the services in the /services/admin folder are updated (configuration) or removed (to prevent accidental reinstall). Also the tables are registered in the /Data folder using proc metalib .","title":"Configuration"},{"location":"dci-evaluation/#usage","text":"Simply navigate to the imported location from the Stored Process Web App, right click on the 'clickme' stored process, and open in new window!","title":"Usage"},{"location":"dci-evaluation/#caveats","text":"The demo version has been optimised for a rapid install, and should not be considered for production / commercial use, or for use by more than 2-5 people, for the following reasons: 1) Static content is compiled into SAS web services, which is inefficient (not scalable) 2) Requires BASE engine for config tables, with high risk of table locks 3) Interface is not licenced for commercial (or production) use, and not supported 4) Underlying macros are not licensed for re-use on other (internal) projects 5) The embedded HandsOnTable library is not licenced for commercial use without a licence key Contact us for a full-featured, fully licenced, scalable and supported deployment of Data Controller at your earliest convenience!","title":"Caveats"},{"location":"dci-requirements/","text":"Data Controller for SAS\u00ae - System Requirements \u00b6 Overview \u00b6 The Data Controller is a SAS Web Application, deployed into an existing SAS platform, and as such has no special requirements beyond what is typically available in a SAS Foundation or Viya environment. SAS 9 \u00b6 Backend \u00b6 A SAS Foundation deployment of at least 9.4M3 must be available. Earlier versions of SAS can be supported, on request. A SAS Stored Process Server must be configured, running under a system account. Mid-Tier \u00b6 A web server with /SASLogon and the SAS SPWA must be available to end users SAS Viya \u00b6 A minimum of Viya 3.5 is recommended to make use of the ability to run a shared compute instance. Frontend \u00b6 All major browsers supported, including IE11 (earlier versions of IE may not work properly). For IE, note that compatibility view must be disabled.","title":"System Requirements"},{"location":"dci-requirements/#data-controller-for-sas-system-requirements","text":"","title":"Data Controller for SAS\u00ae - System Requirements"},{"location":"dci-requirements/#overview","text":"The Data Controller is a SAS Web Application, deployed into an existing SAS platform, and as such has no special requirements beyond what is typically available in a SAS Foundation or Viya environment.","title":"Overview"},{"location":"dci-requirements/#sas-9","text":"","title":"SAS 9"},{"location":"dci-requirements/#backend","text":"A SAS Foundation deployment of at least 9.4M3 must be available. Earlier versions of SAS can be supported, on request. A SAS Stored Process Server must be configured, running under a system account.","title":"Backend"},{"location":"dci-requirements/#mid-tier","text":"A web server with /SASLogon and the SAS SPWA must be available to end users","title":"Mid-Tier"},{"location":"dci-requirements/#sas-viya","text":"A minimum of Viya 3.5 is recommended to make use of the ability to run a shared compute instance.","title":"SAS Viya"},{"location":"dci-requirements/#frontend","text":"All major browsers supported, including IE11 (earlier versions of IE may not work properly). For IE, note that compatibility view must be disabled.","title":"Frontend"},{"location":"dci-stpinstance/","text":"Data Controller for SAS\u00ae - Stored Process Server \u00b6 Overview \u00b6 Data Controller requires that the operating system account (eg sassrv) has the ability to WRITE to each of the libraries set up for editing. For SAS installations where business users have the unrestricted ability to create Stored Processes in production, this can represent a security risk. Under these circumstances, it is recommended to create a dedicated STP server instance for Data Controller, with a dedicated system account. Note Data Controller only updates data (add, delete, modify records). It does not need the ability to create new (permanent) tables, or modify the structure of existing tables. Set up DC account \u00b6 It is recommended to have a user for each environment in which DC is deployed, eg: dcsrv_dev dcsrv_test dcsrv_prod After these OS users are created, log into SMC in relevant environment and open User Manager. Adjust as follows: Open SAS General Servers group Select Accounts tab Add the dcsrv_[ENV] user in DefaultAuth domain STP Server Configuration - 9.4 \u00b6 Open the SAS Deployment Wizard and deploy a new Application Context Server from the panel windows. Be sure to use the relevant dcsrv_[env] user as configured above. Now head to the security section. STP Server Configuration - 9.3 \u00b6 As the wizard does not exist in 9.3 it is necessary to copy the folder structure. Clone existing directory \u00b6 Navigate to the SASApp directory on relevant machine (eg !SASCONFIG/Lev1/SASApp ) and make a copy of the StoredProcessServer folder, and rename it (eg DataControllerSTPsvr). Modify the contents of the new folder as follows: Autoexec (and usermods) \u2013 adjust content to ensure it is relevant to a DC context sasv9_usermods.cfg \u2013 suggested items: - memsize 0 - UTILLOC \u201c/change/only/if/needed\u201d - logconfigloc \"location of DataControllerSTPsvr logconfig.xml file (in new folder)\" The following files should have all instances of \u201c\\StoredProcessServer\\\u201d replaced with \u201c\\DataControllerSTPsvr\\\u201d: Logconfig.xml Logconfig.trace.xml StoredProcessServer.bat Logconfig.apm.xml Sasv9.cfg Dtest folder \u2013 we don\u2019t believe this is used but make the changes anyway (same as above, change all files within it to swap \u201cstoredprocessserver\u201d for DataControllerSTPsvr Sasuser folder \u2013 EMPTY CONTENTS (remove all files). They aren\u2019t relevant in the data controller context. Add Server \u00b6 Open ServerManager and adjust as follows: Log into SMC in relevant environment Open ServerManager Right click / new server Select Application Server Name as \u201cSAS_App_DataController\u201d Click Next / select \u201cStored Process Server\u201d / Next Select \u201cCustom\u201d / Next Command = \u201cC:\\SAS92\\Config\\Lev1\\SASApp\\SASDataEditorStoredProcessServer\\StoredProcessServe r.bat\u201d (adjust as appropriate) Object server parameters = empty Multiuser - select dcsrv_[Env] Choose SASApp server machine (put in RH box) Next / Bridge Connection(default) / Next Bridge Port: 8602 Add / Single Port / 8612 Add / Single Port / 8622 Add / Single Port / 8632 Add at least NINE connections, up to a maximum of (5 per CPU core). Next / finish Next, refresh Server Manager to see the new SAS_App_DataController server. Expand and adjust as follows: Right click SAS_App_DataController-Logical server (first nest), properties, Load Balancing tab, select \u201cResponse Time\u201d Availability timeout \u2013 10 seconds Ok / exit Right click SAS_App_DataController \u2013 Stored Process (second nest), properties, options tab, Advanced options, Load Balancing Max clients 1 Launch timeout \u2013 10 seconds Recycle activation limit \u2013 1 Right click Object Spawner (inside Server Manager) / Properties / Servers, and add the new Data Controller STP from \u201cAvailable Servers\u201d to \u201cSelected Servers\u201d Bounce the object spawner VALIDATION (windows) \u00b6 Open command prompt as an administrator, and run : netstat \u2013aon | find /I \u201c8602\u201d (this will check if the new server is listening on the relevant port) Execute the .bat file to ensure a base sas session can be created in the relevant context ( \u201c!SASConfig\\Lev1\\SASApp\\SASDataEditorStoredProcessServer\\StoredProcessServer.bat\u201d ) In SMC (server manager), right click / validate the new server & test the connection Security \u00b6 STP Server Context \u00b6 To protect the new STP server context, the following initialisation code must be added. This code contains: data _null_; if !('/APPROVED/DC/FOLDER/LOCATION'=:symget('_program')) then do; file _webout; put 'Access to this location has not been approved'; put 'This incident may be reported'; abort cancel; end; run; Save this program in the DataControllerSTPsvr folder. Then open Server Manager in SMC and expand SAS_App_DataController server. Right click SAS_App_DataController-Logical server (first nest), properties, Options tab,Set Server Properties, Request. The init program value should be set to the location of the program above.","title":"SAS 9 Dedicated STP"},{"location":"dci-stpinstance/#data-controller-for-sas-stored-process-server","text":"","title":"Data Controller for SAS\u00ae - Stored Process Server"},{"location":"dci-stpinstance/#overview","text":"Data Controller requires that the operating system account (eg sassrv) has the ability to WRITE to each of the libraries set up for editing. For SAS installations where business users have the unrestricted ability to create Stored Processes in production, this can represent a security risk. Under these circumstances, it is recommended to create a dedicated STP server instance for Data Controller, with a dedicated system account. Note Data Controller only updates data (add, delete, modify records). It does not need the ability to create new (permanent) tables, or modify the structure of existing tables.","title":"Overview"},{"location":"dci-stpinstance/#set-up-dc-account","text":"It is recommended to have a user for each environment in which DC is deployed, eg: dcsrv_dev dcsrv_test dcsrv_prod After these OS users are created, log into SMC in relevant environment and open User Manager. Adjust as follows: Open SAS General Servers group Select Accounts tab Add the dcsrv_[ENV] user in DefaultAuth domain","title":"Set up DC account"},{"location":"dci-stpinstance/#stp-server-configuration-94","text":"Open the SAS Deployment Wizard and deploy a new Application Context Server from the panel windows. Be sure to use the relevant dcsrv_[env] user as configured above. Now head to the security section.","title":"STP Server Configuration - 9.4"},{"location":"dci-stpinstance/#stp-server-configuration-93","text":"As the wizard does not exist in 9.3 it is necessary to copy the folder structure.","title":"STP Server Configuration - 9.3"},{"location":"dci-stpinstance/#clone-existing-directory","text":"Navigate to the SASApp directory on relevant machine (eg !SASCONFIG/Lev1/SASApp ) and make a copy of the StoredProcessServer folder, and rename it (eg DataControllerSTPsvr). Modify the contents of the new folder as follows: Autoexec (and usermods) \u2013 adjust content to ensure it is relevant to a DC context sasv9_usermods.cfg \u2013 suggested items: - memsize 0 - UTILLOC \u201c/change/only/if/needed\u201d - logconfigloc \"location of DataControllerSTPsvr logconfig.xml file (in new folder)\" The following files should have all instances of \u201c\\StoredProcessServer\\\u201d replaced with \u201c\\DataControllerSTPsvr\\\u201d: Logconfig.xml Logconfig.trace.xml StoredProcessServer.bat Logconfig.apm.xml Sasv9.cfg Dtest folder \u2013 we don\u2019t believe this is used but make the changes anyway (same as above, change all files within it to swap \u201cstoredprocessserver\u201d for DataControllerSTPsvr Sasuser folder \u2013 EMPTY CONTENTS (remove all files). They aren\u2019t relevant in the data controller context.","title":"Clone existing directory"},{"location":"dci-stpinstance/#add-server","text":"Open ServerManager and adjust as follows: Log into SMC in relevant environment Open ServerManager Right click / new server Select Application Server Name as \u201cSAS_App_DataController\u201d Click Next / select \u201cStored Process Server\u201d / Next Select \u201cCustom\u201d / Next Command = \u201cC:\\SAS92\\Config\\Lev1\\SASApp\\SASDataEditorStoredProcessServer\\StoredProcessServe r.bat\u201d (adjust as appropriate) Object server parameters = empty Multiuser - select dcsrv_[Env] Choose SASApp server machine (put in RH box) Next / Bridge Connection(default) / Next Bridge Port: 8602 Add / Single Port / 8612 Add / Single Port / 8622 Add / Single Port / 8632 Add at least NINE connections, up to a maximum of (5 per CPU core). Next / finish Next, refresh Server Manager to see the new SAS_App_DataController server. Expand and adjust as follows: Right click SAS_App_DataController-Logical server (first nest), properties, Load Balancing tab, select \u201cResponse Time\u201d Availability timeout \u2013 10 seconds Ok / exit Right click SAS_App_DataController \u2013 Stored Process (second nest), properties, options tab, Advanced options, Load Balancing Max clients 1 Launch timeout \u2013 10 seconds Recycle activation limit \u2013 1 Right click Object Spawner (inside Server Manager) / Properties / Servers, and add the new Data Controller STP from \u201cAvailable Servers\u201d to \u201cSelected Servers\u201d Bounce the object spawner","title":"Add Server"},{"location":"dci-stpinstance/#validation-windows","text":"Open command prompt as an administrator, and run : netstat \u2013aon | find /I \u201c8602\u201d (this will check if the new server is listening on the relevant port) Execute the .bat file to ensure a base sas session can be created in the relevant context ( \u201c!SASConfig\\Lev1\\SASApp\\SASDataEditorStoredProcessServer\\StoredProcessServer.bat\u201d ) In SMC (server manager), right click / validate the new server & test the connection","title":"VALIDATION (windows)"},{"location":"dci-stpinstance/#security","text":"","title":"Security"},{"location":"dci-stpinstance/#stp-server-context","text":"To protect the new STP server context, the following initialisation code must be added. This code contains: data _null_; if !('/APPROVED/DC/FOLDER/LOCATION'=:symget('_program')) then do; file _webout; put 'Access to this location has not been approved'; put 'This incident may be reported'; abort cancel; end; run; Save this program in the DataControllerSTPsvr folder. Then open Server Manager in SMC and expand SAS_App_DataController server. Right click SAS_App_DataController-Logical server (first nest), properties, Options tab,Set Server Properties, Request. The init program value should be set to the location of the program above.","title":"STP Server Context"},{"location":"dci-troubleshooting/","text":"Data Controller for SAS\u00ae - Troubleshooting \u00b6 Overview \u00b6 Let us know if you experience an installation problem that is not described here! Internet Explorer - blank screen \u00b6 If you have an older, or 'locked down' version of Internet Explorer you may get a blank / white screen when navigating to the Data Controller url. To fix this, click settings (cog icon in top right), Compatibility View settings , and uncheck Display intranet sites in Compatibility view as follows: Workspace Server Type Only \u00b6 Data Controller requires the OS account to have disk write privileges for a number of reasons: log capture folder creation (initial setup) table creation (demo version) writing staging data (editors) updating databases / datasets (approvers) On Viya, this is the default case. On SAS 9, if your Stored Process Shared Server account (typically sassrv ) is unavailable, or overly restricted, you may need to use a Workspace Server account for your STPs. This means that your Approvers must have the requisite access to perform the database updates. The imported version of Data Controller is set up to work with the Stored Process Server. To switch this to Workspace Server, you can run the following code after importing the SPK: /* get the macros (or download / %include seperately) */ filename mc url \"https://raw.githubusercontent.com/sasjs/core/main/all.sas\"; %inc mc; /* put the path to your Data Controller folder here */ %let DCROOT=/YOUR/META/PATH/DataController; /* this will extract all the objects in that folder */ %mm_getfoldertree(root=&dcroot, outds=stps) /* this creates the program to update all the STPs in that folder */ filename tmp temp; data _null_; set stps; file tmp; if publictype='StoredProcess' then do; str=cats('%mm_updatestpservertype(target=' ,path,'/',name,',type=WKS)'); put str; end; run; /* run the program */ %inc tmp; Custom Library \u00b6 If you wish to change the default libref or libname then there are TWO items to configure: 1) The library itself 2) The mpelib macro variable and the libname statement in the /Admin/Data_Controller_Settings stored process. Note Be sure to make this change after running the configurator, to ensure the tables are first registered! Permission is needed to access the ServerContext Object \u00b6 After a successful install, your business user may see the following message: Error obtaining stored process from repository Permission is needed to access the ServerContext object attached to the stored process. The reason is that the context chosen when importing the SPK (perhaps, SASApp) is not available to your business user. It's likely you have multiple contexts. The SPK must be re-imported with the correct context chosen. This may require regenerating the tables, or adjusting the permissions, if the new context uses a different system account. Stored Processes Cannot Be Imported Into A Project Repository \u00b6 During the SPK import on a SAS 9 instance you may see the following dialog: Stored processes cannot be imported into a project repository This can happen when importing with Data Integration Studio and your user profile is making use of a personal project repository. Try re-connecting with the Foundation repository, or import with SAS Management Console (which does not support project repositories). There is no LogicalServer of the type requested associated with the ServerContext in metadata. \u00b6 This can happen if you enter the wrong serverName when deploying the SAS program on an EBI platform. Make sure it matches an existing Stored Process Server Context.","title":"Troubleshooting"},{"location":"dci-troubleshooting/#data-controller-for-sas-troubleshooting","text":"","title":"Data Controller for SAS\u00ae - Troubleshooting"},{"location":"dci-troubleshooting/#overview","text":"Let us know if you experience an installation problem that is not described here!","title":"Overview"},{"location":"dci-troubleshooting/#internet-explorer-blank-screen","text":"If you have an older, or 'locked down' version of Internet Explorer you may get a blank / white screen when navigating to the Data Controller url. To fix this, click settings (cog icon in top right), Compatibility View settings , and uncheck Display intranet sites in Compatibility view as follows:","title":"Internet Explorer - blank screen"},{"location":"dci-troubleshooting/#workspace-server-type-only","text":"Data Controller requires the OS account to have disk write privileges for a number of reasons: log capture folder creation (initial setup) table creation (demo version) writing staging data (editors) updating databases / datasets (approvers) On Viya, this is the default case. On SAS 9, if your Stored Process Shared Server account (typically sassrv ) is unavailable, or overly restricted, you may need to use a Workspace Server account for your STPs. This means that your Approvers must have the requisite access to perform the database updates. The imported version of Data Controller is set up to work with the Stored Process Server. To switch this to Workspace Server, you can run the following code after importing the SPK: /* get the macros (or download / %include seperately) */ filename mc url \"https://raw.githubusercontent.com/sasjs/core/main/all.sas\"; %inc mc; /* put the path to your Data Controller folder here */ %let DCROOT=/YOUR/META/PATH/DataController; /* this will extract all the objects in that folder */ %mm_getfoldertree(root=&dcroot, outds=stps) /* this creates the program to update all the STPs in that folder */ filename tmp temp; data _null_; set stps; file tmp; if publictype='StoredProcess' then do; str=cats('%mm_updatestpservertype(target=' ,path,'/',name,',type=WKS)'); put str; end; run; /* run the program */ %inc tmp;","title":"Workspace Server Type Only"},{"location":"dci-troubleshooting/#custom-library","text":"If you wish to change the default libref or libname then there are TWO items to configure: 1) The library itself 2) The mpelib macro variable and the libname statement in the /Admin/Data_Controller_Settings stored process. Note Be sure to make this change after running the configurator, to ensure the tables are first registered!","title":"Custom Library"},{"location":"dci-troubleshooting/#permission-is-needed-to-access-the-servercontext-object","text":"After a successful install, your business user may see the following message: Error obtaining stored process from repository Permission is needed to access the ServerContext object attached to the stored process. The reason is that the context chosen when importing the SPK (perhaps, SASApp) is not available to your business user. It's likely you have multiple contexts. The SPK must be re-imported with the correct context chosen. This may require regenerating the tables, or adjusting the permissions, if the new context uses a different system account.","title":"Permission is needed to access the ServerContext Object"},{"location":"dci-troubleshooting/#stored-processes-cannot-be-imported-into-a-project-repository","text":"During the SPK import on a SAS 9 instance you may see the following dialog: Stored processes cannot be imported into a project repository This can happen when importing with Data Integration Studio and your user profile is making use of a personal project repository. Try re-connecting with the Foundation repository, or import with SAS Management Console (which does not support project repositories).","title":"Stored Processes Cannot Be Imported Into A Project Repository"},{"location":"dci-troubleshooting/#there-is-no-logicalserver-of-the-type-requested-associated-with-the-servercontext-in-metadata","text":"This can happen if you enter the wrong serverName when deploying the SAS program on an EBI platform. Make sure it matches an existing Stored Process Server Context.","title":"There is no LogicalServer of the type requested associated with the ServerContext in metadata."},{"location":"dcu-datacatalog/","text":"Data Controller for SAS: Data Catalog \u00b6 Data Controller collects information about the size and shape of the tables and columns. The Catalog does not contain information about the data content (values). The catalog is based primarily on the existing SAS dictionary tables, augmented with attributes such as primary key fields, filesize / libsize, and number of observations (eg for database tables). Frequently changing data (such as nobs, size) are stored on the MPE_DATASTATUS_XXX tables. The rest is stored on the MPE_DATACATALOG_XXX tables. Tables \u00b6 Libraries \u00b6 This table contains library level attributes to provide a high level overview of data coverage. Note that unless you are an administrator, you are unlikely to have the ability to view / open all of these libraries. To avoid errors when opening invalid libraries, you can add pipe-separated LIBREFs to the DCXXXX.MPE_CONFIG table (var_scope='DC_CATALOG', var_name='DC_IGNORELIBS'). Tables \u00b6 Table attributes are split between those that change infrequently (eg PK_FIELDS) and those that change often (eg size, modified date, and NOBS). Variables \u00b6 Variable attributes come from dictionary tables with an extra PK indicator. A PK is identified by the fact the variable is within an index that is both UNIQUE and NOTNULL. Variable names are always uppercase. Assumptions \u00b6 The following assumptions are made: Data Models (eg attributes) are not sensitive. If so the catalog tables should be disabled. Users can see all tables in the libraries they can access. The refresh process will close out any tables that are not found, if the user can see at least one table in a library. For a particular site, libraries are unique on LIBREF. If you have duplicate librefs, specific table security setups, or sensitive models - contact us.","title":"Data Catalog"},{"location":"dcu-datacatalog/#data-controller-for-sas-data-catalog","text":"Data Controller collects information about the size and shape of the tables and columns. The Catalog does not contain information about the data content (values). The catalog is based primarily on the existing SAS dictionary tables, augmented with attributes such as primary key fields, filesize / libsize, and number of observations (eg for database tables). Frequently changing data (such as nobs, size) are stored on the MPE_DATASTATUS_XXX tables. The rest is stored on the MPE_DATACATALOG_XXX tables.","title":"Data Controller for SAS: Data Catalog"},{"location":"dcu-datacatalog/#tables","text":"","title":"Tables"},{"location":"dcu-datacatalog/#libraries","text":"This table contains library level attributes to provide a high level overview of data coverage. Note that unless you are an administrator, you are unlikely to have the ability to view / open all of these libraries. To avoid errors when opening invalid libraries, you can add pipe-separated LIBREFs to the DCXXXX.MPE_CONFIG table (var_scope='DC_CATALOG', var_name='DC_IGNORELIBS').","title":"Libraries"},{"location":"dcu-datacatalog/#tables_1","text":"Table attributes are split between those that change infrequently (eg PK_FIELDS) and those that change often (eg size, modified date, and NOBS).","title":"Tables"},{"location":"dcu-datacatalog/#variables","text":"Variable attributes come from dictionary tables with an extra PK indicator. A PK is identified by the fact the variable is within an index that is both UNIQUE and NOTNULL. Variable names are always uppercase.","title":"Variables"},{"location":"dcu-datacatalog/#assumptions","text":"The following assumptions are made: Data Models (eg attributes) are not sensitive. If so the catalog tables should be disabled. Users can see all tables in the libraries they can access. The refresh process will close out any tables that are not found, if the user can see at least one table in a library. For a particular site, libraries are unique on LIBREF. If you have duplicate librefs, specific table security setups, or sensitive models - contact us.","title":"Assumptions"},{"location":"dcu-fileupload/","text":"Data Controller for SAS: File Uploads \u00b6 Files can be uploaded via the Editor interface - first choose the library and table, then click \"Upload\". All versions of excel are supported. Uploaded data may optionally contain a column named _____DELETE__THIS__RECORD_____ - where this contains the value \"Yes\" the row is marked for deletion. If loading very large files (eg over 10mb) it is more efficient to use CSV format, as this bypasses the local rendering engine, but also the local DQ checks - so be careful! Examples of local (excel) but not remote (CSV) file checks include: Length of character variables - CSV files are truncated at the max target column length Length of numeric variables - if the target numeric variable is below 8 bytes then the staged CSV value may be rounded if it is too large to fit NOTNULL - this rule is only applied at backend when the constraint is physical (rather than a DC setting) MINVAL MAXVAL CASE Note that the HARDSELECT_*** hooks are not applied to the rendered Excel values (they are currently only applied when editing a cell). Excel Uploads \u00b6 Thanks to our pro license of sheetJS , we can support all versions of excel, large workbooks, and extract data extremely fast. We also support the ingest of password-protected workbooks . The rules for data extraction are: Scan the spreadsheet until a row is found with all the target columns (not case sensitive) Extract data below until the first row containing a blank primary key value This is incredibly flexible, and means: data can be anywhere, on any worksheet data can contain additional columns (they are just ignored) data can be completely surrounded by other data A copy of the original Excel file is also uploaded to the staging area. This means that a complete audit trail can be captured, right back to the original source data. Note If the excel contains more than one range with the target columns (eg, on different sheets), only the FIRST will be extracted. CSV Uploads \u00b6 The following should be considered when uploading data in this way: A header row (with variable names) is required Variable names must match those in the target table (not case sensitive). An easy way to ensure this is to download the data from Viewer and use this as a template. Duplicate variable names are not permitted Missing columns are not permitted Additional columns are ignored The order of variables does not matter EXCEPT for the (optional) _____DELETE__THIS__RECORD_____ variable. When using this variable, it must be the first . The delimiter is extracted from the header row - so for var1;var2;var3 the delimeter would be assumed to be a semicolon The above assumes the delimiter is the first special character! So var,1;var2;var3 would fail The following characters should not be used as delimiters doublequote quote space underscore When loading dates, be aware that Data Controller makes use of the ANYDTDTE and ANYDTDTTME informats (width 19). This means that uploaded date / datetime values should be unambiguous (eg 01FEB1942 vs 01/02/42 ), to avoid confusion - as the latter could be interpreted as 02JAN2042 depending on your locale and options YEARCUTOFF settings. Note that UTC dates with offset values (eg 2018-12-26T09:19:25.123+0100 ) are not currently supported. If this is a feature you would like to see, contact us. Tip To get a copy of a file in the right format for upload, use the file download feature in the Viewer tab Warning Lengths are taken from the target table. If a CSV contains long strings (eg \"ABCDE\" for a $3 variable) then the rest will be silently truncated (only \"ABC\" staged and loaded). If the target variable is a short numeric (eg 4., or 4 bytes) then floats or large integers may be rounded. This issue does not apply to excel uploads, which are first validated in the browser.","title":"File Uploads"},{"location":"dcu-fileupload/#data-controller-for-sas-file-uploads","text":"Files can be uploaded via the Editor interface - first choose the library and table, then click \"Upload\". All versions of excel are supported. Uploaded data may optionally contain a column named _____DELETE__THIS__RECORD_____ - where this contains the value \"Yes\" the row is marked for deletion. If loading very large files (eg over 10mb) it is more efficient to use CSV format, as this bypasses the local rendering engine, but also the local DQ checks - so be careful! Examples of local (excel) but not remote (CSV) file checks include: Length of character variables - CSV files are truncated at the max target column length Length of numeric variables - if the target numeric variable is below 8 bytes then the staged CSV value may be rounded if it is too large to fit NOTNULL - this rule is only applied at backend when the constraint is physical (rather than a DC setting) MINVAL MAXVAL CASE Note that the HARDSELECT_*** hooks are not applied to the rendered Excel values (they are currently only applied when editing a cell).","title":"Data Controller for SAS: File Uploads"},{"location":"dcu-fileupload/#excel-uploads","text":"Thanks to our pro license of sheetJS , we can support all versions of excel, large workbooks, and extract data extremely fast. We also support the ingest of password-protected workbooks . The rules for data extraction are: Scan the spreadsheet until a row is found with all the target columns (not case sensitive) Extract data below until the first row containing a blank primary key value This is incredibly flexible, and means: data can be anywhere, on any worksheet data can contain additional columns (they are just ignored) data can be completely surrounded by other data A copy of the original Excel file is also uploaded to the staging area. This means that a complete audit trail can be captured, right back to the original source data. Note If the excel contains more than one range with the target columns (eg, on different sheets), only the FIRST will be extracted.","title":"Excel Uploads"},{"location":"dcu-fileupload/#csv-uploads","text":"The following should be considered when uploading data in this way: A header row (with variable names) is required Variable names must match those in the target table (not case sensitive). An easy way to ensure this is to download the data from Viewer and use this as a template. Duplicate variable names are not permitted Missing columns are not permitted Additional columns are ignored The order of variables does not matter EXCEPT for the (optional) _____DELETE__THIS__RECORD_____ variable. When using this variable, it must be the first . The delimiter is extracted from the header row - so for var1;var2;var3 the delimeter would be assumed to be a semicolon The above assumes the delimiter is the first special character! So var,1;var2;var3 would fail The following characters should not be used as delimiters doublequote quote space underscore When loading dates, be aware that Data Controller makes use of the ANYDTDTE and ANYDTDTTME informats (width 19). This means that uploaded date / datetime values should be unambiguous (eg 01FEB1942 vs 01/02/42 ), to avoid confusion - as the latter could be interpreted as 02JAN2042 depending on your locale and options YEARCUTOFF settings. Note that UTC dates with offset values (eg 2018-12-26T09:19:25.123+0100 ) are not currently supported. If this is a feature you would like to see, contact us. Tip To get a copy of a file in the right format for upload, use the file download feature in the Viewer tab Warning Lengths are taken from the target table. If a CSV contains long strings (eg \"ABCDE\" for a $3 variable) then the rest will be silently truncated (only \"ABC\" staged and loaded). If the target variable is a short numeric (eg 4., or 4 bytes) then floats or large integers may be rounded. This issue does not apply to excel uploads, which are first validated in the browser.","title":"CSV Uploads"},{"location":"dcu-lineage/","text":"Data Lineage \u00b6 The Data Lineage feature is available for SAS 9 installs. The implementation differs depending on whether the lineage is table level or column level. Table Level lineage \u00b6 Table level lineage is relatively straightforward, and so it is extracted in a single ad-hoc proc metadata call and stored in the DATACTRL.MPE_LINEAGE_TABS table. To trigger the population (or refresh) of this table, simply execute the YOURSERVER/SASStoredProcess/?_program={appLoc}/DataController/admin/refreshtablelineage service from a browser. This data is stored with SCD2 so it is possible to track changes to lineage over time. When users execute table level lineage, queries are made against this table, so there is very little metadata impact. Column Level lineage \u00b6 Column level lineage is more complex as it also includes all the different transforms, and calculation logic along the way. For this reason it is performed at runtime, which means the initial request can take some time if there is a lot of lineage. After the first request, subsequent lineage requests (for that particular column and direction) are cached in the DATACTRL.MPE_LINEAGE_COLS table for faster response times. If the job is changed and a new diagram is needed, the user can click the 'refresh' checkbox. Export Types \u00b6 Both Table and column level lineage pages allow the following export formats: SVG - high res digram format PNG - image format DOT - the graphviz language format used to generate the diagram CSV - a download of all the sources and targets in the diagram","title":"Data Lineage"},{"location":"dcu-lineage/#data-lineage","text":"The Data Lineage feature is available for SAS 9 installs. The implementation differs depending on whether the lineage is table level or column level.","title":"Data Lineage"},{"location":"dcu-lineage/#table-level-lineage","text":"Table level lineage is relatively straightforward, and so it is extracted in a single ad-hoc proc metadata call and stored in the DATACTRL.MPE_LINEAGE_TABS table. To trigger the population (or refresh) of this table, simply execute the YOURSERVER/SASStoredProcess/?_program={appLoc}/DataController/admin/refreshtablelineage service from a browser. This data is stored with SCD2 so it is possible to track changes to lineage over time. When users execute table level lineage, queries are made against this table, so there is very little metadata impact.","title":"Table Level lineage"},{"location":"dcu-lineage/#column-level-lineage","text":"Column level lineage is more complex as it also includes all the different transforms, and calculation logic along the way. For this reason it is performed at runtime, which means the initial request can take some time if there is a lot of lineage. After the first request, subsequent lineage requests (for that particular column and direction) are cached in the DATACTRL.MPE_LINEAGE_COLS table for faster response times. If the job is changed and a new diagram is needed, the user can click the 'refresh' checkbox.","title":"Column Level lineage"},{"location":"dcu-lineage/#export-types","text":"Both Table and column level lineage pages allow the following export formats: SVG - high res digram format PNG - image format DOT - the graphviz language format used to generate the diagram CSV - a download of all the sources and targets in the diagram","title":"Export Types"},{"location":"dcu-tableviewer/","text":"Data Controller for SAS: Viewer \u00b6 The viewer screen provides a raw view of the underlying table. Choose a library, then a table, and click view to see the first 5000 rows. A filter option is provided should you wish to view a different section of rows. The following libraries will be visible: All libraries available on startup (session autoexec) Any libraries configured in the services/public/[Data_Controller_Settings/settings] Stored Process / Viya Job All libraries available to the logged in user in metadata (SAS 9 only) Row and Column level security can also be applied in VIEW mode, as can additional table-level permissions (MPE_SECURITY table). Full Table Search \u00b6 A single search box can be used to make a full table search on any character or numeric value, using this macro . Options \u00b6 This button shows a range of options. If the table is editable, you will also see a EDIT option. Download \u00b6 The Download button gives several options for obtaining the current view of data: 1) CSV. This provides a comma delimited file. 2) Excel. This provides a tab delimited file. 3) SAS Datalines. This provides a SAS program with data as datalines, so that the data can be rebuilt as a SAS table. 4) SAS DDL. A download of a DDL file using SAS flavoured syntax. 5) TSQL DDL. A DDL download using SQL Server flavoured syntax. Note - if the table is registered in Data Controller as being TXTEMPORAL (SCD2) then the download option will prefilter for the current records and removes the valid from / valid to variables. This makes the CSV suitable for DC file upload, if desired. Web Query URL \u00b6 This option gives you a URL that can be used to import data directly into third party tools such as Power BI or Microsoft Excel (as a \"web query\"). You can set up a filter, eg for a particular month, and refresh the query on demand using client tooling such as VBA.","title":"Table Viewer"},{"location":"dcu-tableviewer/#data-controller-for-sas-viewer","text":"The viewer screen provides a raw view of the underlying table. Choose a library, then a table, and click view to see the first 5000 rows. A filter option is provided should you wish to view a different section of rows. The following libraries will be visible: All libraries available on startup (session autoexec) Any libraries configured in the services/public/[Data_Controller_Settings/settings] Stored Process / Viya Job All libraries available to the logged in user in metadata (SAS 9 only) Row and Column level security can also be applied in VIEW mode, as can additional table-level permissions (MPE_SECURITY table).","title":"Data Controller for SAS: Viewer"},{"location":"dcu-tableviewer/#full-table-search","text":"A single search box can be used to make a full table search on any character or numeric value, using this macro .","title":"Full Table Search"},{"location":"dcu-tableviewer/#options","text":"This button shows a range of options. If the table is editable, you will also see a EDIT option.","title":"Options"},{"location":"dcu-tableviewer/#download","text":"The Download button gives several options for obtaining the current view of data: 1) CSV. This provides a comma delimited file. 2) Excel. This provides a tab delimited file. 3) SAS Datalines. This provides a SAS program with data as datalines, so that the data can be rebuilt as a SAS table. 4) SAS DDL. A download of a DDL file using SAS flavoured syntax. 5) TSQL DDL. A DDL download using SQL Server flavoured syntax. Note - if the table is registered in Data Controller as being TXTEMPORAL (SCD2) then the download option will prefilter for the current records and removes the valid from / valid to variables. This makes the CSV suitable for DC file upload, if desired.","title":"Download"},{"location":"dcu-tableviewer/#web-query-url","text":"This option gives you a URL that can be used to import data directly into third party tools such as Power BI or Microsoft Excel (as a \"web query\"). You can set up a filter, eg for a particular month, and refresh the query on demand using client tooling such as VBA.","title":"Web Query URL"},{"location":"dynamic-cell-dropdown/","text":"Dynamic Cell Dropdown \u00b6 This is a simple, but incredibly powerful feature! Configure a SAS process to run when clicking a particular cell. Data Controller will send the row to SAS, and your SAS program can use the values in the row determine a column of values to send back - which will be used in the frontend selectbox. So if you'd like the user to only see products for a particular category, or ISIN's for a particular asset group, you can perform that easily. This feature is used extensively in Data Controller to fetch tables specific to a library, or columns specific to a table: You can also use the response to populate other dropdowns (also in the same row) in the same request - these are called 'extended validations'. Frontend Configuration \u00b6 Open the MPE_VALIDATIONS table and configure the library, table and column that should contain the selectbox. In the RULE_TYPE column, enter either: HARDSELECT_HOOK - The user entry MUST match the returned values SOFTSELECT_HOOK - The user can view the list but type something else if they wish The RULE_VALUE column should contain the full path to the SAS Program, Viya Job or SAS 9 Stored process that you would like to execute. If the value ends in \".sas\" then it is assumed to be a SAS program on a directory, otherwise a SAS web service (STP or Viya Job). Backend Configuration \u00b6 If creating a Stored Process, be sure to deselect the 'automatic SAS macros' - the presence of %stpbegin or %stpend autocall macros will cause problems with the Data Controller backend. You can write any SAS code you wish. For examples of hook scripts you can look at the Data Controller internal validation programs (listed in the MPE_VALIDATIONS table). You will receive the following as inputs: work.source_row -> A dataset containing the current row being modified in Data Controller. This will have already been created in the current SAS session. All variables are available. Use this to filter the initial values in work.dynamic_values . &DC_LIBREF -> The DC control library &LIBDS - The library.dataset being filtered &VARIABLE_NM - The column for which to supply the validation The following tables should be created in the WORK library as outputs: work.dynamic_values work.dynamic_extended_values (optional) WORK.DYNAMIC_VALUES \u00b6 This output table can contain up to three columns: display_index (optional, mandatory if using dynamic_extended_values ). Is a numeric key used to join the two tables. display_value - always character raw_value - unformatted character or numeric according to source data type Example values: DISPLAY_INDEX:best. DISPLAY_VALUE:$ RAW_VALUE 1 $77.43 77.43 2 $88.43 88.43 WORK.DYNAMIC_EXTENDED_VALUES \u00b6 This output table is optional. If provided, it will map the DISPLAY_INDEX from the DYNAMIC_VALUES table to additional column/value pairs, that will be used to populate dropdowns for other cells in the same row. The following columns should be provided: display_index - a numeric key joining each value to the dynamic_values table extra_col_name - the name of the additional variable(s) to contain the extra dropdown(s) display_value - the value to display in the dropdown. Always character. display_type - Either C or N depending on the raw value type raw_value_num - The unformatted value if numeric raw_value_char - The unformatted value if character forced_value - set to 1 to force this value to be automatically selected when the source value is changed. If anything else but 1, the dropdown will still appear, but the user must manually make the selection. Example Values: DISPLAY_INDEX:best. EXTRA_COL_NAME:$32 DISPLAY_VALUE:$ DISPLAY_TYPE:$1. RAW_VALUE_NUM RAW_VALUE_CHAR:$5000 FORCED_VALUE 1 DISCOUNT_RT \"50%\" N 0.5 . 1 DISCOUNT_RT \"40%\" N 0.4 0 1 DISCOUNT_RT \"30%\" N 0.3 1 1 CURRENCY_SYMBOL \"GBP\" C \"GBP\" . 1 CURRENCY_SYMBOL \"RSD\" C \"RSD\" . 2 DISCOUNT_RT \"50%\" N 0.5 . 2 DISCOUNT_RT \"40%\" N 0.4 1 2 CURRENCY_SYMBOL \"EUR\" C \"EUR\" . 2 CURRENCY_SYMBOL \"HKD\" C \"HKD\" 1 Code Examples \u00b6 Simple dropdown /** @file @brief Simple dynamic cell dropdown for product code @details The input table is simply one row from the target table called \"work.source_row\". Available macro variables: @li DC_LIBREF - The DC control library @li LIBDS - The library.dataset being filtered @li VARIABLE_NM - The column being filtered <h4> Service Outputs </h4> Output should be a single table called \"work.dynamic_values\" in the format below. |DISPLAY_VALUE:$|RAW_VALUE:??| |---|---| |$44.00|44| **/ %dc_assignlib (READ,mylibref) proc sql; create table work . DYNAMIC_VALUES as select distinct some_product as raw_value from mylibref . my_other_table where area in ( select area from work . source_row) order by 1 ; Extended dropdown proc sql; create table work . source as select libref,dsn from &DC_LIBREF. .MPE_TABLES where tx_to > \"%sysfunc(datetime(),E8601DT26.6)\" dt order by 1 , 2 ; data work . DYNAMIC_VALUES ( keep =display_index raw_value display_value); set work . source end =last; by libref; if last . libref then do ; display_index +1 ; raw_value=libref; display_value=libref; output ; end ; if last then do ; display_index +1 ; raw_value= '*ALL*' ; display_value= '*ALL*' ; output ; end ; run; data work . dynamic_extended_values( keep =display_index extra_col_name display_type display_value RAW_VALUE_CHAR raw_value_num forced_value); set work . source end =last; by libref dsn; retain extra_col_name 'ALERT_DS' ; retain display_type 'C' ; retain raw_value_num .; raw_value_char=dsn; display_value=dsn; forced_value= 0 ; if first . libref then display_index +1 ; if last . libref then do ; display_value= '*ALL*' ; raw_value_char= '*ALL*' ; forced_value= 1 ; output ; end ; else output ; if last then do ; display_value= '*ALL*' ; raw_value_char= '*ALL*' ; forced_value= 1 ; output ; end ; run; Technical Notes \u00b6 When first clicking on a 'dynamic dropdown' cell, the frontend will first hash the entire row, and store the subsequent response from SAS against this hash in an internal lookup table. In this way, the lookup table can be subsequently referenced to vastly improve performance (by avoiding unnecessary server requests). The lookup event will occur immediately upon clicking on the (dynamic dropdown) cell. If the row has not changed since the previous click, the response will be instant. If any value in the row HAS changed, and that particular combination of values has not previously been requested (in the same browser session), then a request to SAS will need to take place before the dropdown values are shown.","title":"Dynamic Cell Dropdown"},{"location":"dynamic-cell-dropdown/#dynamic-cell-dropdown","text":"This is a simple, but incredibly powerful feature! Configure a SAS process to run when clicking a particular cell. Data Controller will send the row to SAS, and your SAS program can use the values in the row determine a column of values to send back - which will be used in the frontend selectbox. So if you'd like the user to only see products for a particular category, or ISIN's for a particular asset group, you can perform that easily. This feature is used extensively in Data Controller to fetch tables specific to a library, or columns specific to a table: You can also use the response to populate other dropdowns (also in the same row) in the same request - these are called 'extended validations'.","title":"Dynamic Cell Dropdown"},{"location":"dynamic-cell-dropdown/#frontend-configuration","text":"Open the MPE_VALIDATIONS table and configure the library, table and column that should contain the selectbox. In the RULE_TYPE column, enter either: HARDSELECT_HOOK - The user entry MUST match the returned values SOFTSELECT_HOOK - The user can view the list but type something else if they wish The RULE_VALUE column should contain the full path to the SAS Program, Viya Job or SAS 9 Stored process that you would like to execute. If the value ends in \".sas\" then it is assumed to be a SAS program on a directory, otherwise a SAS web service (STP or Viya Job).","title":"Frontend Configuration"},{"location":"dynamic-cell-dropdown/#backend-configuration","text":"If creating a Stored Process, be sure to deselect the 'automatic SAS macros' - the presence of %stpbegin or %stpend autocall macros will cause problems with the Data Controller backend. You can write any SAS code you wish. For examples of hook scripts you can look at the Data Controller internal validation programs (listed in the MPE_VALIDATIONS table). You will receive the following as inputs: work.source_row -> A dataset containing the current row being modified in Data Controller. This will have already been created in the current SAS session. All variables are available. Use this to filter the initial values in work.dynamic_values . &DC_LIBREF -> The DC control library &LIBDS - The library.dataset being filtered &VARIABLE_NM - The column for which to supply the validation The following tables should be created in the WORK library as outputs: work.dynamic_values work.dynamic_extended_values (optional)","title":"Backend Configuration"},{"location":"dynamic-cell-dropdown/#workdynamic_values","text":"This output table can contain up to three columns: display_index (optional, mandatory if using dynamic_extended_values ). Is a numeric key used to join the two tables. display_value - always character raw_value - unformatted character or numeric according to source data type Example values: DISPLAY_INDEX:best. DISPLAY_VALUE:$ RAW_VALUE 1 $77.43 77.43 2 $88.43 88.43","title":"WORK.DYNAMIC_VALUES"},{"location":"dynamic-cell-dropdown/#workdynamic_extended_values","text":"This output table is optional. If provided, it will map the DISPLAY_INDEX from the DYNAMIC_VALUES table to additional column/value pairs, that will be used to populate dropdowns for other cells in the same row. The following columns should be provided: display_index - a numeric key joining each value to the dynamic_values table extra_col_name - the name of the additional variable(s) to contain the extra dropdown(s) display_value - the value to display in the dropdown. Always character. display_type - Either C or N depending on the raw value type raw_value_num - The unformatted value if numeric raw_value_char - The unformatted value if character forced_value - set to 1 to force this value to be automatically selected when the source value is changed. If anything else but 1, the dropdown will still appear, but the user must manually make the selection. Example Values: DISPLAY_INDEX:best. EXTRA_COL_NAME:$32 DISPLAY_VALUE:$ DISPLAY_TYPE:$1. RAW_VALUE_NUM RAW_VALUE_CHAR:$5000 FORCED_VALUE 1 DISCOUNT_RT \"50%\" N 0.5 . 1 DISCOUNT_RT \"40%\" N 0.4 0 1 DISCOUNT_RT \"30%\" N 0.3 1 1 CURRENCY_SYMBOL \"GBP\" C \"GBP\" . 1 CURRENCY_SYMBOL \"RSD\" C \"RSD\" . 2 DISCOUNT_RT \"50%\" N 0.5 . 2 DISCOUNT_RT \"40%\" N 0.4 1 2 CURRENCY_SYMBOL \"EUR\" C \"EUR\" . 2 CURRENCY_SYMBOL \"HKD\" C \"HKD\" 1","title":"WORK.DYNAMIC_EXTENDED_VALUES"},{"location":"dynamic-cell-dropdown/#code-examples","text":"Simple dropdown /** @file @brief Simple dynamic cell dropdown for product code @details The input table is simply one row from the target table called \"work.source_row\". Available macro variables: @li DC_LIBREF - The DC control library @li LIBDS - The library.dataset being filtered @li VARIABLE_NM - The column being filtered <h4> Service Outputs </h4> Output should be a single table called \"work.dynamic_values\" in the format below. |DISPLAY_VALUE:$|RAW_VALUE:??| |---|---| |$44.00|44| **/ %dc_assignlib (READ,mylibref) proc sql; create table work . DYNAMIC_VALUES as select distinct some_product as raw_value from mylibref . my_other_table where area in ( select area from work . source_row) order by 1 ; Extended dropdown proc sql; create table work . source as select libref,dsn from &DC_LIBREF. .MPE_TABLES where tx_to > \"%sysfunc(datetime(),E8601DT26.6)\" dt order by 1 , 2 ; data work . DYNAMIC_VALUES ( keep =display_index raw_value display_value); set work . source end =last; by libref; if last . libref then do ; display_index +1 ; raw_value=libref; display_value=libref; output ; end ; if last then do ; display_index +1 ; raw_value= '*ALL*' ; display_value= '*ALL*' ; output ; end ; run; data work . dynamic_extended_values( keep =display_index extra_col_name display_type display_value RAW_VALUE_CHAR raw_value_num forced_value); set work . source end =last; by libref dsn; retain extra_col_name 'ALERT_DS' ; retain display_type 'C' ; retain raw_value_num .; raw_value_char=dsn; display_value=dsn; forced_value= 0 ; if first . libref then display_index +1 ; if last . libref then do ; display_value= '*ALL*' ; raw_value_char= '*ALL*' ; forced_value= 1 ; output ; end ; else output ; if last then do ; display_value= '*ALL*' ; raw_value_char= '*ALL*' ; forced_value= 1 ; output ; end ; run;","title":"Code Examples"},{"location":"dynamic-cell-dropdown/#technical-notes","text":"When first clicking on a 'dynamic dropdown' cell, the frontend will first hash the entire row, and store the subsequent response from SAS against this hash in an internal lookup table. In this way, the lookup table can be subsequently referenced to vastly improve performance (by avoiding unnecessary server requests). The lookup event will occur immediately upon clicking on the (dynamic dropdown) cell. If the row has not changed since the previous click, the response will be instant. If any value in the row HAS changed, and that particular combination of values has not previously been requested (in the same browser session), then a request to SAS will need to take place before the dropdown values are shown.","title":"Technical Notes"},{"location":"emails/","text":"Data Controller for SAS\u00ae - Emails \u00b6 Overview \u00b6 Data Controller enables email alerts for users when tables are: SUBMITTED - a proposed change has been submitted. APPROVED - the proposed change was approved and applied. REJECTED - the proposed change was rejected. Emails are sent after any post edit / post approve hooks. They can be sent when specific tables are updated, or when any tables in a particular library are updated, or for all changes to all tables. See configuration section below. Email addresses are looked for first in DCXXXXXX.MPE_EMAILS . If they are not found there, then a metadata search is made (the first email found in metadata for that user is used). Setup \u00b6 As not every site has emails configured, this feature is switched OFF by default. To switch it on, navigate to DCXXXXXX.MPE_CONFIG and set the value for DC_EMAIL_ALERTS to be YES (uppercase). Tip If your Stored Process session does not have the email options configured, then the appropriate options statement must be invoked. These options may need to be done at startup, or in the configuration file. See documentation Configuration \u00b6 The DCXXXXXX.MPE_ALERTS table must be updated with the following attributes: ALERT_EVENT - either *ALL* , SUBMITTED , APPROVED or REJECTED ALERT_LIB - either *ALL* or the libref to be alerted on ALERT_DS - either *ALL* or the dataset name to be alerted on ALERT_USER - the metadata name (not displayname) of the user to be alerted If your site does not put emails in metadata, then the user emails must instead be entered in DCXXXXXX.MPE_EMAILS .","title":"Emails"},{"location":"emails/#data-controller-for-sas-emails","text":"","title":"Data Controller for SAS\u00ae - Emails"},{"location":"emails/#overview","text":"Data Controller enables email alerts for users when tables are: SUBMITTED - a proposed change has been submitted. APPROVED - the proposed change was approved and applied. REJECTED - the proposed change was rejected. Emails are sent after any post edit / post approve hooks. They can be sent when specific tables are updated, or when any tables in a particular library are updated, or for all changes to all tables. See configuration section below. Email addresses are looked for first in DCXXXXXX.MPE_EMAILS . If they are not found there, then a metadata search is made (the first email found in metadata for that user is used).","title":"Overview"},{"location":"emails/#setup","text":"As not every site has emails configured, this feature is switched OFF by default. To switch it on, navigate to DCXXXXXX.MPE_CONFIG and set the value for DC_EMAIL_ALERTS to be YES (uppercase). Tip If your Stored Process session does not have the email options configured, then the appropriate options statement must be invoked. These options may need to be done at startup, or in the configuration file. See documentation","title":"Setup"},{"location":"emails/#configuration","text":"The DCXXXXXX.MPE_ALERTS table must be updated with the following attributes: ALERT_EVENT - either *ALL* , SUBMITTED , APPROVED or REJECTED ALERT_LIB - either *ALL* or the libref to be alerted on ALERT_DS - either *ALL* or the dataset name to be alerted on ALERT_USER - the metadata name (not displayname) of the user to be alerted If your site does not put emails in metadata, then the user emails must instead be entered in DCXXXXXX.MPE_EMAILS .","title":"Configuration"},{"location":"evaluation-agreement/","text":"Data Controller for SAS\u00ae Evaluation Agreement \u00b6 The terms and conditions contained below constitute a legal agreement. This agreement (\"Agreement\") contains herein the entire agreement between the licensee (\"Licensee\") and Bowe IO Ltd. Read this agreement carefully. By downloading, installing, and/or examining the product, you acknowledge: 1 - You are authorized to enter this agreement for and on behalf of your company, and are doing so, and 2 - You have read, understand and agree that you and the company shall be bound by these terms and conditions and every modification and addition provided for. Software products included with this product that are not Bowe IO Ltd products are licensed to you by the software provider. Please refer to the license contained in the provider's product for their terms of use. 1. License Grant. \u00b6 Bowe IO Ltd grants you a limited, non-exclusive, non-transferable license to use, for evaluation/non-production purposes only , the Bowe IO Ltd software program(s) known as Data Controller for SAS\u00ae (the \"Software\") - and related product documentation - at no charge, subject to the terms and restrictions set forth in this License Agreement. You are not permitted to use the Software in any manner not expressly authorized by this License. You acknowledge and agree that ownership of the Software and all subsequent copies thereof regardless of the form or media are held by Bowe IO Ltd. 2. Term of Agreement. \u00b6 Your license is effective until terminated by Bowe IO Ltd (at the sole discretion of Bowe IO Ltd and without notice). The License will terminate automatically if you fail to comply with any of the limitations or other requirements described herein. At termination you shall cease all use of the Software and destroy all copies, full or partial, of the Software. 3. Ownership Rights. \u00b6 The Software and related documentation are protected by United Kingdom copyright laws and international treaties. Bowe IO Ltd, third party component providers and open source component providers own and retain all right, title and interest in and to the Software and related documentation, including all copyrights, patents, trade secret rights, trademarks and other intellectual property rights therein. 4. Use of Name and Trademarks. \u00b6 You shall not use the name, trade names or trademarks of Bowe IO Ltd or any of its affiliates in any advertising, promotional literature or any other material, whether in written, electronic or other form, without prior approval. 5. Restrictions \u00b6 5.1 - You may not rent, lease, lend, redistribute or sublicense the Software. You may not copy the Software other than to make archival or backup copies - provided that the backup copy includes all copyright or other proprietary notices contained on the original. You may not copy related product documentation. You may not modify, reverse engineer, decompile, or disassemble the Software, except to the extent the such restriction is expressly prohibited by applicable law. 5.2 - Certain components of the Software are provided under various Open Source licenses that have been made available to Bowe IO Ltd. You may modify or replace only these Open-Sourced Components; provided that (i) the resultant Software is used in place of the unmodified Software, on a single computer; and (ii) you otherwise comply with the terms of this License and any applicable licensing terms governing use of the Open-Sourced Components. Bowe IO Ltd is not obligated to provide any maintenance, technical or other support for the resultant Software. 6. Exclusion of Warranties. \u00b6 THE SOFTWARE IS PROVIDED TO LICENSEE \"AS IS\", AND ANY USE BY LICENSEE OF THE SOFTWARE WILL BE AT LICENSEE'S SOLE RISK. Bowe IO Ltd makes no warrranties relating to the softwtare, and disclaims all warranties (express or implied), including without limitation those of merchantability and fitness for any particular purpose. 7. Limitation of Liability. \u00b6 In no event shall Bowe IO Ltd be liable for any incidental, special, indirect or consequential damages whatsoever, including, without limitation, damages for loss of profits, loss of data, business interrupton or any other commercial damages or losses, arising out of or related to your use or inability to use the Bowe IO Ltd software, however caused, regardless of the theory of liabilty (contract, tort or otherwise) and even if Bowe IO Ltd has been advised of the possibility of such damages. 8. Governing law and jurisdiction \u00b6 8.1 - This agreement and any disputes or claims arising out of or in connection with its subject matter are governed by and construed in accordance with the law of England. 8.2 - The parties irrevocably agree that the courts of England have exclusive jurisdiction to settle any dispute or claim that arises out of or in connection with this agreement. 9. Assignment/Transfers. \u00b6 You may not assign or transfer this Agreement, in whole or in part, without the prior written consent of Bowe IO Ltd. Any attempted assignment or transfer in violation of this Section will be null and void. 10.Third Party Acknowledgements \u00b6 (A) Aspects of the Software utilize or include third party software and other copyrighted material. Acknowledgements, licensing terms and disclaimers for such material are available when accessing the Software on the Bowe IO Ltd website, and your use of such material is governed by their respective terms. (B) The Software includes certain software provided under various Open Source licenses. You may obtain complete machine-readable copies of the source code and licenses for the Open Source software at the Bowe IO Ltd Open Source website (https://docs.datacontroller.io/licenses). Open Source Software is distributed WITHOUT ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE 11. Severability. \u00b6 If any provision of this Agreement is held invalid, illegal or unenforceable, the validity, legality and enforceability of any of the remaining provisions of this Agreement shall not in any way be affected or impaired. 12. Entire Agreement. \u00b6 This Agreement is the entire agreement between you and Bowe IO Ltd concerning the Software and all related documentation and supersedes any other prior or contemporaneous agreements or communications with respect to the Software and related documentation, either written or oral.","title":"Evaluation Licence"},{"location":"evaluation-agreement/#data-controller-for-sas-evaluation-agreement","text":"The terms and conditions contained below constitute a legal agreement. This agreement (\"Agreement\") contains herein the entire agreement between the licensee (\"Licensee\") and Bowe IO Ltd. Read this agreement carefully. By downloading, installing, and/or examining the product, you acknowledge: 1 - You are authorized to enter this agreement for and on behalf of your company, and are doing so, and 2 - You have read, understand and agree that you and the company shall be bound by these terms and conditions and every modification and addition provided for. Software products included with this product that are not Bowe IO Ltd products are licensed to you by the software provider. Please refer to the license contained in the provider's product for their terms of use.","title":"Data Controller for SAS\u00ae Evaluation Agreement"},{"location":"evaluation-agreement/#1-license-grant","text":"Bowe IO Ltd grants you a limited, non-exclusive, non-transferable license to use, for evaluation/non-production purposes only , the Bowe IO Ltd software program(s) known as Data Controller for SAS\u00ae (the \"Software\") - and related product documentation - at no charge, subject to the terms and restrictions set forth in this License Agreement. You are not permitted to use the Software in any manner not expressly authorized by this License. You acknowledge and agree that ownership of the Software and all subsequent copies thereof regardless of the form or media are held by Bowe IO Ltd.","title":"1. License Grant."},{"location":"evaluation-agreement/#2-term-of-agreement","text":"Your license is effective until terminated by Bowe IO Ltd (at the sole discretion of Bowe IO Ltd and without notice). The License will terminate automatically if you fail to comply with any of the limitations or other requirements described herein. At termination you shall cease all use of the Software and destroy all copies, full or partial, of the Software.","title":"2. Term of Agreement."},{"location":"evaluation-agreement/#3-ownership-rights","text":"The Software and related documentation are protected by United Kingdom copyright laws and international treaties. Bowe IO Ltd, third party component providers and open source component providers own and retain all right, title and interest in and to the Software and related documentation, including all copyrights, patents, trade secret rights, trademarks and other intellectual property rights therein.","title":"3. Ownership Rights."},{"location":"evaluation-agreement/#4-use-of-name-and-trademarks","text":"You shall not use the name, trade names or trademarks of Bowe IO Ltd or any of its affiliates in any advertising, promotional literature or any other material, whether in written, electronic or other form, without prior approval.","title":"4. Use of Name and Trademarks."},{"location":"evaluation-agreement/#5-restrictions","text":"5.1 - You may not rent, lease, lend, redistribute or sublicense the Software. You may not copy the Software other than to make archival or backup copies - provided that the backup copy includes all copyright or other proprietary notices contained on the original. You may not copy related product documentation. You may not modify, reverse engineer, decompile, or disassemble the Software, except to the extent the such restriction is expressly prohibited by applicable law. 5.2 - Certain components of the Software are provided under various Open Source licenses that have been made available to Bowe IO Ltd. You may modify or replace only these Open-Sourced Components; provided that (i) the resultant Software is used in place of the unmodified Software, on a single computer; and (ii) you otherwise comply with the terms of this License and any applicable licensing terms governing use of the Open-Sourced Components. Bowe IO Ltd is not obligated to provide any maintenance, technical or other support for the resultant Software.","title":"5. Restrictions"},{"location":"evaluation-agreement/#6-exclusion-of-warranties","text":"THE SOFTWARE IS PROVIDED TO LICENSEE \"AS IS\", AND ANY USE BY LICENSEE OF THE SOFTWARE WILL BE AT LICENSEE'S SOLE RISK. Bowe IO Ltd makes no warrranties relating to the softwtare, and disclaims all warranties (express or implied), including without limitation those of merchantability and fitness for any particular purpose.","title":"6. Exclusion of Warranties."},{"location":"evaluation-agreement/#7-limitation-of-liability","text":"In no event shall Bowe IO Ltd be liable for any incidental, special, indirect or consequential damages whatsoever, including, without limitation, damages for loss of profits, loss of data, business interrupton or any other commercial damages or losses, arising out of or related to your use or inability to use the Bowe IO Ltd software, however caused, regardless of the theory of liabilty (contract, tort or otherwise) and even if Bowe IO Ltd has been advised of the possibility of such damages.","title":"7. Limitation of Liability."},{"location":"evaluation-agreement/#8-governing-law-and-jurisdiction","text":"8.1 - This agreement and any disputes or claims arising out of or in connection with its subject matter are governed by and construed in accordance with the law of England. 8.2 - The parties irrevocably agree that the courts of England have exclusive jurisdiction to settle any dispute or claim that arises out of or in connection with this agreement.","title":"8. Governing law and jurisdiction"},{"location":"evaluation-agreement/#9-assignmenttransfers","text":"You may not assign or transfer this Agreement, in whole or in part, without the prior written consent of Bowe IO Ltd. Any attempted assignment or transfer in violation of this Section will be null and void.","title":"9. Assignment/Transfers."},{"location":"evaluation-agreement/#10third-party-acknowledgements","text":"(A) Aspects of the Software utilize or include third party software and other copyrighted material. Acknowledgements, licensing terms and disclaimers for such material are available when accessing the Software on the Bowe IO Ltd website, and your use of such material is governed by their respective terms. (B) The Software includes certain software provided under various Open Source licenses. You may obtain complete machine-readable copies of the source code and licenses for the Open Source software at the Bowe IO Ltd Open Source website (https://docs.datacontroller.io/licenses). Open Source Software is distributed WITHOUT ANY WARRANTY, without even the implied warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE","title":"10.Third Party Acknowledgements"},{"location":"evaluation-agreement/#11-severability","text":"If any provision of this Agreement is held invalid, illegal or unenforceable, the validity, legality and enforceability of any of the remaining provisions of this Agreement shall not in any way be affected or impaired.","title":"11. Severability."},{"location":"evaluation-agreement/#12-entire-agreement","text":"This Agreement is the entire agreement between you and Bowe IO Ltd concerning the Software and all related documentation and supersedes any other prior or contemporaneous agreements or communications with respect to the Software and related documentation, either written or oral.","title":"12. Entire Agreement."},{"location":"excel/","text":"Excel Uploads \u00b6 Data Controller for SAS\u00ae supports all versions of excel. Data is extracted from excel from within the browser - there is no need for additional SAS components. So long as the column names match those in the target table, the data can be on any worksheet, start from any row, and any column. The data can be completely surrounded by irrelevant data - the extraction will stop as soon as it hits one empty cell in a primary key column. The columns can be in any order, and are not case sensitive. More details here . Formulas \u00b6 It is possible to configure certain columns to be extracted as formulae, rather than raw values. The target column must be character, and it should be wide enough to support the longest formula in the source data. If the order of values is important, you should include a row number in your primary key. Configuration is as follows: Once this is done, you are ready to upload: The final table will look like this: If you would like further integrations / support with excel uploads, we are happy to discuss new features. Just get in touch .","title":"Excel Formulas"},{"location":"excel/#excel-uploads","text":"Data Controller for SAS\u00ae supports all versions of excel. Data is extracted from excel from within the browser - there is no need for additional SAS components. So long as the column names match those in the target table, the data can be on any worksheet, start from any row, and any column. The data can be completely surrounded by irrelevant data - the extraction will stop as soon as it hits one empty cell in a primary key column. The columns can be in any order, and are not case sensitive. More details here .","title":"Excel Uploads"},{"location":"excel/#formulas","text":"It is possible to configure certain columns to be extracted as formulae, rather than raw values. The target column must be character, and it should be wide enough to support the longest formula in the source data. If the order of values is important, you should include a row number in your primary key. Configuration is as follows: Once this is done, you are ready to upload: The final table will look like this: If you would like further integrations / support with excel uploads, we are happy to discuss new features. Just get in touch .","title":"Formulas"},{"location":"filter/","text":"Filtering \u00b6 Data Controller for SAS\u00ae enables you to create complex table filters. The \"dynamic\" setting enables the dropdown values to be pre-filtered by previous filter clauses. Filtered views are shareable! Shared Filters \u00b6 When filters are submitted, the query is stored, and a unique URL is generated. This means you can share the link to a filtered view of a table! This can be used for VIEW, for EDIT and also for downloading data. Dynamic Where Clause \u00b6 When filtering without a dynamic where clause, all values are always returned in the selection box. By contrast, when the dynamic where clause box is checked (default), the values in the second and subsequent filter clauses are filtered by the previous filter clause settings, eg:","title":"Filter Mechanism"},{"location":"filter/#filtering","text":"Data Controller for SAS\u00ae enables you to create complex table filters. The \"dynamic\" setting enables the dropdown values to be pre-filtered by previous filter clauses. Filtered views are shareable!","title":"Filtering"},{"location":"filter/#shared-filters","text":"When filters are submitted, the query is stored, and a unique URL is generated. This means you can share the link to a filtered view of a table! This can be used for VIEW, for EDIT and also for downloading data.","title":"Shared Filters"},{"location":"filter/#dynamic-where-clause","text":"When filtering without a dynamic where clause, all values are always returned in the selection box. By contrast, when the dynamic where clause box is checked (default), the values in the second and subsequent filter clauses are filtered by the previous filter clause settings, eg:","title":"Dynamic Where Clause"},{"location":"formats/","text":"Formats \u00b6 Data Controller allows formats to be viewed and edited directly from the web interface - avoiding the need to create and maintain parallel 'CNTLIN' datasets. Formats are displayed with a special icon ( bolt ), in the same library as other tables (in both the VIEW and EDIT screens): Viewing or editing a format catalog will always mean that the entire catalog is exported, before being filtered (if filters applied) and displayed. For this reason, it is recommended to split a large format catalog over several catalogs, if performance is a consideration. The usual export mechanisms can also be applied - you can downlad the DDL, or export the catalog in CSV / Excel / Datalines / Markdown / DDL formats. When adding a format to MPE_TABLES, the DSN should contain the format catalog name plus a -FC extension. The LOADTYPE should be FORMAT_CAT and the BUSKEY should be FMTNAME START . HOOK scripts can also be applied (ie, run some DQ after an edit, or re-run a batch job after an approval). Example: LIBREF:$8. DSN:$32. LOADTYPE:$12. BUSKEY:$1000. MYLIB FORMATS-FC FORMAT_CAT FMTNAME START Just like regular table edits, all changes to formats are logged in the MPE_AUDIT table.","title":"Formats"},{"location":"formats/#formats","text":"Data Controller allows formats to be viewed and edited directly from the web interface - avoiding the need to create and maintain parallel 'CNTLIN' datasets. Formats are displayed with a special icon ( bolt ), in the same library as other tables (in both the VIEW and EDIT screens): Viewing or editing a format catalog will always mean that the entire catalog is exported, before being filtered (if filters applied) and displayed. For this reason, it is recommended to split a large format catalog over several catalogs, if performance is a consideration. The usual export mechanisms can also be applied - you can downlad the DDL, or export the catalog in CSV / Excel / Datalines / Markdown / DDL formats. When adding a format to MPE_TABLES, the DSN should contain the format catalog name plus a -FC extension. The LOADTYPE should be FORMAT_CAT and the BUSKEY should be FMTNAME START . HOOK scripts can also be applied (ie, run some DQ after an edit, or re-run a batch job after an approval). Example: LIBREF:$8. DSN:$32. LOADTYPE:$12. BUSKEY:$1000. MYLIB FORMATS-FC FORMAT_CAT FMTNAME START Just like regular table edits, all changes to formats are logged in the MPE_AUDIT table.","title":"Formats"},{"location":"libraries/","text":"Adding Libraries to Data Controller \u00b6 The process for adding new libraries to Data Controller depends on whether we are talking about: The VIEW or EDIT menu The flavour of SAS being used In VIEW mode, all available libraries are shown, unless the DC_RESTRICT_VIEWER option is set. In EDIT mode, only the libraries corresponding to the configuration in MPE_TABLES are visible. This list may be shorter if the user is not in the admin group or does not have the necessary security settings. Flavour specific guidance follows. Viya Libraries \u00b6 Library definitions should be added in the autoexec.sas of the designated Compute Context using Environment Manager. If the above is not feasible, it is possible to insert code in the [DC Drive Path]/services/settings.sas file however - this will have a performance impact due to the additional API calls. SAS 9 EBI Libraries \u00b6 In most cases, libname statements are NOT required so long as they are accessible in metadata. For the VIEW menu, the libname statement is made using the mm_assignlib macro (META engine). It is important that each library has a unique LIBREF. For the EDIT menu, direct libname statements are derived using the mm_assigndirectlib macro. If metadata extraction is not possible, libname statements may be added to the [DC Meta Path]/services/public/Data_Controller_Settings Stored Process. SASjs Server Libraries \u00b6 New library definitions can be added to the [DC Drive Path]/services/public/settings.sas Stored Program.","title":"Libraries"},{"location":"libraries/#adding-libraries-to-data-controller","text":"The process for adding new libraries to Data Controller depends on whether we are talking about: The VIEW or EDIT menu The flavour of SAS being used In VIEW mode, all available libraries are shown, unless the DC_RESTRICT_VIEWER option is set. In EDIT mode, only the libraries corresponding to the configuration in MPE_TABLES are visible. This list may be shorter if the user is not in the admin group or does not have the necessary security settings. Flavour specific guidance follows.","title":"Adding Libraries to Data Controller"},{"location":"libraries/#viya-libraries","text":"Library definitions should be added in the autoexec.sas of the designated Compute Context using Environment Manager. If the above is not feasible, it is possible to insert code in the [DC Drive Path]/services/settings.sas file however - this will have a performance impact due to the additional API calls.","title":"Viya Libraries"},{"location":"libraries/#sas-9-ebi-libraries","text":"In most cases, libname statements are NOT required so long as they are accessible in metadata. For the VIEW menu, the libname statement is made using the mm_assignlib macro (META engine). It is important that each library has a unique LIBREF. For the EDIT menu, direct libname statements are derived using the mm_assigndirectlib macro. If metadata extraction is not possible, libname statements may be added to the [DC Meta Path]/services/public/Data_Controller_Settings Stored Process.","title":"SAS 9 EBI Libraries"},{"location":"libraries/#sasjs-server-libraries","text":"New library definitions can be added to the [DC Drive Path]/services/public/settings.sas Stored Program.","title":"SASjs Server Libraries"},{"location":"licences/","text":"Data Controller for SAS\u00ae - Source Licences \u00b6 Overview \u00b6 Data Controller source licences are extracted automatically from our repo using the license-checker NPM module \u251c\u2500 @angular/animations@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/animations \u2502 \u2514\u2500 licenseFile: node_modules/@angular/animations/README.md \u251c\u2500 @angular/common@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/common \u2502 \u2514\u2500 licenseFile: node_modules/@angular/common/README.md \u251c\u2500 @angular/compiler@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/compiler \u2502 \u2514\u2500 licenseFile: node_modules/@angular/compiler/README.md \u251c\u2500 @angular/core@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/core \u2502 \u2514\u2500 licenseFile: node_modules/@angular/core/README.md \u251c\u2500 @angular/forms@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/forms \u2502 \u2514\u2500 licenseFile: node_modules/@angular/forms/README.md \u251c\u2500 @angular/platform-browser-dynamic@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/platform-browser-dynamic \u2502 \u2514\u2500 licenseFile: node_modules/@angular/platform-browser-dynamic/README.md \u251c\u2500 @angular/platform-browser@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/platform-browser \u2502 \u2514\u2500 licenseFile: node_modules/@angular/platform-browser/README.md \u251c\u2500 @angular/router@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/router \u2502 \u2514\u2500 licenseFile: node_modules/@angular/router/README.md \u251c\u2500 @clr/angular@4.0.14 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/vmware/clarity \u2502 \u251c\u2500 publisher: Clarity Design System \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@clr/angular \u2502 \u2514\u2500 licenseFile: node_modules/@clr/angular/README.md \u251c\u2500 @clr/icons@4.0.14 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: ssh://git@git.eng.vmware.com/clarity \u2502 \u251c\u2500 publisher: clarity \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@clr/icons \u2502 \u2514\u2500 licenseFile: node_modules/@clr/icons/README.md \u251c\u2500 @clr/ui@4.0.14 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/vmware/clarity \u2502 \u251c\u2500 publisher: clarity \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@clr/ui \u2502 \u2514\u2500 licenseFile: node_modules/@clr/ui/README.md \u251c\u2500 @handsontable/angular@7.0.0 \u2502 \u251c\u2500 licenses: Custom: https://handsontable.com \u2502 \u251c\u2500 repository: https://github.com/handsontable/handsontable \u2502 \u251c\u2500 publisher: Handsoncode \u2502 \u251c\u2500 email: hello@handsoncode.net \u2502 \u251c\u2500 url: https://handsoncode.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@handsontable/angular \u2502 \u2514\u2500 licenseFile: node_modules/@handsontable/angular/LICENSE.txt \u251c\u2500 @handsontable/formulajs@2.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/handsontable/formula.js \u2502 \u251c\u2500 publisher: Handsoncode \u2502 \u251c\u2500 email: hello@handsontable.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@handsontable/formulajs \u2502 \u2514\u2500 licenseFile: node_modules/@handsontable/formulajs/LICENSE \u251c\u2500 @npmcli/move-file@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/npm/move-file \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@npmcli/move-file \u2502 \u2514\u2500 licenseFile: node_modules/@npmcli/move-file/LICENSE.md \u251c\u2500 @sasjs/adapter@2.2.17 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/sasjs/adapter \u2502 \u251c\u2500 publisher: Allan Bowe \u2502 \u251c\u2500 email: support@macropeople.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@sasjs/adapter \u2502 \u2514\u2500 licenseFile: node_modules/@sasjs/adapter/LICENSE \u251c\u2500 @sasjs/utils@2.12.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/sasjs/utils \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@sasjs/utils \u2502 \u2514\u2500 licenseFile: node_modules/@sasjs/utils/README.md \u251c\u2500 @sheet/perf@1.20201208.1 \u2502 \u251c\u2500 licenses: MIT* \u2502 \u251c\u2500 publisher: sheetjs \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@sheet/perf \u2502 \u2514\u2500 licenseFile: node_modules/@sheet/perf/README.html \u251c\u2500 @types/d3-color@1.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-color \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-color/LICENSE \u251c\u2500 @types/d3-graphviz@2.6.6 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-graphviz \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-graphviz/LICENSE \u251c\u2500 @types/d3-interpolate@1.4.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-interpolate \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-interpolate/LICENSE \u251c\u2500 @types/d3-selection@1.4.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-selection \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-selection/LICENSE \u251c\u2500 @types/d3-transition@1.3.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-transition \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-transition/LICENSE \u251c\u2500 @types/d3-zoom@1.8.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-zoom \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-zoom/LICENSE \u251c\u2500 @types/json-schema@7.0.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/json-schema \u2502 \u2514\u2500 licenseFile: node_modules/@types/json-schema/LICENSE \u251c\u2500 @types/marked@1.2.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/marked \u2502 \u2514\u2500 licenseFile: node_modules/@types/marked/LICENSE \u251c\u2500 @types/minimatch@3.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/minimatch \u2502 \u2514\u2500 licenseFile: node_modules/@types/minimatch/LICENSE \u251c\u2500 @types/node@12.20.6 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/node \u2502 \u2514\u2500 licenseFile: node_modules/@types/node/LICENSE \u251c\u2500 @types/pikaday@1.7.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/pikaday \u2502 \u2514\u2500 licenseFile: node_modules/@types/pikaday/LICENSE \u251c\u2500 @types/prompts@2.0.11 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/prompts \u2502 \u2514\u2500 licenseFile: node_modules/@types/prompts/LICENSE \u251c\u2500 @types/text-encoding@0.0.35 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/text-encoding \u2502 \u2514\u2500 licenseFile: node_modules/@types/text-encoding/LICENSE \u251c\u2500 @webassemblyjs/ast@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/ast \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/ast/LICENSE \u251c\u2500 @webassemblyjs/floating-point-hex-parser@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Mauro Bringolf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/floating-point-hex-parser \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/floating-point-hex-parser/LICENSE \u251c\u2500 @webassemblyjs/helper-api-error@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-api-error \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-api-error/LICENSE \u251c\u2500 @webassemblyjs/helper-buffer@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-buffer \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-buffer/LICENSE \u251c\u2500 @webassemblyjs/helper-code-frame@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-code-frame \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-code-frame/LICENSE \u251c\u2500 @webassemblyjs/helper-fsm@1.9.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 publisher: Mauro Bringolf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-fsm \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-fsm/LICENSE \u251c\u2500 @webassemblyjs/helper-module-context@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-module-context \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-module-context/LICENSE \u251c\u2500 @webassemblyjs/helper-wasm-bytecode@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-wasm-bytecode \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-wasm-bytecode/LICENSE \u251c\u2500 @webassemblyjs/helper-wasm-section@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-wasm-section \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-wasm-section/LICENSE \u251c\u2500 @webassemblyjs/ieee754@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/ieee754 \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/ieee754/LICENSE \u251c\u2500 @webassemblyjs/leb128@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/leb128 \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/leb128/LICENSE.txt \u251c\u2500 @webassemblyjs/utf8@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/utf8 \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/utf8/LICENSE \u251c\u2500 @webassemblyjs/wasm-edit@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wasm-edit \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wasm-edit/LICENSE \u251c\u2500 @webassemblyjs/wasm-gen@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wasm-gen \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wasm-gen/LICENSE \u251c\u2500 @webassemblyjs/wasm-opt@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wasm-opt \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wasm-opt/LICENSE \u251c\u2500 @webassemblyjs/wasm-parser@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wasm-parser \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wasm-parser/LICENSE \u251c\u2500 @webassemblyjs/wast-parser@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wast-parser \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wast-parser/LICENSE \u251c\u2500 @webassemblyjs/wast-printer@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wast-printer \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wast-printer/LICENSE \u251c\u2500 @webcomponents/custom-elements@1.4.3 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/webcomponents/polyfills \u2502 \u251c\u2500 publisher: The Polymer Project Authors \u2502 \u251c\u2500 url: https://polymer.github.io/AUTHORS.txt \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webcomponents/custom-elements \u2502 \u2514\u2500 licenseFile: node_modules/@webcomponents/custom-elements/LICENSE.md \u251c\u2500 @xtuc/ieee754@1.2.0 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/feross/ieee754 \u2502 \u251c\u2500 publisher: Feross Aboukhadijeh \u2502 \u251c\u2500 email: feross@feross.org \u2502 \u251c\u2500 url: http://feross.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@xtuc/ieee754 \u2502 \u2514\u2500 licenseFile: node_modules/@xtuc/ieee754/LICENSE \u251c\u2500 @xtuc/long@4.2.2 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/dcodeIO/long.js \u2502 \u251c\u2500 publisher: Daniel Wirtz \u2502 \u251c\u2500 email: dcode@dcode.io \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@xtuc/long \u2502 \u2514\u2500 licenseFile: node_modules/@xtuc/long/LICENSE \u251c\u2500 acorn@6.4.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/acornjs/acorn \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/acorn \u2502 \u2514\u2500 licenseFile: node_modules/acorn/LICENSE \u251c\u2500 aggregate-error@3.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/aggregate-error \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/aggregate-error \u2502 \u2514\u2500 licenseFile: node_modules/aggregate-error/license \u251c\u2500 ajv-keywords@3.5.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/epoberezkin/ajv-keywords \u2502 \u251c\u2500 publisher: Evgeny Poberezkin \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ajv-keywords \u2502 \u2514\u2500 licenseFile: node_modules/ajv-keywords/LICENSE \u251c\u2500 ajv@6.12.6 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/ajv-validator/ajv \u2502 \u251c\u2500 publisher: Evgeny Poberezkin \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ajv \u2502 \u2514\u2500 licenseFile: node_modules/ajv/LICENSE \u251c\u2500 angular-prism@0.1.20 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/vaibhav93/angular-prism \u2502 \u251c\u2500 publisher: Vaibhav Bansal \u2502 \u251c\u2500 email: vaibhavbansal1993@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/angular-prism \u2502 \u2514\u2500 licenseFile: node_modules/angular-prism/README.MD \u251c\u2500 ansi-regex@2.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/ansi-regex \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ansi-regex \u2502 \u2514\u2500 licenseFile: node_modules/ansi-regex/license \u251c\u2500 ansi-styles@2.2.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/ansi-styles \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ansi-styles \u2502 \u2514\u2500 licenseFile: node_modules/ansi-styles/license \u251c\u2500 anymatch@3.1.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/micromatch/anymatch \u2502 \u251c\u2500 publisher: Elan Shanker \u2502 \u251c\u2500 url: https://github.com/es128 \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/anymatch \u2502 \u2514\u2500 licenseFile: node_modules/anymatch/LICENSE \u251c\u2500 asn1.js@5.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/asn1.js \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/asn1.js \u2502 \u2514\u2500 licenseFile: node_modules/asn1.js/LICENSE \u251c\u2500 assert@1.5.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/browserify/commonjs-assert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/assert \u2502 \u2514\u2500 licenseFile: node_modules/assert/LICENSE \u251c\u2500 asynckit@0.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/alexindigo/asynckit \u2502 \u251c\u2500 publisher: Alex Indigo \u2502 \u251c\u2500 email: iam@alexindigo.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/asynckit \u2502 \u2514\u2500 licenseFile: node_modules/asynckit/LICENSE \u251c\u2500 axios@0.21.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/axios/axios \u2502 \u251c\u2500 publisher: Matt Zabriskie \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/axios \u2502 \u2514\u2500 licenseFile: node_modules/axios/LICENSE \u251c\u2500 balanced-match@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/juliangruber/balanced-match \u2502 \u251c\u2500 publisher: Julian Gruber \u2502 \u251c\u2500 email: mail@juliangruber.com \u2502 \u251c\u2500 url: http://juliangruber.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/balanced-match \u2502 \u2514\u2500 licenseFile: node_modules/balanced-match/LICENSE.md \u251c\u2500 base64-arraybuffer@0.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/niklasvh/base64-arraybuffer \u2502 \u251c\u2500 publisher: Niklas von Hertzen \u2502 \u251c\u2500 email: niklasvh@gmail.com \u2502 \u251c\u2500 url: https://hertzen.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/base64-arraybuffer \u2502 \u2514\u2500 licenseFile: node_modules/base64-arraybuffer/LICENSE-MIT \u251c\u2500 base64-js@1.5.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/beatgammit/base64-js \u2502 \u251c\u2500 publisher: T. Jameson Little \u2502 \u251c\u2500 email: t.jameson.little@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/base64-js \u2502 \u2514\u2500 licenseFile: node_modules/base64-js/LICENSE \u251c\u2500 bessel@1.0.2 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/SheetJS/bessel \u2502 \u251c\u2500 publisher: SheetJS \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/bessel \u2502 \u2514\u2500 licenseFile: node_modules/bessel/LICENSE \u251c\u2500 big.js@5.2.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/MikeMcl/big.js \u2502 \u251c\u2500 publisher: Michael Mclaughlin \u2502 \u251c\u2500 email: M8ch88l@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/big.js \u2502 \u2514\u2500 licenseFile: node_modules/big.js/LICENCE \u251c\u2500 bignumber.js@8.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/MikeMcl/bignumber.js \u2502 \u251c\u2500 publisher: Michael Mclaughlin \u2502 \u251c\u2500 email: M8ch88l@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/bignumber.js \u2502 \u2514\u2500 licenseFile: node_modules/bignumber.js/LICENCE \u251c\u2500 binary-extensions@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/binary-extensions \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/binary-extensions \u2502 \u2514\u2500 licenseFile: node_modules/binary-extensions/license \u251c\u2500 bn.js@5.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/bn.js \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/bn.js \u2502 \u2514\u2500 licenseFile: node_modules/bn.js/LICENSE \u251c\u2500 brace-expansion@1.1.11 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/juliangruber/brace-expansion \u2502 \u251c\u2500 publisher: Julian Gruber \u2502 \u251c\u2500 email: mail@juliangruber.com \u2502 \u251c\u2500 url: http://juliangruber.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/brace-expansion \u2502 \u2514\u2500 licenseFile: node_modules/brace-expansion/LICENSE \u251c\u2500 braces@3.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/braces \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/braces \u2502 \u2514\u2500 licenseFile: node_modules/braces/LICENSE \u251c\u2500 brorand@1.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/brorand \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/brorand \u2502 \u2514\u2500 licenseFile: node_modules/brorand/README.md \u251c\u2500 browserify-aes@1.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-aes \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-aes \u2502 \u2514\u2500 licenseFile: node_modules/browserify-aes/LICENSE \u251c\u2500 browserify-cipher@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-cipher \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 email: calvin.metcalf@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-cipher \u2502 \u2514\u2500 licenseFile: node_modules/browserify-cipher/LICENSE \u251c\u2500 browserify-des@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-des \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 email: calvin.metcalf@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-des \u2502 \u2514\u2500 licenseFile: node_modules/browserify-des/license \u251c\u2500 browserify-rsa@4.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-rsa \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-rsa \u2502 \u2514\u2500 licenseFile: node_modules/browserify-rsa/LICENSE \u251c\u2500 browserify-sign@4.2.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-sign \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-sign \u2502 \u2514\u2500 licenseFile: node_modules/browserify-sign/LICENSE \u251c\u2500 browserify-zlib@0.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/devongovett/browserify-zlib \u2502 \u251c\u2500 publisher: Devon Govett \u2502 \u251c\u2500 email: devongovett@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-zlib \u2502 \u2514\u2500 licenseFile: node_modules/browserify-zlib/LICENSE \u251c\u2500 buffer-from@1.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/LinusU/buffer-from \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/buffer-from \u2502 \u2514\u2500 licenseFile: node_modules/buffer-from/LICENSE \u251c\u2500 buffer-xor@1.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/buffer-xor \u2502 \u251c\u2500 publisher: Daniel Cousens \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/buffer-xor \u2502 \u2514\u2500 licenseFile: node_modules/buffer-xor/LICENSE \u251c\u2500 buffer@5.7.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/feross/buffer \u2502 \u251c\u2500 publisher: Feross Aboukhadijeh \u2502 \u251c\u2500 email: feross@feross.org \u2502 \u251c\u2500 url: https://feross.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/buffer \u2502 \u2514\u2500 licenseFile: node_modules/buffer/LICENSE \u251c\u2500 builtin-status-codes@3.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/bendrucker/builtin-status-codes \u2502 \u251c\u2500 publisher: Ben Drucker \u2502 \u251c\u2500 email: bvdrucker@gmail.com \u2502 \u251c\u2500 url: bendrucker.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/builtin-status-codes \u2502 \u2514\u2500 licenseFile: node_modules/builtin-status-codes/license \u251c\u2500 cacache@15.0.5 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/cacache \u2502 \u251c\u2500 publisher: Kat March\u00e1n \u2502 \u251c\u2500 email: kzm@sykosomatic.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/cacache \u2502 \u2514\u2500 licenseFile: node_modules/cacache/LICENSE.md \u251c\u2500 chalk@1.1.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/chalk \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/chalk \u2502 \u2514\u2500 licenseFile: node_modules/chalk/license \u251c\u2500 chokidar@3.5.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/paulmillr/chokidar \u2502 \u251c\u2500 publisher: Paul Miller \u2502 \u251c\u2500 url: https://paulmillr.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/chokidar \u2502 \u2514\u2500 licenseFile: node_modules/chokidar/LICENSE \u251c\u2500 chownr@2.0.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/chownr \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/chownr \u2502 \u2514\u2500 licenseFile: node_modules/chownr/LICENSE \u251c\u2500 chrome-trace-event@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: github.com:samccone/chrome-trace-event \u2502 \u251c\u2500 publisher: Trent Mick, Sam Saccone \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/chrome-trace-event \u2502 \u2514\u2500 licenseFile: node_modules/chrome-trace-event/LICENSE.txt \u251c\u2500 cipher-base@1.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/cipher-base \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 email: calvin.metcalf@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/cipher-base \u2502 \u2514\u2500 licenseFile: node_modules/cipher-base/LICENSE \u251c\u2500 clean-stack@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/clean-stack \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/clean-stack \u2502 \u2514\u2500 licenseFile: node_modules/clean-stack/license \u251c\u2500 cli-table@0.3.6 \u2502 \u251c\u2500 licenses: MIT* \u2502 \u251c\u2500 repository: https://github.com/Automattic/cli-table \u2502 \u251c\u2500 publisher: Guillermo Rauch \u2502 \u251c\u2500 email: guillermo@learnboost.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/cli-table \u2502 \u2514\u2500 licenseFile: node_modules/cli-table/README.md \u251c\u2500 clipboard@2.0.8 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zenorocha/clipboard.js \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/clipboard \u2502 \u2514\u2500 licenseFile: node_modules/clipboard/LICENSE \u251c\u2500 clone-deep@4.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/clone-deep \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/clone-deep \u2502 \u2514\u2500 licenseFile: node_modules/clone-deep/LICENSE \u251c\u2500 codepage@1.13.1 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/SheetJS/js-codepage \u2502 \u251c\u2500 publisher: SheetJS \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/codepage \u2502 \u2514\u2500 licenseFile: node_modules/codepage/LICENSE \u251c\u2500 colors@1.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Marak/colors.js \u2502 \u251c\u2500 publisher: Marak Squires \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/colors \u2502 \u2514\u2500 licenseFile: node_modules/colors/LICENSE \u251c\u2500 combined-stream@1.0.8 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/felixge/node-combined-stream \u2502 \u251c\u2500 publisher: Felix Geisend\u00f6rfer \u2502 \u251c\u2500 email: felix@debuggable.com \u2502 \u251c\u2500 url: http://debuggable.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/combined-stream \u2502 \u2514\u2500 licenseFile: node_modules/combined-stream/License \u251c\u2500 commander@2.15.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/tj/commander.js \u2502 \u251c\u2500 publisher: TJ Holowaychuk \u2502 \u251c\u2500 email: tj@vision-media.ca \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/commander \u2502 \u2514\u2500 licenseFile: node_modules/commander/LICENSE \u251c\u2500 commondir@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/node-commondir \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/commondir \u2502 \u2514\u2500 licenseFile: node_modules/commondir/LICENSE \u251c\u2500 concat-map@0.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/node-concat-map \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/concat-map \u2502 \u2514\u2500 licenseFile: node_modules/concat-map/LICENSE \u251c\u2500 consola@2.15.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/nuxt/consola \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/consola \u2502 \u2514\u2500 licenseFile: node_modules/consola/README.md \u251c\u2500 console-browserify@1.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/browserify/console-browserify \u2502 \u251c\u2500 publisher: Raynos \u2502 \u251c\u2500 email: raynos2@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/console-browserify \u2502 \u2514\u2500 licenseFile: node_modules/console-browserify/LICENCE \u251c\u2500 constants-browserify@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/juliangruber/constants-browserify \u2502 \u251c\u2500 publisher: Julian Gruber \u2502 \u251c\u2500 email: julian@juliangruber.com \u2502 \u251c\u2500 url: http://juliangruber.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/constants-browserify \u2502 \u2514\u2500 licenseFile: node_modules/constants-browserify/README.md \u251c\u2500 core-js@2.6.12 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zloirock/core-js \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/core-js \u2502 \u2514\u2500 licenseFile: node_modules/core-js/LICENSE \u251c\u2500 core-util-is@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/isaacs/core-util-is \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/core-util-is \u2502 \u2514\u2500 licenseFile: node_modules/core-util-is/LICENSE \u251c\u2500 create-ecdh@4.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/createECDH \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/create-ecdh \u2502 \u2514\u2500 licenseFile: node_modules/create-ecdh/LICENSE \u251c\u2500 create-hash@1.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/createHash \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/create-hash \u2502 \u2514\u2500 licenseFile: node_modules/create-hash/LICENSE \u251c\u2500 create-hmac@1.1.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/createHmac \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/create-hmac \u2502 \u2514\u2500 licenseFile: node_modules/create-hmac/LICENSE \u251c\u2500 crypto-browserify@3.12.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/crypto-browserify \u2502 \u251c\u2500 publisher: Dominic Tarr \u2502 \u251c\u2500 email: dominic.tarr@gmail.com \u2502 \u251c\u2500 url: dominictarr.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/crypto-browserify \u2502 \u2514\u2500 licenseFile: node_modules/crypto-browserify/LICENSE \u251c\u2500 crypto-js@3.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/brix/crypto-js \u2502 \u251c\u2500 publisher: Evan Vosberg \u2502 \u251c\u2500 url: http://github.com/evanvosberg \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/crypto-js \u2502 \u2514\u2500 licenseFile: node_modules/crypto-js/LICENSE \u251c\u2500 d3-color@1.4.1 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-color \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-color \u2502 \u2514\u2500 licenseFile: node_modules/d3-color/LICENSE \u251c\u2500 d3-dispatch@1.0.6 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-dispatch \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-dispatch \u2502 \u2514\u2500 licenseFile: node_modules/d3-dispatch/LICENSE \u251c\u2500 d3-drag@1.2.5 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-drag \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-drag \u2502 \u2514\u2500 licenseFile: node_modules/d3-drag/LICENSE \u251c\u2500 d3-ease@1.0.7 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-ease \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-ease \u2502 \u2514\u2500 licenseFile: node_modules/d3-ease/LICENSE \u251c\u2500 d3-format@1.4.5 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-format \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-format \u2502 \u2514\u2500 licenseFile: node_modules/d3-format/LICENSE \u251c\u2500 d3-graphviz@2.6.1 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/magjac/d3-graphviz \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-graphviz \u2502 \u2514\u2500 licenseFile: node_modules/d3-graphviz/LICENSE \u251c\u2500 d3-interpolate@1.4.0 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-interpolate \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-interpolate \u2502 \u2514\u2500 licenseFile: node_modules/d3-interpolate/LICENSE \u251c\u2500 d3-path@1.0.9 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-path \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-path \u2502 \u2514\u2500 licenseFile: node_modules/d3-path/LICENSE \u251c\u2500 d3-selection@1.4.2 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-selection \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: https://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-selection \u2502 \u2514\u2500 licenseFile: node_modules/d3-selection/LICENSE \u251c\u2500 d3-timer@1.0.10 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-timer \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-timer \u2502 \u2514\u2500 licenseFile: node_modules/d3-timer/LICENSE \u251c\u2500 d3-transition@1.3.2 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-transition \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: https://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-transition \u2502 \u2514\u2500 licenseFile: node_modules/d3-transition/LICENSE \u251c\u2500 d3-zoom@1.8.3 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-zoom \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-zoom \u2502 \u2514\u2500 licenseFile: node_modules/d3-zoom/LICENSE \u251c\u2500 datacontroller@3.12.0 \u2502 \u251c\u2500 licenses: UNLICENSED \u2502 \u251c\u2500 private: true \u2502 \u251c\u2500 path: ../dcfrontend \u2502 \u2514\u2500 licenseFile: licence.md \u251c\u2500 delayed-stream@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/felixge/node-delayed-stream \u2502 \u251c\u2500 publisher: Felix Geisend\u00f6rfer \u2502 \u251c\u2500 email: felix@debuggable.com \u2502 \u251c\u2500 url: http://debuggable.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/delayed-stream \u2502 \u2514\u2500 licenseFile: node_modules/delayed-stream/License \u251c\u2500 delegate@3.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zenorocha/delegate \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/delegate \u2502 \u2514\u2500 licenseFile: node_modules/delegate/readme.md \u251c\u2500 des.js@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/des.js \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/des.js \u2502 \u2514\u2500 licenseFile: node_modules/des.js/README.md \u251c\u2500 diffie-hellman@5.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/diffie-hellman \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/diffie-hellman \u2502 \u2514\u2500 licenseFile: node_modules/diffie-hellman/LICENSE \u251c\u2500 domain-browser@1.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/bevry/domain-browser \u2502 \u251c\u2500 publisher: 2013+ Bevry Pty Ltd \u2502 \u251c\u2500 email: us@bevry.me \u2502 \u251c\u2500 url: http://bevry.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/domain-browser \u2502 \u2514\u2500 licenseFile: node_modules/domain-browser/LICENSE.md \u251c\u2500 dompurify@2.2.7 \u2502 \u251c\u2500 licenses: (MPL-2.0 OR Apache-2.0) \u2502 \u251c\u2500 repository: https://github.com/cure53/DOMPurify \u2502 \u251c\u2500 publisher: Mario Heiderich \u2502 \u251c\u2500 email: mario@cure53.de \u2502 \u251c\u2500 url: https://cure53.de/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/dompurify \u2502 \u2514\u2500 licenseFile: node_modules/dompurify/LICENSE \u251c\u2500 elliptic@6.5.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/elliptic \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/elliptic \u2502 \u2514\u2500 licenseFile: node_modules/elliptic/README.md \u251c\u2500 emoji-toolkit@6.5.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/joypixels/emoji-toolkit \u2502 \u251c\u2500 publisher: JoyPixels \u2502 \u251c\u2500 email: support@joypixels.com \u2502 \u251c\u2500 url: https://www.joypixels.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/emoji-toolkit \u2502 \u2514\u2500 licenseFile: node_modules/emoji-toolkit/LICENSE.md \u251c\u2500 emojis-list@3.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/kikobeats/emojis-list \u2502 \u251c\u2500 publisher: Kiko Beats \u2502 \u251c\u2500 email: josefrancisco.verdu@gmail.com \u2502 \u251c\u2500 url: https://github.com/Kikobeats \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/emojis-list \u2502 \u2514\u2500 licenseFile: node_modules/emojis-list/LICENSE.md \u251c\u2500 enhanced-resolve@3.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/enhanced-resolve \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/enhanced-resolve \u2502 \u2514\u2500 licenseFile: node_modules/enhanced-resolve/README.md \u251c\u2500 errno@0.1.8 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/rvagg/node-errno \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/errno \u2502 \u2514\u2500 licenseFile: node_modules/errno/README.md \u251c\u2500 escape-string-regexp@1.0.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/escape-string-regexp \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/escape-string-regexp \u2502 \u2514\u2500 licenseFile: node_modules/escape-string-regexp/license \u251c\u2500 eslint-scope@4.0.3 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/eslint/eslint-scope \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/eslint-scope \u2502 \u2514\u2500 licenseFile: node_modules/eslint-scope/LICENSE \u251c\u2500 esrecurse@4.3.0 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/estools/esrecurse \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/esrecurse \u2502 \u2514\u2500 licenseFile: node_modules/esrecurse/README.md \u251c\u2500 estraverse@4.3.0 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/estools/estraverse \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/estraverse \u2502 \u2514\u2500 licenseFile: node_modules/estraverse/LICENSE.BSD \u251c\u2500 events@3.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Gozala/events \u2502 \u251c\u2500 publisher: Irakli Gozalishvili \u2502 \u251c\u2500 email: rfobic@gmail.com \u2502 \u251c\u2500 url: http://jeditoolkit.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/events \u2502 \u2514\u2500 licenseFile: node_modules/events/LICENSE \u251c\u2500 evp_bytestokey@1.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/EVP_BytesToKey \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 email: calvin.metcalf@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/evp_bytestokey \u2502 \u2514\u2500 licenseFile: node_modules/evp_bytestokey/LICENSE \u251c\u2500 exit-on-epipe@1.0.1 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/SheetJS/node-exit-on-epipe \u2502 \u251c\u2500 publisher: sheetjs \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/exit-on-epipe \u2502 \u2514\u2500 licenseFile: node_modules/exit-on-epipe/LICENSE \u251c\u2500 fast-deep-equal@3.1.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/epoberezkin/fast-deep-equal \u2502 \u251c\u2500 publisher: Evgeny Poberezkin \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fast-deep-equal \u2502 \u2514\u2500 licenseFile: node_modules/fast-deep-equal/LICENSE \u251c\u2500 fast-json-stable-stringify@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/epoberezkin/fast-json-stable-stringify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fast-json-stable-stringify \u2502 \u2514\u2500 licenseFile: node_modules/fast-json-stable-stringify/LICENSE \u251c\u2500 fill-range@7.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/fill-range \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fill-range \u2502 \u2514\u2500 licenseFile: node_modules/fill-range/LICENSE \u251c\u2500 find-cache-dir@3.3.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/avajs/find-cache-dir \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/find-cache-dir \u2502 \u2514\u2500 licenseFile: node_modules/find-cache-dir/license \u251c\u2500 find-up@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/find-up \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/find-up \u2502 \u2514\u2500 licenseFile: node_modules/find-up/license \u251c\u2500 follow-redirects@1.13.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/follow-redirects/follow-redirects \u2502 \u251c\u2500 publisher: Ruben Verborgh \u2502 \u251c\u2500 email: ruben@verborgh.org \u2502 \u251c\u2500 url: https://ruben.verborgh.org/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/follow-redirects \u2502 \u2514\u2500 licenseFile: node_modules/follow-redirects/LICENSE \u251c\u2500 form-data@4.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/form-data/form-data \u2502 \u251c\u2500 publisher: Felix Geisend\u00f6rfer \u2502 \u251c\u2500 email: felix@debuggable.com \u2502 \u251c\u2500 url: http://debuggable.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/form-data \u2502 \u2514\u2500 licenseFile: node_modules/form-data/License \u251c\u2500 fs-extra@7.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jprichardson/node-fs-extra \u2502 \u251c\u2500 publisher: JP Richardson \u2502 \u251c\u2500 email: jprichardson@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fs-extra \u2502 \u2514\u2500 licenseFile: node_modules/fs-extra/LICENSE \u251c\u2500 fs-minipass@2.1.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/fs-minipass \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fs-minipass \u2502 \u2514\u2500 licenseFile: node_modules/fs-minipass/LICENSE \u251c\u2500 fs.realpath@1.0.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/fs.realpath \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fs.realpath \u2502 \u2514\u2500 licenseFile: node_modules/fs.realpath/LICENSE \u251c\u2500 fsevents@2.3.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/fsevents/fsevents \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fsevents \u2502 \u2514\u2500 licenseFile: node_modules/fsevents/LICENSE \u251c\u2500 function-bind@1.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Raynos/function-bind \u2502 \u251c\u2500 publisher: Raynos \u2502 \u251c\u2500 email: raynos2@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/function-bind \u2502 \u2514\u2500 licenseFile: node_modules/function-bind/LICENSE \u251c\u2500 glob-parent@5.1.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/gulpjs/glob-parent \u2502 \u251c\u2500 publisher: Gulp Team \u2502 \u251c\u2500 email: team@gulpjs.com \u2502 \u251c\u2500 url: https://gulpjs.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/glob-parent \u2502 \u2514\u2500 licenseFile: node_modules/glob-parent/LICENSE \u251c\u2500 glob@7.1.6 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/node-glob \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/glob \u2502 \u2514\u2500 licenseFile: node_modules/glob/LICENSE \u251c\u2500 good-listener@1.2.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zenorocha/good-listener \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/good-listener \u2502 \u2514\u2500 licenseFile: node_modules/good-listener/readme.md \u251c\u2500 graceful-fs@4.2.6 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/node-graceful-fs \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/graceful-fs \u2502 \u2514\u2500 licenseFile: node_modules/graceful-fs/LICENSE \u251c\u2500 handlebars@4.7.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/wycats/handlebars.js \u2502 \u251c\u2500 publisher: Yehuda Katz \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/handlebars \u2502 \u2514\u2500 licenseFile: node_modules/handlebars/LICENSE \u251c\u2500 handsontable@8.3.2 \u2502 \u251c\u2500 licenses: Custom: https://handsontable.com \u2502 \u251c\u2500 repository: https://github.com/handsontable/handsontable \u2502 \u251c\u2500 publisher: Handsoncode \u2502 \u251c\u2500 email: hello@handsontable.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/handsontable \u2502 \u2514\u2500 licenseFile: node_modules/handsontable/LICENSE.txt \u251c\u2500 has-ansi@2.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/has-ansi \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/has-ansi \u2502 \u2514\u2500 licenseFile: node_modules/has-ansi/license \u251c\u2500 has@1.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/tarruda/has \u2502 \u251c\u2500 publisher: Thiago de Arruda \u2502 \u251c\u2500 email: tpadilha84@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/has \u2502 \u2514\u2500 licenseFile: node_modules/has/LICENSE-MIT \u251c\u2500 hash-base@3.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/hash-base \u2502 \u251c\u2500 publisher: Kirill Fomichev \u2502 \u251c\u2500 email: fanatid@ya.ru \u2502 \u251c\u2500 url: https://github.com/fanatid \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/hash-base \u2502 \u2514\u2500 licenseFile: node_modules/hash-base/LICENSE \u251c\u2500 hash.js@1.1.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/hash.js \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/hash.js \u2502 \u2514\u2500 licenseFile: node_modules/hash.js/README.md \u251c\u2500 highlight.js@9.18.5 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/highlightjs/highlight.js \u2502 \u251c\u2500 publisher: Ivan Sagalaev \u2502 \u251c\u2500 email: maniac@softwaremaniacs.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/highlight.js \u2502 \u2514\u2500 licenseFile: node_modules/highlight.js/LICENSE \u251c\u2500 hmac-drbg@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/hmac-drbg \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/hmac-drbg \u2502 \u2514\u2500 licenseFile: node_modules/hmac-drbg/README.md \u251c\u2500 hot-formula-parser@4.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/handsontable/formula-parser \u2502 \u251c\u2500 publisher: Handsoncode \u2502 \u251c\u2500 email: hello@handsontable.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/hot-formula-parser \u2502 \u2514\u2500 licenseFile: node_modules/hot-formula-parser/LICENSE \u251c\u2500 https-browserify@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/https-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/https-browserify \u2502 \u2514\u2500 licenseFile: node_modules/https-browserify/LICENSE \u251c\u2500 https@1.0.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 publisher: hardus van der berg \u2502 \u251c\u2500 email: hardus@sunfork.com \u2502 \u251c\u2500 url: http://www.sunfork.com \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/https \u251c\u2500 iconv-lite@0.5.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/ashtuchkin/iconv-lite \u2502 \u251c\u2500 publisher: Alexander Shtuchkin \u2502 \u251c\u2500 email: ashtuchkin@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/iconv-lite \u2502 \u2514\u2500 licenseFile: node_modules/iconv-lite/LICENSE \u251c\u2500 ieee754@1.2.1 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/feross/ieee754 \u2502 \u251c\u2500 publisher: Feross Aboukhadijeh \u2502 \u251c\u2500 email: feross@feross.org \u2502 \u251c\u2500 url: https://feross.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ieee754 \u2502 \u2514\u2500 licenseFile: node_modules/ieee754/LICENSE \u251c\u2500 imurmurhash@0.1.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jensyt/imurmurhash-js \u2502 \u251c\u2500 publisher: Jens Taylor \u2502 \u251c\u2500 email: jensyt@gmail.com \u2502 \u251c\u2500 url: https://github.com/homebrewing \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/imurmurhash \u2502 \u2514\u2500 licenseFile: node_modules/imurmurhash/README.md \u251c\u2500 indent-string@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/indent-string \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/indent-string \u2502 \u2514\u2500 licenseFile: node_modules/indent-string/license \u251c\u2500 infer-owner@1.0.4 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/infer-owner \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: https://izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/infer-owner \u2502 \u2514\u2500 licenseFile: node_modules/infer-owner/LICENSE \u251c\u2500 inflight@1.0.6 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/inflight \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/inflight \u2502 \u2514\u2500 licenseFile: node_modules/inflight/LICENSE \u251c\u2500 inherits@2.0.4 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/inherits \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/inherits \u2502 \u2514\u2500 licenseFile: node_modules/inherits/LICENSE \u251c\u2500 interpret@1.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/gulpjs/interpret \u2502 \u251c\u2500 publisher: Gulp Team \u2502 \u251c\u2500 email: team@gulpjs.com \u2502 \u251c\u2500 url: http://gulpjs.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/interpret \u2502 \u2514\u2500 licenseFile: node_modules/interpret/LICENSE \u251c\u2500 is-binary-path@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/is-binary-path \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-binary-path \u2502 \u2514\u2500 licenseFile: node_modules/is-binary-path/license \u251c\u2500 is-core-module@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/inspect-js/is-core-module \u2502 \u251c\u2500 publisher: Jordan Harband \u2502 \u251c\u2500 email: ljharb@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-core-module \u2502 \u2514\u2500 licenseFile: node_modules/is-core-module/LICENSE \u251c\u2500 is-extglob@2.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/is-extglob \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-extglob \u2502 \u2514\u2500 licenseFile: node_modules/is-extglob/LICENSE \u251c\u2500 is-finite@1.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/is-finite \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-finite \u2502 \u2514\u2500 licenseFile: node_modules/is-finite/license \u251c\u2500 is-glob@4.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/is-glob \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-glob \u2502 \u2514\u2500 licenseFile: node_modules/is-glob/LICENSE \u251c\u2500 is-number@7.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/is-number \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-number \u2502 \u2514\u2500 licenseFile: node_modules/is-number/LICENSE \u251c\u2500 is-plain-object@2.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/is-plain-object \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-plain-object \u2502 \u2514\u2500 licenseFile: node_modules/is-plain-object/LICENSE \u251c\u2500 isarray@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/juliangruber/isarray \u2502 \u251c\u2500 publisher: Julian Gruber \u2502 \u251c\u2500 email: mail@juliangruber.com \u2502 \u251c\u2500 url: http://juliangruber.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/isarray \u2502 \u2514\u2500 licenseFile: node_modules/isarray/README.md \u251c\u2500 isobject@3.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/isobject \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/isobject \u2502 \u2514\u2500 licenseFile: node_modules/isobject/LICENSE \u251c\u2500 jest-worker@26.6.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/facebook/jest \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jest-worker \u2502 \u2514\u2500 licenseFile: node_modules/jest-worker/LICENSE \u251c\u2500 jquery-datetimepicker@2.5.21 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xdan/datetimepicker \u2502 \u251c\u2500 publisher: Chupurnov \u2502 \u251c\u2500 email: chupurnov@gmail.com \u2502 \u251c\u2500 url: https://xdsoft.net/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jquery-datetimepicker \u2502 \u2514\u2500 licenseFile: node_modules/jquery-datetimepicker/README.md \u251c\u2500 jquery-mousewheel@3.1.13 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jquery/jquery-mousewheel \u2502 \u251c\u2500 publisher: jQuery Foundation and other contributors \u2502 \u251c\u2500 url: https://github.com/jquery/jquery-mousewheel/blob/master/AUTHORS.txt \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jquery-mousewheel \u2502 \u2514\u2500 licenseFile: node_modules/jquery-mousewheel/LICENSE.txt \u251c\u2500 jquery@3.6.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jquery/jquery \u2502 \u251c\u2500 publisher: OpenJS Foundation and other contributors \u2502 \u251c\u2500 url: https://github.com/jquery/jquery/blob/3.6.0/AUTHORS.txt \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jquery \u2502 \u2514\u2500 licenseFile: node_modules/jquery/LICENSE.txt \u251c\u2500 json-parse-better-errors@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zkat/json-parse-better-errors \u2502 \u251c\u2500 publisher: Kat March\u00e1n \u2502 \u251c\u2500 email: kzm@zkat.tech \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/json-parse-better-errors \u2502 \u2514\u2500 licenseFile: node_modules/json-parse-better-errors/LICENSE.md \u251c\u2500 json-schema-traverse@0.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/epoberezkin/json-schema-traverse \u2502 \u251c\u2500 publisher: Evgeny Poberezkin \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/json-schema-traverse \u2502 \u2514\u2500 licenseFile: node_modules/json-schema-traverse/LICENSE \u251c\u2500 json5@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/json5/json5 \u2502 \u251c\u2500 publisher: Aseem Kishore \u2502 \u251c\u2500 email: aseem.kishore@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/json5 \u2502 \u2514\u2500 licenseFile: node_modules/json5/LICENSE.md \u251c\u2500 jsonfile@4.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jprichardson/node-jsonfile \u2502 \u251c\u2500 publisher: JP Richardson \u2502 \u251c\u2500 email: jprichardson@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jsonfile \u2502 \u2514\u2500 licenseFile: node_modules/jsonfile/LICENSE \u251c\u2500 jsrsasign@10.1.13 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/kjur/jsrsasign \u2502 \u251c\u2500 publisher: Kenji Urushima \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jsrsasign \u2502 \u2514\u2500 licenseFile: node_modules/jsrsasign/README.md \u251c\u2500 jstat@1.9.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jstat/jstat \u2502 \u251c\u2500 publisher: Trevor Norris \u2502 \u251c\u2500 email: trev.norris@gmail.com \u2502 \u251c\u2500 url: http://trevorjnorris.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jstat \u2502 \u2514\u2500 licenseFile: node_modules/jstat/LICENSE \u251c\u2500 katex@0.12.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/KaTeX/KaTeX \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/katex \u2502 \u2514\u2500 licenseFile: node_modules/katex/LICENSE \u251c\u2500 kind-of@6.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/kind-of \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/kind-of \u2502 \u2514\u2500 licenseFile: node_modules/kind-of/LICENSE \u251c\u2500 kleur@3.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/lukeed/kleur \u2502 \u251c\u2500 publisher: Luke Edwards \u2502 \u251c\u2500 email: luke.edwards05@gmail.com \u2502 \u251c\u2500 url: lukeed.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/kleur \u2502 \u2514\u2500 licenseFile: node_modules/kleur/license \u251c\u2500 loader-runner@2.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/loader-runner \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/loader-runner \u2502 \u2514\u2500 licenseFile: node_modules/loader-runner/LICENSE \u251c\u2500 loader-utils@1.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/loader-utils \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/loader-utils \u2502 \u2514\u2500 licenseFile: node_modules/loader-utils/LICENSE \u251c\u2500 lodash@4.17.21 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/lodash/lodash \u2502 \u251c\u2500 publisher: John-David Dalton \u2502 \u251c\u2500 email: john.david.dalton@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/lodash \u2502 \u2514\u2500 licenseFile: node_modules/lodash/LICENSE \u251c\u2500 lru-cache@4.1.5 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/node-lru-cache \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/lru-cache \u2502 \u2514\u2500 licenseFile: node_modules/lru-cache/LICENSE \u251c\u2500 lunr@2.3.9 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/olivernn/lunr.js \u2502 \u251c\u2500 publisher: Oliver Nightingale \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/lunr \u2502 \u2514\u2500 licenseFile: node_modules/lunr/LICENSE \u251c\u2500 make-dir@3.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/make-dir \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/make-dir \u2502 \u2514\u2500 licenseFile: node_modules/make-dir/license \u251c\u2500 marked@1.2.9 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/markedjs/marked \u2502 \u251c\u2500 publisher: Christopher Jeffrey \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/marked \u2502 \u2514\u2500 licenseFile: node_modules/marked/LICENSE.md \u251c\u2500 md5.js@1.3.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/md5.js \u2502 \u251c\u2500 publisher: Kirill Fomichev \u2502 \u251c\u2500 email: fanatid@ya.ru \u2502 \u251c\u2500 url: https://github.com/fanatid \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/md5.js \u2502 \u2514\u2500 licenseFile: node_modules/md5.js/LICENSE \u251c\u2500 memory-fs@0.5.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/memory-fs \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/memory-fs \u2502 \u2514\u2500 licenseFile: node_modules/memory-fs/LICENSE \u251c\u2500 merge-stream@2.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/grncdr/merge-stream \u2502 \u251c\u2500 publisher: Stephen Sugden \u2502 \u251c\u2500 email: me@stephensugden.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/merge-stream \u2502 \u2514\u2500 licenseFile: node_modules/merge-stream/LICENSE \u251c\u2500 micromatch@4.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/micromatch \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/micromatch \u2502 \u2514\u2500 licenseFile: node_modules/micromatch/LICENSE \u251c\u2500 miller-rabin@4.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/miller-rabin \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/miller-rabin \u2502 \u2514\u2500 licenseFile: node_modules/miller-rabin/README.md \u251c\u2500 mime-db@1.46.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jshttp/mime-db \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/mime-db \u2502 \u2514\u2500 licenseFile: node_modules/mime-db/LICENSE \u251c\u2500 mime-types@2.1.29 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jshttp/mime-types \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/mime-types \u2502 \u2514\u2500 licenseFile: node_modules/mime-types/LICENSE \u251c\u2500 minimalistic-assert@1.0.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/calvinmetcalf/minimalistic-assert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minimalistic-assert \u2502 \u2514\u2500 licenseFile: node_modules/minimalistic-assert/LICENSE \u251c\u2500 minimalistic-crypto-utils@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/minimalistic-crypto-utils \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minimalistic-crypto-utils \u2502 \u2514\u2500 licenseFile: node_modules/minimalistic-crypto-utils/README.md \u251c\u2500 minimatch@3.0.4 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/minimatch \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minimatch \u2502 \u2514\u2500 licenseFile: node_modules/minimatch/LICENSE \u251c\u2500 minimist@1.2.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/minimist \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minimist \u2502 \u2514\u2500 licenseFile: node_modules/minimist/LICENSE \u251c\u2500 minipass-collect@1.0.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: https://izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minipass-collect \u2502 \u2514\u2500 licenseFile: node_modules/minipass-collect/LICENSE \u251c\u2500 minipass-flush@1.0.5 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/minipass-flush \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: https://izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minipass-flush \u2502 \u2514\u2500 licenseFile: node_modules/minipass-flush/LICENSE \u251c\u2500 minipass-pipeline@1.2.4 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: https://izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minipass-pipeline \u2502 \u2514\u2500 licenseFile: node_modules/minipass-pipeline/LICENSE \u251c\u2500 minipass@3.1.3 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/minipass \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minipass \u2502 \u2514\u2500 licenseFile: node_modules/minipass/LICENSE \u251c\u2500 mkdirp@0.5.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/node-mkdirp \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/mkdirp \u2502 \u2514\u2500 licenseFile: node_modules/mkdirp/LICENSE \u251c\u2500 moment@2.29.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/moment/moment \u2502 \u251c\u2500 publisher: Iskren Ivov Chernev \u2502 \u251c\u2500 email: iskren.chernev@gmail.com \u2502 \u251c\u2500 url: https://github.com/ichernev \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/moment \u2502 \u2514\u2500 licenseFile: node_modules/moment/LICENSE \u251c\u2500 neo-async@2.6.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/suguru03/neo-async \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/neo-async \u2502 \u2514\u2500 licenseFile: node_modules/neo-async/LICENSE \u251c\u2500 ng2-file-upload@1.4.0 \u2502 \u251c\u2500 licenses: UNKNOWN \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/ng2-file-upload \u251c\u2500 ngx-clipboard@12.3.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/maxisam/ngx-clipboard \u2502 \u251c\u2500 publisher: Sam Lin \u2502 \u251c\u2500 email: maxisam@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ngx-clipboard \u2502 \u2514\u2500 licenseFile: node_modules/ngx-clipboard/README.md \u251c\u2500 ngx-markdown@10.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jfcere/ngx-markdown \u2502 \u251c\u2500 publisher: Jean-Francois Cere \u2502 \u251c\u2500 email: jfcere@sherweb.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ngx-markdown \u2502 \u2514\u2500 licenseFile: node_modules/ngx-markdown/LICENSE \u251c\u2500 ngx-window-token@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/maxisam/ngx-window-token \u2502 \u251c\u2500 publisher: Sam Lin \u2502 \u251c\u2500 email: maxisam@gmail.com \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/ngx-window-token \u251c\u2500 node-libs-browser@2.2.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/node-libs-browser \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/node-libs-browser \u2502 \u2514\u2500 licenseFile: node_modules/node-libs-browser/LICENSE \u251c\u2500 nodejs@0.0.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/nodejs \u251c\u2500 normalize-path@3.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/normalize-path \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/normalize-path \u2502 \u2514\u2500 licenseFile: node_modules/normalize-path/LICENSE \u251c\u2500 numbro@2.3.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/BenjaminVanRyseghem/numbro \u2502 \u251c\u2500 publisher: Benjamin Van Ryseghem \u2502 \u251c\u2500 email: benjamin@vanryseghem.com \u2502 \u251c\u2500 url: https://benjamin.vanryseghem.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/numbro \u2502 \u2514\u2500 licenseFile: node_modules/numbro/LICENSE \u251c\u2500 object-assign@4.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/object-assign \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/object-assign \u2502 \u2514\u2500 licenseFile: node_modules/object-assign/license \u251c\u2500 once@1.4.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/once \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/once \u2502 \u2514\u2500 licenseFile: node_modules/once/LICENSE \u251c\u2500 os-browserify@0.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/CoderPuppy/os-browserify \u2502 \u251c\u2500 publisher: CoderPuppy \u2502 \u251c\u2500 email: coderpup@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/os-browserify \u2502 \u2514\u2500 licenseFile: node_modules/os-browserify/LICENSE \u251c\u2500 p-limit@2.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/p-limit \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/p-limit \u2502 \u2514\u2500 licenseFile: node_modules/p-limit/license \u251c\u2500 p-map@4.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/p-map \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: https://sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/p-map \u2502 \u2514\u2500 licenseFile: node_modules/p-map/license \u251c\u2500 p-try@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/p-try \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/p-try \u2502 \u2514\u2500 licenseFile: node_modules/p-try/license \u251c\u2500 pako@1.0.11 \u2502 \u251c\u2500 licenses: (MIT AND Zlib) \u2502 \u251c\u2500 repository: https://github.com/nodeca/pako \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pako \u2502 \u2514\u2500 licenseFile: node_modules/pako/LICENSE \u251c\u2500 parse-asn1@5.1.6 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/parse-asn1 \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/parse-asn1 \u2502 \u2514\u2500 licenseFile: node_modules/parse-asn1/LICENSE \u251c\u2500 path-browserify@0.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/path-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/path-browserify \u2502 \u2514\u2500 licenseFile: node_modules/path-browserify/LICENSE \u251c\u2500 path-exists@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/path-exists \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/path-exists \u2502 \u2514\u2500 licenseFile: node_modules/path-exists/license \u251c\u2500 path-is-absolute@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/path-is-absolute \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/path-is-absolute \u2502 \u2514\u2500 licenseFile: node_modules/path-is-absolute/license \u251c\u2500 path-parse@1.0.6 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jbgutierrez/path-parse \u2502 \u251c\u2500 publisher: Javier Blanco \u2502 \u251c\u2500 email: http://jbgutierrez.info \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/path-parse \u2502 \u2514\u2500 licenseFile: node_modules/path-parse/LICENSE \u251c\u2500 pbkdf2@3.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/pbkdf2 \u2502 \u251c\u2500 publisher: Daniel Cousens \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pbkdf2 \u2502 \u2514\u2500 licenseFile: node_modules/pbkdf2/LICENSE \u251c\u2500 php-date-formatter@1.3.6 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/kartik-v/php-date-formatter \u2502 \u251c\u2500 publisher: Kartik Visweswaran \u2502 \u251c\u2500 email: kartikv2@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/php-date-formatter \u2502 \u2514\u2500 licenseFile: node_modules/php-date-formatter/LICENSE.md \u251c\u2500 picomatch@2.2.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/picomatch \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/picomatch \u2502 \u2514\u2500 licenseFile: node_modules/picomatch/LICENSE \u251c\u2500 pify@2.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/pify \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pify \u2502 \u2514\u2500 licenseFile: node_modules/pify/license \u251c\u2500 pikaday@1.8.0 \u2502 \u251c\u2500 licenses: (0BSD OR MIT) \u2502 \u251c\u2500 repository: https://github.com/Pikaday/Pikaday \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pikaday \u2502 \u2514\u2500 licenseFile: node_modules/pikaday/LICENSE \u251c\u2500 pinkie-promise@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/floatdrop/pinkie-promise \u2502 \u251c\u2500 publisher: Vsevolod Strukchinsky \u2502 \u251c\u2500 email: floatdrop@gmail.com \u2502 \u251c\u2500 url: github.com/floatdrop \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pinkie-promise \u2502 \u2514\u2500 licenseFile: node_modules/pinkie-promise/license \u251c\u2500 pinkie@2.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/floatdrop/pinkie \u2502 \u251c\u2500 publisher: Vsevolod Strukchinsky \u2502 \u251c\u2500 email: floatdrop@gmail.com \u2502 \u251c\u2500 url: github.com/floatdrop \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pinkie \u2502 \u2514\u2500 licenseFile: node_modules/pinkie/license \u251c\u2500 pkg-dir@4.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/pkg-dir \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pkg-dir \u2502 \u2514\u2500 licenseFile: node_modules/pkg-dir/license \u251c\u2500 prismjs@1.23.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/PrismJS/prism \u2502 \u251c\u2500 publisher: Lea Verou \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/prismjs \u2502 \u2514\u2500 licenseFile: node_modules/prismjs/LICENSE \u251c\u2500 process-nextick-args@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/calvinmetcalf/process-nextick-args \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/process-nextick-args \u2502 \u2514\u2500 licenseFile: node_modules/process-nextick-args/license.md \u251c\u2500 process@0.11.10 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/shtylman/node-process \u2502 \u251c\u2500 publisher: Roman Shtylman \u2502 \u251c\u2500 email: shtylman@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/process \u2502 \u2514\u2500 licenseFile: node_modules/process/LICENSE \u251c\u2500 progress@2.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/visionmedia/node-progress \u2502 \u251c\u2500 publisher: TJ Holowaychuk \u2502 \u251c\u2500 email: tj@vision-media.ca \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/progress \u2502 \u2514\u2500 licenseFile: node_modules/progress/LICENSE \u251c\u2500 promise-inflight@1.0.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/iarna/promise-inflight \u2502 \u251c\u2500 publisher: Rebecca Turner \u2502 \u251c\u2500 email: me@re-becca.org \u2502 \u251c\u2500 url: http://re-becca.org/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/promise-inflight \u2502 \u2514\u2500 licenseFile: node_modules/promise-inflight/LICENSE \u251c\u2500 prompts@2.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/terkelg/prompts \u2502 \u251c\u2500 publisher: Terkel Gjervig \u2502 \u251c\u2500 email: terkel@terkel.com \u2502 \u251c\u2500 url: https://terkel.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/prompts \u2502 \u2514\u2500 licenseFile: node_modules/prompts/license \u251c\u2500 prr@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/rvagg/prr \u2502 \u251c\u2500 publisher: Rod Vagg \u2502 \u251c\u2500 email: rod@vagg.org \u2502 \u251c\u2500 url: https://github.com/rvagg \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/prr \u2502 \u2514\u2500 licenseFile: node_modules/prr/LICENSE.md \u251c\u2500 pseudomap@1.0.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/pseudomap \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pseudomap \u2502 \u2514\u2500 licenseFile: node_modules/pseudomap/LICENSE \u251c\u2500 public-encrypt@4.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/publicEncrypt \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/public-encrypt \u2502 \u2514\u2500 licenseFile: node_modules/public-encrypt/LICENSE \u251c\u2500 punycode@2.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/bestiejs/punycode.js \u2502 \u251c\u2500 publisher: Mathias Bynens \u2502 \u251c\u2500 url: https://mathiasbynens.be/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/punycode \u2502 \u2514\u2500 licenseFile: node_modules/punycode/LICENSE-MIT.txt \u251c\u2500 querystring-es3@0.2.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/mike-spainhower/querystring \u2502 \u251c\u2500 publisher: Irakli Gozalishvili \u2502 \u251c\u2500 email: rfobic@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/querystring-es3 \u2502 \u2514\u2500 licenseFile: node_modules/querystring-es3/License.md \u251c\u2500 querystring@0.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Gozala/querystring \u2502 \u251c\u2500 publisher: Irakli Gozalishvili \u2502 \u251c\u2500 email: rfobic@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/querystring \u2502 \u2514\u2500 licenseFile: node_modules/querystring/License.md \u251c\u2500 randombytes@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/randombytes \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/randombytes \u2502 \u2514\u2500 licenseFile: node_modules/randombytes/LICENSE \u251c\u2500 randomfill@1.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/randomfill \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/randomfill \u2502 \u2514\u2500 licenseFile: node_modules/randomfill/LICENSE \u251c\u2500 readable-stream@2.3.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/nodejs/readable-stream \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/readable-stream \u2502 \u2514\u2500 licenseFile: node_modules/readable-stream/LICENSE \u251c\u2500 readdirp@3.5.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/paulmillr/readdirp \u2502 \u251c\u2500 publisher: Thorsten Lorenz \u2502 \u251c\u2500 email: thlorenz@gmx.de \u2502 \u251c\u2500 url: thlorenz.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/readdirp \u2502 \u2514\u2500 licenseFile: node_modules/readdirp/LICENSE \u251c\u2500 rechoir@0.6.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/tkellen/node-rechoir \u2502 \u251c\u2500 publisher: Tyler Kellen \u2502 \u251c\u2500 url: http://goingslowly.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/rechoir \u2502 \u2514\u2500 licenseFile: node_modules/rechoir/LICENSE \u251c\u2500 repeating@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/repeating \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/repeating \u2502 \u2514\u2500 licenseFile: node_modules/repeating/license \u251c\u2500 resolve@1.20.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/browserify/resolve \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/resolve \u2502 \u2514\u2500 licenseFile: node_modules/resolve/LICENSE \u251c\u2500 rimraf@2.7.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/rimraf \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/rimraf \u2502 \u2514\u2500 licenseFile: node_modules/rimraf/LICENSE \u251c\u2500 ripemd160@2.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/ripemd160 \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ripemd160 \u2502 \u2514\u2500 licenseFile: node_modules/ripemd160/LICENSE \u251c\u2500 rxjs-compat@6.6.6 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/rxjs-compat \u2502 \u2514\u2500 licenseFile: node_modules/rxjs-compat/LICENSE.txt \u251c\u2500 rxjs@6.6.6 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/reactivex/rxjs \u2502 \u251c\u2500 publisher: Ben Lesh \u2502 \u251c\u2500 email: ben@benlesh.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/rxjs \u2502 \u2514\u2500 licenseFile: node_modules/rxjs/LICENSE.txt \u251c\u2500 safe-buffer@5.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/feross/safe-buffer \u2502 \u251c\u2500 publisher: Feross Aboukhadijeh \u2502 \u251c\u2500 email: feross@feross.org \u2502 \u251c\u2500 url: http://feross.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/safe-buffer \u2502 \u2514\u2500 licenseFile: node_modules/safe-buffer/LICENSE \u251c\u2500 safer-buffer@2.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/ChALkeR/safer-buffer \u2502 \u251c\u2500 publisher: Nikita Skovoroda \u2502 \u251c\u2500 email: chalkerx@gmail.com \u2502 \u251c\u2500 url: https://github.com/ChALkeR \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/safer-buffer \u2502 \u2514\u2500 licenseFile: node_modules/safer-buffer/LICENSE \u251c\u2500 sass-loader@7.3.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack-contrib/sass-loader \u2502 \u251c\u2500 publisher: J. Tangelder \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/sass-loader \u2502 \u2514\u2500 licenseFile: node_modules/sass-loader/LICENSE \u251c\u2500 save-svg-as-png@1.4.17 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/exupero/saveSvgAsPng \u2502 \u251c\u2500 publisher: Eric Shull \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/save-svg-as-png \u2502 \u2514\u2500 licenseFile: node_modules/save-svg-as-png/LICENSE \u251c\u2500 schema-utils@2.7.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/schema-utils \u2502 \u251c\u2500 publisher: webpack Contrib \u2502 \u251c\u2500 url: https://github.com/webpack-contrib \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/schema-utils \u2502 \u2514\u2500 licenseFile: node_modules/schema-utils/LICENSE \u251c\u2500 select@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zenorocha/select \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/select \u2502 \u2514\u2500 licenseFile: node_modules/select/readme.md \u251c\u2500 semver@5.7.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/node-semver \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/semver \u2502 \u2514\u2500 licenseFile: node_modules/semver/LICENSE \u251c\u2500 serialize-javascript@5.0.1 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/yahoo/serialize-javascript \u2502 \u251c\u2500 publisher: Eric Ferraiuolo \u2502 \u251c\u2500 email: edf@ericf.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/serialize-javascript \u2502 \u2514\u2500 licenseFile: node_modules/serialize-javascript/LICENSE \u251c\u2500 setimmediate@1.0.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/YuzuJS/setImmediate \u2502 \u251c\u2500 publisher: YuzuJS \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/setimmediate \u2502 \u2514\u2500 licenseFile: node_modules/setimmediate/LICENSE.txt \u251c\u2500 sha.js@2.4.11 \u2502 \u251c\u2500 licenses: (MIT AND BSD-3-Clause) \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/sha.js \u2502 \u251c\u2500 publisher: Dominic Tarr \u2502 \u251c\u2500 email: dominic.tarr@gmail.com \u2502 \u251c\u2500 url: dominictarr.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/sha.js \u2502 \u2514\u2500 licenseFile: node_modules/sha.js/LICENSE \u251c\u2500 shallow-clone@3.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/shallow-clone \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/shallow-clone \u2502 \u2514\u2500 licenseFile: node_modules/shallow-clone/LICENSE \u251c\u2500 shelljs@0.8.4 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/shelljs/shelljs \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/shelljs \u2502 \u2514\u2500 licenseFile: node_modules/shelljs/LICENSE \u251c\u2500 sisteransi@1.0.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/terkelg/sisteransi \u2502 \u251c\u2500 publisher: Terkel Gjervig \u2502 \u251c\u2500 email: terkel@terkel.com \u2502 \u251c\u2500 url: https://terkel.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/sisteransi \u2502 \u2514\u2500 licenseFile: node_modules/sisteransi/license \u251c\u2500 sl-blip@1.0.0 \u2502 \u251c\u2500 licenses: UNKNOWN \u2502 \u251c\u2500 repository: none \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/sl-blip \u251c\u2500 source-list-map@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/source-list-map \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/source-list-map \u2502 \u2514\u2500 licenseFile: node_modules/source-list-map/LICENSE \u251c\u2500 source-map-support@0.5.19 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/evanw/node-source-map-support \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/source-map-support \u2502 \u2514\u2500 licenseFile: node_modules/source-map-support/LICENSE.md \u251c\u2500 ssri@8.0.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/ssri \u2502 \u251c\u2500 publisher: Kat March\u00e1n \u2502 \u251c\u2500 email: kzm@sykosomatic.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ssri \u2502 \u2514\u2500 licenseFile: node_modules/ssri/LICENSE.md \u251c\u2500 stream-browserify@2.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/browserify/stream-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/stream-browserify \u2502 \u2514\u2500 licenseFile: node_modules/stream-browserify/LICENSE \u251c\u2500 stream-http@2.8.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jhiesey/stream-http \u2502 \u251c\u2500 publisher: John Hiesey \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/stream-http \u2502 \u2514\u2500 licenseFile: node_modules/stream-http/LICENSE \u251c\u2500 string_decoder@1.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/nodejs/string_decoder \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/string_decoder \u2502 \u2514\u2500 licenseFile: node_modules/string_decoder/LICENSE \u251c\u2500 strip-ansi@3.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/strip-ansi \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/strip-ansi \u2502 \u2514\u2500 licenseFile: node_modules/strip-ansi/license \u251c\u2500 supports-color@2.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/supports-color \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/supports-color \u2502 \u2514\u2500 licenseFile: node_modules/supports-color/license \u251c\u2500 tapable@1.1.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/tapable \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/tapable \u2502 \u2514\u2500 licenseFile: node_modules/tapable/LICENSE \u251c\u2500 terser-webpack-plugin@4.2.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack-contrib/terser-webpack-plugin \u2502 \u251c\u2500 publisher: webpack Contrib Team \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/terser-webpack-plugin \u2502 \u2514\u2500 licenseFile: node_modules/terser-webpack-plugin/LICENSE \u251c\u2500 terser@5.5.1 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/terser/terser \u2502 \u251c\u2500 publisher: Mihai Bazon \u2502 \u251c\u2500 email: mihai.bazon@gmail.com \u2502 \u251c\u2500 url: http://lisperator.net/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/terser \u2502 \u2514\u2500 licenseFile: node_modules/terser/LICENSE \u251c\u2500 text-encoding@0.7.0 \u2502 \u251c\u2500 licenses: (Unlicense OR Apache-2.0) \u2502 \u251c\u2500 repository: https://github.com/inexorabletash/text-encoding \u2502 \u251c\u2500 publisher: Joshua Bell \u2502 \u251c\u2500 email: inexorabletash@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/text-encoding \u2502 \u2514\u2500 licenseFile: node_modules/text-encoding/LICENSE.md \u251c\u2500 timers-browserify@2.0.12 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jryans/timers-browserify \u2502 \u251c\u2500 publisher: J. Ryan Stinnett \u2502 \u251c\u2500 email: jryans@gmail.com \u2502 \u251c\u2500 url: https://convolv.es/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/timers-browserify \u2502 \u2514\u2500 licenseFile: node_modules/timers-browserify/LICENSE.md \u251c\u2500 tiny-emitter@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/scottcorgan/tiny-emitter \u2502 \u251c\u2500 publisher: Scott Corgan \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/tiny-emitter \u2502 \u2514\u2500 licenseFile: node_modules/tiny-emitter/LICENSE \u251c\u2500 to-arraybuffer@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jhiesey/to-arraybuffer \u2502 \u251c\u2500 publisher: John Hiesey \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/to-arraybuffer \u2502 \u2514\u2500 licenseFile: node_modules/to-arraybuffer/LICENSE \u251c\u2500 to-regex-range@5.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/to-regex-range \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/to-regex-range \u2502 \u2514\u2500 licenseFile: node_modules/to-regex-range/LICENSE \u251c\u2500 ts-helpers@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/ngParty/ts-helpers \u2502 \u251c\u2500 publisher: Martin Hochel \u2502 \u251c\u2500 email: hochelmartin@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ts-helpers \u2502 \u2514\u2500 licenseFile: node_modules/ts-helpers/LICENSE \u251c\u2500 tslib@2.1.0 \u2502 \u251c\u2500 licenses: 0BSD \u2502 \u251c\u2500 repository: https://github.com/Microsoft/tslib \u2502 \u251c\u2500 publisher: Microsoft Corp. \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/tslib \u2502 \u2514\u2500 licenseFile: node_modules/tslib/LICENSE.txt \u251c\u2500 tty-browserify@0.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/tty-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/tty-browserify \u2502 \u2514\u2500 licenseFile: node_modules/tty-browserify/LICENSE \u251c\u2500 typedoc-default-themes@0.12.9 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/TypeStrong/typedoc-default-themes \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/typedoc-default-themes \u2502 \u2514\u2500 licenseFile: node_modules/typedoc-default-themes/LICENSE \u251c\u2500 typedoc-neo-theme@1.1.0 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/google/typedoc-neo-theme \u2502 \u251c\u2500 publisher: Nick Felker, based on work by Sebastian Lenz \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/typedoc-neo-theme \u2502 \u2514\u2500 licenseFile: node_modules/typedoc-neo-theme/LICENSE \u251c\u2500 typedoc@0.16.11 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/TypeStrong/TypeDoc \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/typedoc \u2502 \u2514\u2500 licenseFile: node_modules/typedoc/LICENSE \u251c\u2500 typescript@4.1.5 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/Microsoft/TypeScript \u2502 \u251c\u2500 publisher: Microsoft Corp. \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/typescript \u2502 \u2514\u2500 licenseFile: node_modules/typescript/LICENSE.txt \u251c\u2500 uglify-js@3.13.2 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/mishoo/UglifyJS \u2502 \u251c\u2500 publisher: Mihai Bazon \u2502 \u251c\u2500 email: mihai.bazon@gmail.com \u2502 \u251c\u2500 url: http://lisperator.net/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/uglify-js \u2502 \u2514\u2500 licenseFile: node_modules/uglify-js/LICENSE \u251c\u2500 unique-filename@1.1.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/iarna/unique-filename \u2502 \u251c\u2500 publisher: Rebecca Turner \u2502 \u251c\u2500 email: me@re-becca.org \u2502 \u251c\u2500 url: http://re-becca.org/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/unique-filename \u2502 \u2514\u2500 licenseFile: node_modules/unique-filename/LICENSE \u251c\u2500 unique-slug@2.0.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/iarna/unique-slug \u2502 \u251c\u2500 publisher: Rebecca Turner \u2502 \u251c\u2500 email: me@re-becca.org \u2502 \u251c\u2500 url: http://re-becca.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/unique-slug \u2502 \u2514\u2500 licenseFile: node_modules/unique-slug/LICENSE \u251c\u2500 universalify@0.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/RyanZim/universalify \u2502 \u251c\u2500 publisher: Ryan Zimmerman \u2502 \u251c\u2500 email: opensrc@ryanzim.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/universalify \u2502 \u2514\u2500 licenseFile: node_modules/universalify/LICENSE \u251c\u2500 uri-js@4.4.1 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/garycourt/uri-js \u2502 \u251c\u2500 publisher: Gary Court \u2502 \u251c\u2500 email: gary.court@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/uri-js \u2502 \u2514\u2500 licenseFile: node_modules/uri-js/LICENSE \u251c\u2500 url@0.11.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/defunctzombie/node-url \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/url \u2502 \u2514\u2500 licenseFile: node_modules/url/LICENSE \u251c\u2500 util-deprecate@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/TooTallNate/util-deprecate \u2502 \u251c\u2500 publisher: Nathan Rajlich \u2502 \u251c\u2500 email: nathan@tootallnate.net \u2502 \u251c\u2500 url: http://n8.io/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/util-deprecate \u2502 \u2514\u2500 licenseFile: node_modules/util-deprecate/LICENSE \u251c\u2500 util@0.11.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/defunctzombie/node-util \u2502 \u251c\u2500 publisher: Joyent \u2502 \u251c\u2500 url: http://www.joyent.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/util \u2502 \u2514\u2500 licenseFile: node_modules/util/LICENSE \u251c\u2500 valid-url@1.0.9 \u2502 \u251c\u2500 licenses: MIT* \u2502 \u251c\u2500 repository: https://github.com/ogt/valid-url \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/valid-url \u2502 \u2514\u2500 licenseFile: node_modules/valid-url/LICENSE \u251c\u2500 viz.js@1.8.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/mdaines/viz.js \u2502 \u251c\u2500 publisher: Mike Daines \u2502 \u251c\u2500 email: mdaines@fastmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/viz.js \u2502 \u2514\u2500 licenseFile: node_modules/viz.js/LICENSE \u251c\u2500 vm-browserify@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/vm-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/vm-browserify \u2502 \u2514\u2500 licenseFile: node_modules/vm-browserify/LICENSE \u251c\u2500 watchpack-chokidar2@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/watchpack \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/watchpack-chokidar2 \u251c\u2500 watchpack@1.7.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/watchpack \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/watchpack \u2502 \u2514\u2500 licenseFile: node_modules/watchpack/LICENSE \u251c\u2500 web-animations-js@2.3.2 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/web-animations/web-animations-js \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/web-animations-js \u2502 \u2514\u2500 licenseFile: node_modules/web-animations-js/README.md \u251c\u2500 webpack-sources@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/webpack-sources \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/webpack-sources \u2502 \u2514\u2500 licenseFile: node_modules/webpack-sources/LICENSE \u251c\u2500 webpack@4.44.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/webpack \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/webpack \u2502 \u2514\u2500 licenseFile: node_modules/webpack/LICENSE \u251c\u2500 wordwrap@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/node-wordwrap \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/wordwrap \u2502 \u2514\u2500 licenseFile: node_modules/wordwrap/LICENSE \u251c\u2500 wrappy@1.0.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/wrappy \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/wrappy \u2502 \u2514\u2500 licenseFile: node_modules/wrappy/LICENSE \u251c\u2500 xtend@4.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Raynos/xtend \u2502 \u251c\u2500 publisher: Raynos \u2502 \u251c\u2500 email: raynos2@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/xtend \u2502 \u2514\u2500 licenseFile: node_modules/xtend/LICENSE \u251c\u2500 yallist@2.1.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/yallist \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/yallist \u2502 \u2514\u2500 licenseFile: node_modules/yallist/LICENSE \u251c\u2500 zone.js@0.10.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: Brian Ford \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/zone.js \u2502 \u2514\u2500 licenseFile: node_modules/zone.js/LICENSE \u2514\u2500 zone@0.3.4 \u251c\u2500 licenses: Custom: https://api.dartlang.org/apidocs/channels/stable/dartdoc-viewer/dart-async.Zone \u251c\u2500 repository: https://github.com/strongloop/zone \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/zone \u2514\u2500 licenseFile: node_modules/zone/LICENSE.md","title":"Other Licences"},{"location":"licences/#data-controller-for-sas-source-licences","text":"","title":"Data Controller for SAS\u00ae - Source Licences"},{"location":"licences/#overview","text":"Data Controller source licences are extracted automatically from our repo using the license-checker NPM module \u251c\u2500 @angular/animations@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/animations \u2502 \u2514\u2500 licenseFile: node_modules/@angular/animations/README.md \u251c\u2500 @angular/common@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/common \u2502 \u2514\u2500 licenseFile: node_modules/@angular/common/README.md \u251c\u2500 @angular/compiler@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/compiler \u2502 \u2514\u2500 licenseFile: node_modules/@angular/compiler/README.md \u251c\u2500 @angular/core@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/core \u2502 \u2514\u2500 licenseFile: node_modules/@angular/core/README.md \u251c\u2500 @angular/forms@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/forms \u2502 \u2514\u2500 licenseFile: node_modules/@angular/forms/README.md \u251c\u2500 @angular/platform-browser-dynamic@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/platform-browser-dynamic \u2502 \u2514\u2500 licenseFile: node_modules/@angular/platform-browser-dynamic/README.md \u251c\u2500 @angular/platform-browser@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/platform-browser \u2502 \u2514\u2500 licenseFile: node_modules/@angular/platform-browser/README.md \u251c\u2500 @angular/router@11.2.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: angular \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@angular/router \u2502 \u2514\u2500 licenseFile: node_modules/@angular/router/README.md \u251c\u2500 @clr/angular@4.0.14 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/vmware/clarity \u2502 \u251c\u2500 publisher: Clarity Design System \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@clr/angular \u2502 \u2514\u2500 licenseFile: node_modules/@clr/angular/README.md \u251c\u2500 @clr/icons@4.0.14 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: ssh://git@git.eng.vmware.com/clarity \u2502 \u251c\u2500 publisher: clarity \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@clr/icons \u2502 \u2514\u2500 licenseFile: node_modules/@clr/icons/README.md \u251c\u2500 @clr/ui@4.0.14 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/vmware/clarity \u2502 \u251c\u2500 publisher: clarity \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@clr/ui \u2502 \u2514\u2500 licenseFile: node_modules/@clr/ui/README.md \u251c\u2500 @handsontable/angular@7.0.0 \u2502 \u251c\u2500 licenses: Custom: https://handsontable.com \u2502 \u251c\u2500 repository: https://github.com/handsontable/handsontable \u2502 \u251c\u2500 publisher: Handsoncode \u2502 \u251c\u2500 email: hello@handsoncode.net \u2502 \u251c\u2500 url: https://handsoncode.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@handsontable/angular \u2502 \u2514\u2500 licenseFile: node_modules/@handsontable/angular/LICENSE.txt \u251c\u2500 @handsontable/formulajs@2.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/handsontable/formula.js \u2502 \u251c\u2500 publisher: Handsoncode \u2502 \u251c\u2500 email: hello@handsontable.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@handsontable/formulajs \u2502 \u2514\u2500 licenseFile: node_modules/@handsontable/formulajs/LICENSE \u251c\u2500 @npmcli/move-file@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/npm/move-file \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@npmcli/move-file \u2502 \u2514\u2500 licenseFile: node_modules/@npmcli/move-file/LICENSE.md \u251c\u2500 @sasjs/adapter@2.2.17 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/sasjs/adapter \u2502 \u251c\u2500 publisher: Allan Bowe \u2502 \u251c\u2500 email: support@macropeople.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@sasjs/adapter \u2502 \u2514\u2500 licenseFile: node_modules/@sasjs/adapter/LICENSE \u251c\u2500 @sasjs/utils@2.12.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/sasjs/utils \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@sasjs/utils \u2502 \u2514\u2500 licenseFile: node_modules/@sasjs/utils/README.md \u251c\u2500 @sheet/perf@1.20201208.1 \u2502 \u251c\u2500 licenses: MIT* \u2502 \u251c\u2500 publisher: sheetjs \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@sheet/perf \u2502 \u2514\u2500 licenseFile: node_modules/@sheet/perf/README.html \u251c\u2500 @types/d3-color@1.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-color \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-color/LICENSE \u251c\u2500 @types/d3-graphviz@2.6.6 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-graphviz \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-graphviz/LICENSE \u251c\u2500 @types/d3-interpolate@1.4.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-interpolate \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-interpolate/LICENSE \u251c\u2500 @types/d3-selection@1.4.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-selection \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-selection/LICENSE \u251c\u2500 @types/d3-transition@1.3.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-transition \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-transition/LICENSE \u251c\u2500 @types/d3-zoom@1.8.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/d3-zoom \u2502 \u2514\u2500 licenseFile: node_modules/@types/d3-zoom/LICENSE \u251c\u2500 @types/json-schema@7.0.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/json-schema \u2502 \u2514\u2500 licenseFile: node_modules/@types/json-schema/LICENSE \u251c\u2500 @types/marked@1.2.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/marked \u2502 \u2514\u2500 licenseFile: node_modules/@types/marked/LICENSE \u251c\u2500 @types/minimatch@3.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/minimatch \u2502 \u2514\u2500 licenseFile: node_modules/@types/minimatch/LICENSE \u251c\u2500 @types/node@12.20.6 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/node \u2502 \u2514\u2500 licenseFile: node_modules/@types/node/LICENSE \u251c\u2500 @types/pikaday@1.7.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/pikaday \u2502 \u2514\u2500 licenseFile: node_modules/@types/pikaday/LICENSE \u251c\u2500 @types/prompts@2.0.11 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/prompts \u2502 \u2514\u2500 licenseFile: node_modules/@types/prompts/LICENSE \u251c\u2500 @types/text-encoding@0.0.35 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/DefinitelyTyped/DefinitelyTyped \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@types/text-encoding \u2502 \u2514\u2500 licenseFile: node_modules/@types/text-encoding/LICENSE \u251c\u2500 @webassemblyjs/ast@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/ast \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/ast/LICENSE \u251c\u2500 @webassemblyjs/floating-point-hex-parser@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Mauro Bringolf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/floating-point-hex-parser \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/floating-point-hex-parser/LICENSE \u251c\u2500 @webassemblyjs/helper-api-error@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-api-error \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-api-error/LICENSE \u251c\u2500 @webassemblyjs/helper-buffer@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-buffer \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-buffer/LICENSE \u251c\u2500 @webassemblyjs/helper-code-frame@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-code-frame \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-code-frame/LICENSE \u251c\u2500 @webassemblyjs/helper-fsm@1.9.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 publisher: Mauro Bringolf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-fsm \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-fsm/LICENSE \u251c\u2500 @webassemblyjs/helper-module-context@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-module-context \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-module-context/LICENSE \u251c\u2500 @webassemblyjs/helper-wasm-bytecode@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-wasm-bytecode \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-wasm-bytecode/LICENSE \u251c\u2500 @webassemblyjs/helper-wasm-section@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/helper-wasm-section \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/helper-wasm-section/LICENSE \u251c\u2500 @webassemblyjs/ieee754@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/ieee754 \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/ieee754/LICENSE \u251c\u2500 @webassemblyjs/leb128@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/leb128 \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/leb128/LICENSE.txt \u251c\u2500 @webassemblyjs/utf8@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/utf8 \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/utf8/LICENSE \u251c\u2500 @webassemblyjs/wasm-edit@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wasm-edit \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wasm-edit/LICENSE \u251c\u2500 @webassemblyjs/wasm-gen@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wasm-gen \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wasm-gen/LICENSE \u251c\u2500 @webassemblyjs/wasm-opt@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wasm-opt \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wasm-opt/LICENSE \u251c\u2500 @webassemblyjs/wasm-parser@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wasm-parser \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wasm-parser/LICENSE \u251c\u2500 @webassemblyjs/wast-parser@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wast-parser \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wast-parser/LICENSE \u251c\u2500 @webassemblyjs/wast-printer@1.9.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xtuc/webassemblyjs \u2502 \u251c\u2500 publisher: Sven Sauleau \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webassemblyjs/wast-printer \u2502 \u2514\u2500 licenseFile: node_modules/@webassemblyjs/wast-printer/LICENSE \u251c\u2500 @webcomponents/custom-elements@1.4.3 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/webcomponents/polyfills \u2502 \u251c\u2500 publisher: The Polymer Project Authors \u2502 \u251c\u2500 url: https://polymer.github.io/AUTHORS.txt \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@webcomponents/custom-elements \u2502 \u2514\u2500 licenseFile: node_modules/@webcomponents/custom-elements/LICENSE.md \u251c\u2500 @xtuc/ieee754@1.2.0 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/feross/ieee754 \u2502 \u251c\u2500 publisher: Feross Aboukhadijeh \u2502 \u251c\u2500 email: feross@feross.org \u2502 \u251c\u2500 url: http://feross.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@xtuc/ieee754 \u2502 \u2514\u2500 licenseFile: node_modules/@xtuc/ieee754/LICENSE \u251c\u2500 @xtuc/long@4.2.2 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/dcodeIO/long.js \u2502 \u251c\u2500 publisher: Daniel Wirtz \u2502 \u251c\u2500 email: dcode@dcode.io \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/@xtuc/long \u2502 \u2514\u2500 licenseFile: node_modules/@xtuc/long/LICENSE \u251c\u2500 acorn@6.4.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/acornjs/acorn \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/acorn \u2502 \u2514\u2500 licenseFile: node_modules/acorn/LICENSE \u251c\u2500 aggregate-error@3.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/aggregate-error \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/aggregate-error \u2502 \u2514\u2500 licenseFile: node_modules/aggregate-error/license \u251c\u2500 ajv-keywords@3.5.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/epoberezkin/ajv-keywords \u2502 \u251c\u2500 publisher: Evgeny Poberezkin \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ajv-keywords \u2502 \u2514\u2500 licenseFile: node_modules/ajv-keywords/LICENSE \u251c\u2500 ajv@6.12.6 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/ajv-validator/ajv \u2502 \u251c\u2500 publisher: Evgeny Poberezkin \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ajv \u2502 \u2514\u2500 licenseFile: node_modules/ajv/LICENSE \u251c\u2500 angular-prism@0.1.20 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/vaibhav93/angular-prism \u2502 \u251c\u2500 publisher: Vaibhav Bansal \u2502 \u251c\u2500 email: vaibhavbansal1993@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/angular-prism \u2502 \u2514\u2500 licenseFile: node_modules/angular-prism/README.MD \u251c\u2500 ansi-regex@2.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/ansi-regex \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ansi-regex \u2502 \u2514\u2500 licenseFile: node_modules/ansi-regex/license \u251c\u2500 ansi-styles@2.2.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/ansi-styles \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ansi-styles \u2502 \u2514\u2500 licenseFile: node_modules/ansi-styles/license \u251c\u2500 anymatch@3.1.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/micromatch/anymatch \u2502 \u251c\u2500 publisher: Elan Shanker \u2502 \u251c\u2500 url: https://github.com/es128 \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/anymatch \u2502 \u2514\u2500 licenseFile: node_modules/anymatch/LICENSE \u251c\u2500 asn1.js@5.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/asn1.js \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/asn1.js \u2502 \u2514\u2500 licenseFile: node_modules/asn1.js/LICENSE \u251c\u2500 assert@1.5.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/browserify/commonjs-assert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/assert \u2502 \u2514\u2500 licenseFile: node_modules/assert/LICENSE \u251c\u2500 asynckit@0.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/alexindigo/asynckit \u2502 \u251c\u2500 publisher: Alex Indigo \u2502 \u251c\u2500 email: iam@alexindigo.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/asynckit \u2502 \u2514\u2500 licenseFile: node_modules/asynckit/LICENSE \u251c\u2500 axios@0.21.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/axios/axios \u2502 \u251c\u2500 publisher: Matt Zabriskie \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/axios \u2502 \u2514\u2500 licenseFile: node_modules/axios/LICENSE \u251c\u2500 balanced-match@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/juliangruber/balanced-match \u2502 \u251c\u2500 publisher: Julian Gruber \u2502 \u251c\u2500 email: mail@juliangruber.com \u2502 \u251c\u2500 url: http://juliangruber.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/balanced-match \u2502 \u2514\u2500 licenseFile: node_modules/balanced-match/LICENSE.md \u251c\u2500 base64-arraybuffer@0.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/niklasvh/base64-arraybuffer \u2502 \u251c\u2500 publisher: Niklas von Hertzen \u2502 \u251c\u2500 email: niklasvh@gmail.com \u2502 \u251c\u2500 url: https://hertzen.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/base64-arraybuffer \u2502 \u2514\u2500 licenseFile: node_modules/base64-arraybuffer/LICENSE-MIT \u251c\u2500 base64-js@1.5.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/beatgammit/base64-js \u2502 \u251c\u2500 publisher: T. Jameson Little \u2502 \u251c\u2500 email: t.jameson.little@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/base64-js \u2502 \u2514\u2500 licenseFile: node_modules/base64-js/LICENSE \u251c\u2500 bessel@1.0.2 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/SheetJS/bessel \u2502 \u251c\u2500 publisher: SheetJS \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/bessel \u2502 \u2514\u2500 licenseFile: node_modules/bessel/LICENSE \u251c\u2500 big.js@5.2.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/MikeMcl/big.js \u2502 \u251c\u2500 publisher: Michael Mclaughlin \u2502 \u251c\u2500 email: M8ch88l@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/big.js \u2502 \u2514\u2500 licenseFile: node_modules/big.js/LICENCE \u251c\u2500 bignumber.js@8.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/MikeMcl/bignumber.js \u2502 \u251c\u2500 publisher: Michael Mclaughlin \u2502 \u251c\u2500 email: M8ch88l@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/bignumber.js \u2502 \u2514\u2500 licenseFile: node_modules/bignumber.js/LICENCE \u251c\u2500 binary-extensions@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/binary-extensions \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/binary-extensions \u2502 \u2514\u2500 licenseFile: node_modules/binary-extensions/license \u251c\u2500 bn.js@5.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/bn.js \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/bn.js \u2502 \u2514\u2500 licenseFile: node_modules/bn.js/LICENSE \u251c\u2500 brace-expansion@1.1.11 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/juliangruber/brace-expansion \u2502 \u251c\u2500 publisher: Julian Gruber \u2502 \u251c\u2500 email: mail@juliangruber.com \u2502 \u251c\u2500 url: http://juliangruber.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/brace-expansion \u2502 \u2514\u2500 licenseFile: node_modules/brace-expansion/LICENSE \u251c\u2500 braces@3.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/braces \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/braces \u2502 \u2514\u2500 licenseFile: node_modules/braces/LICENSE \u251c\u2500 brorand@1.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/brorand \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/brorand \u2502 \u2514\u2500 licenseFile: node_modules/brorand/README.md \u251c\u2500 browserify-aes@1.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-aes \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-aes \u2502 \u2514\u2500 licenseFile: node_modules/browserify-aes/LICENSE \u251c\u2500 browserify-cipher@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-cipher \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 email: calvin.metcalf@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-cipher \u2502 \u2514\u2500 licenseFile: node_modules/browserify-cipher/LICENSE \u251c\u2500 browserify-des@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-des \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 email: calvin.metcalf@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-des \u2502 \u2514\u2500 licenseFile: node_modules/browserify-des/license \u251c\u2500 browserify-rsa@4.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-rsa \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-rsa \u2502 \u2514\u2500 licenseFile: node_modules/browserify-rsa/LICENSE \u251c\u2500 browserify-sign@4.2.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/browserify-sign \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-sign \u2502 \u2514\u2500 licenseFile: node_modules/browserify-sign/LICENSE \u251c\u2500 browserify-zlib@0.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/devongovett/browserify-zlib \u2502 \u251c\u2500 publisher: Devon Govett \u2502 \u251c\u2500 email: devongovett@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/browserify-zlib \u2502 \u2514\u2500 licenseFile: node_modules/browserify-zlib/LICENSE \u251c\u2500 buffer-from@1.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/LinusU/buffer-from \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/buffer-from \u2502 \u2514\u2500 licenseFile: node_modules/buffer-from/LICENSE \u251c\u2500 buffer-xor@1.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/buffer-xor \u2502 \u251c\u2500 publisher: Daniel Cousens \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/buffer-xor \u2502 \u2514\u2500 licenseFile: node_modules/buffer-xor/LICENSE \u251c\u2500 buffer@5.7.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/feross/buffer \u2502 \u251c\u2500 publisher: Feross Aboukhadijeh \u2502 \u251c\u2500 email: feross@feross.org \u2502 \u251c\u2500 url: https://feross.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/buffer \u2502 \u2514\u2500 licenseFile: node_modules/buffer/LICENSE \u251c\u2500 builtin-status-codes@3.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/bendrucker/builtin-status-codes \u2502 \u251c\u2500 publisher: Ben Drucker \u2502 \u251c\u2500 email: bvdrucker@gmail.com \u2502 \u251c\u2500 url: bendrucker.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/builtin-status-codes \u2502 \u2514\u2500 licenseFile: node_modules/builtin-status-codes/license \u251c\u2500 cacache@15.0.5 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/cacache \u2502 \u251c\u2500 publisher: Kat March\u00e1n \u2502 \u251c\u2500 email: kzm@sykosomatic.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/cacache \u2502 \u2514\u2500 licenseFile: node_modules/cacache/LICENSE.md \u251c\u2500 chalk@1.1.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/chalk \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/chalk \u2502 \u2514\u2500 licenseFile: node_modules/chalk/license \u251c\u2500 chokidar@3.5.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/paulmillr/chokidar \u2502 \u251c\u2500 publisher: Paul Miller \u2502 \u251c\u2500 url: https://paulmillr.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/chokidar \u2502 \u2514\u2500 licenseFile: node_modules/chokidar/LICENSE \u251c\u2500 chownr@2.0.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/chownr \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/chownr \u2502 \u2514\u2500 licenseFile: node_modules/chownr/LICENSE \u251c\u2500 chrome-trace-event@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: github.com:samccone/chrome-trace-event \u2502 \u251c\u2500 publisher: Trent Mick, Sam Saccone \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/chrome-trace-event \u2502 \u2514\u2500 licenseFile: node_modules/chrome-trace-event/LICENSE.txt \u251c\u2500 cipher-base@1.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/cipher-base \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 email: calvin.metcalf@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/cipher-base \u2502 \u2514\u2500 licenseFile: node_modules/cipher-base/LICENSE \u251c\u2500 clean-stack@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/clean-stack \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/clean-stack \u2502 \u2514\u2500 licenseFile: node_modules/clean-stack/license \u251c\u2500 cli-table@0.3.6 \u2502 \u251c\u2500 licenses: MIT* \u2502 \u251c\u2500 repository: https://github.com/Automattic/cli-table \u2502 \u251c\u2500 publisher: Guillermo Rauch \u2502 \u251c\u2500 email: guillermo@learnboost.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/cli-table \u2502 \u2514\u2500 licenseFile: node_modules/cli-table/README.md \u251c\u2500 clipboard@2.0.8 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zenorocha/clipboard.js \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/clipboard \u2502 \u2514\u2500 licenseFile: node_modules/clipboard/LICENSE \u251c\u2500 clone-deep@4.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/clone-deep \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/clone-deep \u2502 \u2514\u2500 licenseFile: node_modules/clone-deep/LICENSE \u251c\u2500 codepage@1.13.1 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/SheetJS/js-codepage \u2502 \u251c\u2500 publisher: SheetJS \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/codepage \u2502 \u2514\u2500 licenseFile: node_modules/codepage/LICENSE \u251c\u2500 colors@1.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Marak/colors.js \u2502 \u251c\u2500 publisher: Marak Squires \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/colors \u2502 \u2514\u2500 licenseFile: node_modules/colors/LICENSE \u251c\u2500 combined-stream@1.0.8 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/felixge/node-combined-stream \u2502 \u251c\u2500 publisher: Felix Geisend\u00f6rfer \u2502 \u251c\u2500 email: felix@debuggable.com \u2502 \u251c\u2500 url: http://debuggable.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/combined-stream \u2502 \u2514\u2500 licenseFile: node_modules/combined-stream/License \u251c\u2500 commander@2.15.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/tj/commander.js \u2502 \u251c\u2500 publisher: TJ Holowaychuk \u2502 \u251c\u2500 email: tj@vision-media.ca \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/commander \u2502 \u2514\u2500 licenseFile: node_modules/commander/LICENSE \u251c\u2500 commondir@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/node-commondir \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/commondir \u2502 \u2514\u2500 licenseFile: node_modules/commondir/LICENSE \u251c\u2500 concat-map@0.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/node-concat-map \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/concat-map \u2502 \u2514\u2500 licenseFile: node_modules/concat-map/LICENSE \u251c\u2500 consola@2.15.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/nuxt/consola \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/consola \u2502 \u2514\u2500 licenseFile: node_modules/consola/README.md \u251c\u2500 console-browserify@1.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/browserify/console-browserify \u2502 \u251c\u2500 publisher: Raynos \u2502 \u251c\u2500 email: raynos2@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/console-browserify \u2502 \u2514\u2500 licenseFile: node_modules/console-browserify/LICENCE \u251c\u2500 constants-browserify@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/juliangruber/constants-browserify \u2502 \u251c\u2500 publisher: Julian Gruber \u2502 \u251c\u2500 email: julian@juliangruber.com \u2502 \u251c\u2500 url: http://juliangruber.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/constants-browserify \u2502 \u2514\u2500 licenseFile: node_modules/constants-browserify/README.md \u251c\u2500 core-js@2.6.12 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zloirock/core-js \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/core-js \u2502 \u2514\u2500 licenseFile: node_modules/core-js/LICENSE \u251c\u2500 core-util-is@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/isaacs/core-util-is \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/core-util-is \u2502 \u2514\u2500 licenseFile: node_modules/core-util-is/LICENSE \u251c\u2500 create-ecdh@4.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/createECDH \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/create-ecdh \u2502 \u2514\u2500 licenseFile: node_modules/create-ecdh/LICENSE \u251c\u2500 create-hash@1.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/createHash \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/create-hash \u2502 \u2514\u2500 licenseFile: node_modules/create-hash/LICENSE \u251c\u2500 create-hmac@1.1.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/createHmac \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/create-hmac \u2502 \u2514\u2500 licenseFile: node_modules/create-hmac/LICENSE \u251c\u2500 crypto-browserify@3.12.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/crypto-browserify \u2502 \u251c\u2500 publisher: Dominic Tarr \u2502 \u251c\u2500 email: dominic.tarr@gmail.com \u2502 \u251c\u2500 url: dominictarr.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/crypto-browserify \u2502 \u2514\u2500 licenseFile: node_modules/crypto-browserify/LICENSE \u251c\u2500 crypto-js@3.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/brix/crypto-js \u2502 \u251c\u2500 publisher: Evan Vosberg \u2502 \u251c\u2500 url: http://github.com/evanvosberg \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/crypto-js \u2502 \u2514\u2500 licenseFile: node_modules/crypto-js/LICENSE \u251c\u2500 d3-color@1.4.1 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-color \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-color \u2502 \u2514\u2500 licenseFile: node_modules/d3-color/LICENSE \u251c\u2500 d3-dispatch@1.0.6 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-dispatch \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-dispatch \u2502 \u2514\u2500 licenseFile: node_modules/d3-dispatch/LICENSE \u251c\u2500 d3-drag@1.2.5 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-drag \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-drag \u2502 \u2514\u2500 licenseFile: node_modules/d3-drag/LICENSE \u251c\u2500 d3-ease@1.0.7 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-ease \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-ease \u2502 \u2514\u2500 licenseFile: node_modules/d3-ease/LICENSE \u251c\u2500 d3-format@1.4.5 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-format \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-format \u2502 \u2514\u2500 licenseFile: node_modules/d3-format/LICENSE \u251c\u2500 d3-graphviz@2.6.1 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/magjac/d3-graphviz \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-graphviz \u2502 \u2514\u2500 licenseFile: node_modules/d3-graphviz/LICENSE \u251c\u2500 d3-interpolate@1.4.0 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-interpolate \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-interpolate \u2502 \u2514\u2500 licenseFile: node_modules/d3-interpolate/LICENSE \u251c\u2500 d3-path@1.0.9 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-path \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-path \u2502 \u2514\u2500 licenseFile: node_modules/d3-path/LICENSE \u251c\u2500 d3-selection@1.4.2 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-selection \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: https://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-selection \u2502 \u2514\u2500 licenseFile: node_modules/d3-selection/LICENSE \u251c\u2500 d3-timer@1.0.10 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-timer \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-timer \u2502 \u2514\u2500 licenseFile: node_modules/d3-timer/LICENSE \u251c\u2500 d3-transition@1.3.2 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-transition \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: https://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-transition \u2502 \u2514\u2500 licenseFile: node_modules/d3-transition/LICENSE \u251c\u2500 d3-zoom@1.8.3 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/d3/d3-zoom \u2502 \u251c\u2500 publisher: Mike Bostock \u2502 \u251c\u2500 url: http://bost.ocks.org/mike \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/d3-zoom \u2502 \u2514\u2500 licenseFile: node_modules/d3-zoom/LICENSE \u251c\u2500 datacontroller@3.12.0 \u2502 \u251c\u2500 licenses: UNLICENSED \u2502 \u251c\u2500 private: true \u2502 \u251c\u2500 path: ../dcfrontend \u2502 \u2514\u2500 licenseFile: licence.md \u251c\u2500 delayed-stream@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/felixge/node-delayed-stream \u2502 \u251c\u2500 publisher: Felix Geisend\u00f6rfer \u2502 \u251c\u2500 email: felix@debuggable.com \u2502 \u251c\u2500 url: http://debuggable.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/delayed-stream \u2502 \u2514\u2500 licenseFile: node_modules/delayed-stream/License \u251c\u2500 delegate@3.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zenorocha/delegate \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/delegate \u2502 \u2514\u2500 licenseFile: node_modules/delegate/readme.md \u251c\u2500 des.js@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/des.js \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/des.js \u2502 \u2514\u2500 licenseFile: node_modules/des.js/README.md \u251c\u2500 diffie-hellman@5.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/diffie-hellman \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/diffie-hellman \u2502 \u2514\u2500 licenseFile: node_modules/diffie-hellman/LICENSE \u251c\u2500 domain-browser@1.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/bevry/domain-browser \u2502 \u251c\u2500 publisher: 2013+ Bevry Pty Ltd \u2502 \u251c\u2500 email: us@bevry.me \u2502 \u251c\u2500 url: http://bevry.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/domain-browser \u2502 \u2514\u2500 licenseFile: node_modules/domain-browser/LICENSE.md \u251c\u2500 dompurify@2.2.7 \u2502 \u251c\u2500 licenses: (MPL-2.0 OR Apache-2.0) \u2502 \u251c\u2500 repository: https://github.com/cure53/DOMPurify \u2502 \u251c\u2500 publisher: Mario Heiderich \u2502 \u251c\u2500 email: mario@cure53.de \u2502 \u251c\u2500 url: https://cure53.de/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/dompurify \u2502 \u2514\u2500 licenseFile: node_modules/dompurify/LICENSE \u251c\u2500 elliptic@6.5.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/elliptic \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/elliptic \u2502 \u2514\u2500 licenseFile: node_modules/elliptic/README.md \u251c\u2500 emoji-toolkit@6.5.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/joypixels/emoji-toolkit \u2502 \u251c\u2500 publisher: JoyPixels \u2502 \u251c\u2500 email: support@joypixels.com \u2502 \u251c\u2500 url: https://www.joypixels.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/emoji-toolkit \u2502 \u2514\u2500 licenseFile: node_modules/emoji-toolkit/LICENSE.md \u251c\u2500 emojis-list@3.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/kikobeats/emojis-list \u2502 \u251c\u2500 publisher: Kiko Beats \u2502 \u251c\u2500 email: josefrancisco.verdu@gmail.com \u2502 \u251c\u2500 url: https://github.com/Kikobeats \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/emojis-list \u2502 \u2514\u2500 licenseFile: node_modules/emojis-list/LICENSE.md \u251c\u2500 enhanced-resolve@3.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/enhanced-resolve \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/enhanced-resolve \u2502 \u2514\u2500 licenseFile: node_modules/enhanced-resolve/README.md \u251c\u2500 errno@0.1.8 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/rvagg/node-errno \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/errno \u2502 \u2514\u2500 licenseFile: node_modules/errno/README.md \u251c\u2500 escape-string-regexp@1.0.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/escape-string-regexp \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/escape-string-regexp \u2502 \u2514\u2500 licenseFile: node_modules/escape-string-regexp/license \u251c\u2500 eslint-scope@4.0.3 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/eslint/eslint-scope \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/eslint-scope \u2502 \u2514\u2500 licenseFile: node_modules/eslint-scope/LICENSE \u251c\u2500 esrecurse@4.3.0 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/estools/esrecurse \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/esrecurse \u2502 \u2514\u2500 licenseFile: node_modules/esrecurse/README.md \u251c\u2500 estraverse@4.3.0 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/estools/estraverse \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/estraverse \u2502 \u2514\u2500 licenseFile: node_modules/estraverse/LICENSE.BSD \u251c\u2500 events@3.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Gozala/events \u2502 \u251c\u2500 publisher: Irakli Gozalishvili \u2502 \u251c\u2500 email: rfobic@gmail.com \u2502 \u251c\u2500 url: http://jeditoolkit.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/events \u2502 \u2514\u2500 licenseFile: node_modules/events/LICENSE \u251c\u2500 evp_bytestokey@1.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/EVP_BytesToKey \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 email: calvin.metcalf@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/evp_bytestokey \u2502 \u2514\u2500 licenseFile: node_modules/evp_bytestokey/LICENSE \u251c\u2500 exit-on-epipe@1.0.1 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/SheetJS/node-exit-on-epipe \u2502 \u251c\u2500 publisher: sheetjs \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/exit-on-epipe \u2502 \u2514\u2500 licenseFile: node_modules/exit-on-epipe/LICENSE \u251c\u2500 fast-deep-equal@3.1.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/epoberezkin/fast-deep-equal \u2502 \u251c\u2500 publisher: Evgeny Poberezkin \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fast-deep-equal \u2502 \u2514\u2500 licenseFile: node_modules/fast-deep-equal/LICENSE \u251c\u2500 fast-json-stable-stringify@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/epoberezkin/fast-json-stable-stringify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fast-json-stable-stringify \u2502 \u2514\u2500 licenseFile: node_modules/fast-json-stable-stringify/LICENSE \u251c\u2500 fill-range@7.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/fill-range \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fill-range \u2502 \u2514\u2500 licenseFile: node_modules/fill-range/LICENSE \u251c\u2500 find-cache-dir@3.3.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/avajs/find-cache-dir \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/find-cache-dir \u2502 \u2514\u2500 licenseFile: node_modules/find-cache-dir/license \u251c\u2500 find-up@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/find-up \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/find-up \u2502 \u2514\u2500 licenseFile: node_modules/find-up/license \u251c\u2500 follow-redirects@1.13.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/follow-redirects/follow-redirects \u2502 \u251c\u2500 publisher: Ruben Verborgh \u2502 \u251c\u2500 email: ruben@verborgh.org \u2502 \u251c\u2500 url: https://ruben.verborgh.org/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/follow-redirects \u2502 \u2514\u2500 licenseFile: node_modules/follow-redirects/LICENSE \u251c\u2500 form-data@4.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/form-data/form-data \u2502 \u251c\u2500 publisher: Felix Geisend\u00f6rfer \u2502 \u251c\u2500 email: felix@debuggable.com \u2502 \u251c\u2500 url: http://debuggable.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/form-data \u2502 \u2514\u2500 licenseFile: node_modules/form-data/License \u251c\u2500 fs-extra@7.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jprichardson/node-fs-extra \u2502 \u251c\u2500 publisher: JP Richardson \u2502 \u251c\u2500 email: jprichardson@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fs-extra \u2502 \u2514\u2500 licenseFile: node_modules/fs-extra/LICENSE \u251c\u2500 fs-minipass@2.1.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/fs-minipass \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fs-minipass \u2502 \u2514\u2500 licenseFile: node_modules/fs-minipass/LICENSE \u251c\u2500 fs.realpath@1.0.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/fs.realpath \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fs.realpath \u2502 \u2514\u2500 licenseFile: node_modules/fs.realpath/LICENSE \u251c\u2500 fsevents@2.3.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/fsevents/fsevents \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/fsevents \u2502 \u2514\u2500 licenseFile: node_modules/fsevents/LICENSE \u251c\u2500 function-bind@1.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Raynos/function-bind \u2502 \u251c\u2500 publisher: Raynos \u2502 \u251c\u2500 email: raynos2@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/function-bind \u2502 \u2514\u2500 licenseFile: node_modules/function-bind/LICENSE \u251c\u2500 glob-parent@5.1.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/gulpjs/glob-parent \u2502 \u251c\u2500 publisher: Gulp Team \u2502 \u251c\u2500 email: team@gulpjs.com \u2502 \u251c\u2500 url: https://gulpjs.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/glob-parent \u2502 \u2514\u2500 licenseFile: node_modules/glob-parent/LICENSE \u251c\u2500 glob@7.1.6 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/node-glob \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/glob \u2502 \u2514\u2500 licenseFile: node_modules/glob/LICENSE \u251c\u2500 good-listener@1.2.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zenorocha/good-listener \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/good-listener \u2502 \u2514\u2500 licenseFile: node_modules/good-listener/readme.md \u251c\u2500 graceful-fs@4.2.6 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/node-graceful-fs \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/graceful-fs \u2502 \u2514\u2500 licenseFile: node_modules/graceful-fs/LICENSE \u251c\u2500 handlebars@4.7.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/wycats/handlebars.js \u2502 \u251c\u2500 publisher: Yehuda Katz \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/handlebars \u2502 \u2514\u2500 licenseFile: node_modules/handlebars/LICENSE \u251c\u2500 handsontable@8.3.2 \u2502 \u251c\u2500 licenses: Custom: https://handsontable.com \u2502 \u251c\u2500 repository: https://github.com/handsontable/handsontable \u2502 \u251c\u2500 publisher: Handsoncode \u2502 \u251c\u2500 email: hello@handsontable.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/handsontable \u2502 \u2514\u2500 licenseFile: node_modules/handsontable/LICENSE.txt \u251c\u2500 has-ansi@2.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/has-ansi \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/has-ansi \u2502 \u2514\u2500 licenseFile: node_modules/has-ansi/license \u251c\u2500 has@1.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/tarruda/has \u2502 \u251c\u2500 publisher: Thiago de Arruda \u2502 \u251c\u2500 email: tpadilha84@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/has \u2502 \u2514\u2500 licenseFile: node_modules/has/LICENSE-MIT \u251c\u2500 hash-base@3.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/hash-base \u2502 \u251c\u2500 publisher: Kirill Fomichev \u2502 \u251c\u2500 email: fanatid@ya.ru \u2502 \u251c\u2500 url: https://github.com/fanatid \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/hash-base \u2502 \u2514\u2500 licenseFile: node_modules/hash-base/LICENSE \u251c\u2500 hash.js@1.1.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/hash.js \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/hash.js \u2502 \u2514\u2500 licenseFile: node_modules/hash.js/README.md \u251c\u2500 highlight.js@9.18.5 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/highlightjs/highlight.js \u2502 \u251c\u2500 publisher: Ivan Sagalaev \u2502 \u251c\u2500 email: maniac@softwaremaniacs.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/highlight.js \u2502 \u2514\u2500 licenseFile: node_modules/highlight.js/LICENSE \u251c\u2500 hmac-drbg@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/hmac-drbg \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/hmac-drbg \u2502 \u2514\u2500 licenseFile: node_modules/hmac-drbg/README.md \u251c\u2500 hot-formula-parser@4.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/handsontable/formula-parser \u2502 \u251c\u2500 publisher: Handsoncode \u2502 \u251c\u2500 email: hello@handsontable.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/hot-formula-parser \u2502 \u2514\u2500 licenseFile: node_modules/hot-formula-parser/LICENSE \u251c\u2500 https-browserify@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/https-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/https-browserify \u2502 \u2514\u2500 licenseFile: node_modules/https-browserify/LICENSE \u251c\u2500 https@1.0.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 publisher: hardus van der berg \u2502 \u251c\u2500 email: hardus@sunfork.com \u2502 \u251c\u2500 url: http://www.sunfork.com \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/https \u251c\u2500 iconv-lite@0.5.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/ashtuchkin/iconv-lite \u2502 \u251c\u2500 publisher: Alexander Shtuchkin \u2502 \u251c\u2500 email: ashtuchkin@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/iconv-lite \u2502 \u2514\u2500 licenseFile: node_modules/iconv-lite/LICENSE \u251c\u2500 ieee754@1.2.1 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/feross/ieee754 \u2502 \u251c\u2500 publisher: Feross Aboukhadijeh \u2502 \u251c\u2500 email: feross@feross.org \u2502 \u251c\u2500 url: https://feross.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ieee754 \u2502 \u2514\u2500 licenseFile: node_modules/ieee754/LICENSE \u251c\u2500 imurmurhash@0.1.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jensyt/imurmurhash-js \u2502 \u251c\u2500 publisher: Jens Taylor \u2502 \u251c\u2500 email: jensyt@gmail.com \u2502 \u251c\u2500 url: https://github.com/homebrewing \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/imurmurhash \u2502 \u2514\u2500 licenseFile: node_modules/imurmurhash/README.md \u251c\u2500 indent-string@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/indent-string \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/indent-string \u2502 \u2514\u2500 licenseFile: node_modules/indent-string/license \u251c\u2500 infer-owner@1.0.4 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/infer-owner \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: https://izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/infer-owner \u2502 \u2514\u2500 licenseFile: node_modules/infer-owner/LICENSE \u251c\u2500 inflight@1.0.6 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/inflight \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/inflight \u2502 \u2514\u2500 licenseFile: node_modules/inflight/LICENSE \u251c\u2500 inherits@2.0.4 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/inherits \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/inherits \u2502 \u2514\u2500 licenseFile: node_modules/inherits/LICENSE \u251c\u2500 interpret@1.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/gulpjs/interpret \u2502 \u251c\u2500 publisher: Gulp Team \u2502 \u251c\u2500 email: team@gulpjs.com \u2502 \u251c\u2500 url: http://gulpjs.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/interpret \u2502 \u2514\u2500 licenseFile: node_modules/interpret/LICENSE \u251c\u2500 is-binary-path@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/is-binary-path \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-binary-path \u2502 \u2514\u2500 licenseFile: node_modules/is-binary-path/license \u251c\u2500 is-core-module@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/inspect-js/is-core-module \u2502 \u251c\u2500 publisher: Jordan Harband \u2502 \u251c\u2500 email: ljharb@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-core-module \u2502 \u2514\u2500 licenseFile: node_modules/is-core-module/LICENSE \u251c\u2500 is-extglob@2.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/is-extglob \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-extglob \u2502 \u2514\u2500 licenseFile: node_modules/is-extglob/LICENSE \u251c\u2500 is-finite@1.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/is-finite \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-finite \u2502 \u2514\u2500 licenseFile: node_modules/is-finite/license \u251c\u2500 is-glob@4.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/is-glob \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-glob \u2502 \u2514\u2500 licenseFile: node_modules/is-glob/LICENSE \u251c\u2500 is-number@7.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/is-number \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-number \u2502 \u2514\u2500 licenseFile: node_modules/is-number/LICENSE \u251c\u2500 is-plain-object@2.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/is-plain-object \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/is-plain-object \u2502 \u2514\u2500 licenseFile: node_modules/is-plain-object/LICENSE \u251c\u2500 isarray@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/juliangruber/isarray \u2502 \u251c\u2500 publisher: Julian Gruber \u2502 \u251c\u2500 email: mail@juliangruber.com \u2502 \u251c\u2500 url: http://juliangruber.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/isarray \u2502 \u2514\u2500 licenseFile: node_modules/isarray/README.md \u251c\u2500 isobject@3.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/isobject \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/isobject \u2502 \u2514\u2500 licenseFile: node_modules/isobject/LICENSE \u251c\u2500 jest-worker@26.6.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/facebook/jest \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jest-worker \u2502 \u2514\u2500 licenseFile: node_modules/jest-worker/LICENSE \u251c\u2500 jquery-datetimepicker@2.5.21 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/xdan/datetimepicker \u2502 \u251c\u2500 publisher: Chupurnov \u2502 \u251c\u2500 email: chupurnov@gmail.com \u2502 \u251c\u2500 url: https://xdsoft.net/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jquery-datetimepicker \u2502 \u2514\u2500 licenseFile: node_modules/jquery-datetimepicker/README.md \u251c\u2500 jquery-mousewheel@3.1.13 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jquery/jquery-mousewheel \u2502 \u251c\u2500 publisher: jQuery Foundation and other contributors \u2502 \u251c\u2500 url: https://github.com/jquery/jquery-mousewheel/blob/master/AUTHORS.txt \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jquery-mousewheel \u2502 \u2514\u2500 licenseFile: node_modules/jquery-mousewheel/LICENSE.txt \u251c\u2500 jquery@3.6.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jquery/jquery \u2502 \u251c\u2500 publisher: OpenJS Foundation and other contributors \u2502 \u251c\u2500 url: https://github.com/jquery/jquery/blob/3.6.0/AUTHORS.txt \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jquery \u2502 \u2514\u2500 licenseFile: node_modules/jquery/LICENSE.txt \u251c\u2500 json-parse-better-errors@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zkat/json-parse-better-errors \u2502 \u251c\u2500 publisher: Kat March\u00e1n \u2502 \u251c\u2500 email: kzm@zkat.tech \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/json-parse-better-errors \u2502 \u2514\u2500 licenseFile: node_modules/json-parse-better-errors/LICENSE.md \u251c\u2500 json-schema-traverse@0.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/epoberezkin/json-schema-traverse \u2502 \u251c\u2500 publisher: Evgeny Poberezkin \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/json-schema-traverse \u2502 \u2514\u2500 licenseFile: node_modules/json-schema-traverse/LICENSE \u251c\u2500 json5@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/json5/json5 \u2502 \u251c\u2500 publisher: Aseem Kishore \u2502 \u251c\u2500 email: aseem.kishore@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/json5 \u2502 \u2514\u2500 licenseFile: node_modules/json5/LICENSE.md \u251c\u2500 jsonfile@4.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jprichardson/node-jsonfile \u2502 \u251c\u2500 publisher: JP Richardson \u2502 \u251c\u2500 email: jprichardson@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jsonfile \u2502 \u2514\u2500 licenseFile: node_modules/jsonfile/LICENSE \u251c\u2500 jsrsasign@10.1.13 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/kjur/jsrsasign \u2502 \u251c\u2500 publisher: Kenji Urushima \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jsrsasign \u2502 \u2514\u2500 licenseFile: node_modules/jsrsasign/README.md \u251c\u2500 jstat@1.9.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jstat/jstat \u2502 \u251c\u2500 publisher: Trevor Norris \u2502 \u251c\u2500 email: trev.norris@gmail.com \u2502 \u251c\u2500 url: http://trevorjnorris.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/jstat \u2502 \u2514\u2500 licenseFile: node_modules/jstat/LICENSE \u251c\u2500 katex@0.12.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/KaTeX/KaTeX \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/katex \u2502 \u2514\u2500 licenseFile: node_modules/katex/LICENSE \u251c\u2500 kind-of@6.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/kind-of \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/kind-of \u2502 \u2514\u2500 licenseFile: node_modules/kind-of/LICENSE \u251c\u2500 kleur@3.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/lukeed/kleur \u2502 \u251c\u2500 publisher: Luke Edwards \u2502 \u251c\u2500 email: luke.edwards05@gmail.com \u2502 \u251c\u2500 url: lukeed.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/kleur \u2502 \u2514\u2500 licenseFile: node_modules/kleur/license \u251c\u2500 loader-runner@2.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/loader-runner \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/loader-runner \u2502 \u2514\u2500 licenseFile: node_modules/loader-runner/LICENSE \u251c\u2500 loader-utils@1.4.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/loader-utils \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/loader-utils \u2502 \u2514\u2500 licenseFile: node_modules/loader-utils/LICENSE \u251c\u2500 lodash@4.17.21 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/lodash/lodash \u2502 \u251c\u2500 publisher: John-David Dalton \u2502 \u251c\u2500 email: john.david.dalton@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/lodash \u2502 \u2514\u2500 licenseFile: node_modules/lodash/LICENSE \u251c\u2500 lru-cache@4.1.5 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/node-lru-cache \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/lru-cache \u2502 \u2514\u2500 licenseFile: node_modules/lru-cache/LICENSE \u251c\u2500 lunr@2.3.9 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/olivernn/lunr.js \u2502 \u251c\u2500 publisher: Oliver Nightingale \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/lunr \u2502 \u2514\u2500 licenseFile: node_modules/lunr/LICENSE \u251c\u2500 make-dir@3.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/make-dir \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/make-dir \u2502 \u2514\u2500 licenseFile: node_modules/make-dir/license \u251c\u2500 marked@1.2.9 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/markedjs/marked \u2502 \u251c\u2500 publisher: Christopher Jeffrey \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/marked \u2502 \u2514\u2500 licenseFile: node_modules/marked/LICENSE.md \u251c\u2500 md5.js@1.3.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/md5.js \u2502 \u251c\u2500 publisher: Kirill Fomichev \u2502 \u251c\u2500 email: fanatid@ya.ru \u2502 \u251c\u2500 url: https://github.com/fanatid \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/md5.js \u2502 \u2514\u2500 licenseFile: node_modules/md5.js/LICENSE \u251c\u2500 memory-fs@0.5.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/memory-fs \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/memory-fs \u2502 \u2514\u2500 licenseFile: node_modules/memory-fs/LICENSE \u251c\u2500 merge-stream@2.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/grncdr/merge-stream \u2502 \u251c\u2500 publisher: Stephen Sugden \u2502 \u251c\u2500 email: me@stephensugden.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/merge-stream \u2502 \u2514\u2500 licenseFile: node_modules/merge-stream/LICENSE \u251c\u2500 micromatch@4.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/micromatch \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/micromatch \u2502 \u2514\u2500 licenseFile: node_modules/micromatch/LICENSE \u251c\u2500 miller-rabin@4.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/miller-rabin \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/miller-rabin \u2502 \u2514\u2500 licenseFile: node_modules/miller-rabin/README.md \u251c\u2500 mime-db@1.46.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jshttp/mime-db \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/mime-db \u2502 \u2514\u2500 licenseFile: node_modules/mime-db/LICENSE \u251c\u2500 mime-types@2.1.29 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jshttp/mime-types \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/mime-types \u2502 \u2514\u2500 licenseFile: node_modules/mime-types/LICENSE \u251c\u2500 minimalistic-assert@1.0.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/calvinmetcalf/minimalistic-assert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minimalistic-assert \u2502 \u2514\u2500 licenseFile: node_modules/minimalistic-assert/LICENSE \u251c\u2500 minimalistic-crypto-utils@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/indutny/minimalistic-crypto-utils \u2502 \u251c\u2500 publisher: Fedor Indutny \u2502 \u251c\u2500 email: fedor@indutny.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minimalistic-crypto-utils \u2502 \u2514\u2500 licenseFile: node_modules/minimalistic-crypto-utils/README.md \u251c\u2500 minimatch@3.0.4 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/minimatch \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minimatch \u2502 \u2514\u2500 licenseFile: node_modules/minimatch/LICENSE \u251c\u2500 minimist@1.2.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/minimist \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minimist \u2502 \u2514\u2500 licenseFile: node_modules/minimist/LICENSE \u251c\u2500 minipass-collect@1.0.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: https://izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minipass-collect \u2502 \u2514\u2500 licenseFile: node_modules/minipass-collect/LICENSE \u251c\u2500 minipass-flush@1.0.5 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/minipass-flush \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: https://izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minipass-flush \u2502 \u2514\u2500 licenseFile: node_modules/minipass-flush/LICENSE \u251c\u2500 minipass-pipeline@1.2.4 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: https://izs.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minipass-pipeline \u2502 \u2514\u2500 licenseFile: node_modules/minipass-pipeline/LICENSE \u251c\u2500 minipass@3.1.3 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/minipass \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/minipass \u2502 \u2514\u2500 licenseFile: node_modules/minipass/LICENSE \u251c\u2500 mkdirp@0.5.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/node-mkdirp \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/mkdirp \u2502 \u2514\u2500 licenseFile: node_modules/mkdirp/LICENSE \u251c\u2500 moment@2.29.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/moment/moment \u2502 \u251c\u2500 publisher: Iskren Ivov Chernev \u2502 \u251c\u2500 email: iskren.chernev@gmail.com \u2502 \u251c\u2500 url: https://github.com/ichernev \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/moment \u2502 \u2514\u2500 licenseFile: node_modules/moment/LICENSE \u251c\u2500 neo-async@2.6.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/suguru03/neo-async \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/neo-async \u2502 \u2514\u2500 licenseFile: node_modules/neo-async/LICENSE \u251c\u2500 ng2-file-upload@1.4.0 \u2502 \u251c\u2500 licenses: UNKNOWN \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/ng2-file-upload \u251c\u2500 ngx-clipboard@12.3.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/maxisam/ngx-clipboard \u2502 \u251c\u2500 publisher: Sam Lin \u2502 \u251c\u2500 email: maxisam@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ngx-clipboard \u2502 \u2514\u2500 licenseFile: node_modules/ngx-clipboard/README.md \u251c\u2500 ngx-markdown@10.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jfcere/ngx-markdown \u2502 \u251c\u2500 publisher: Jean-Francois Cere \u2502 \u251c\u2500 email: jfcere@sherweb.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ngx-markdown \u2502 \u2514\u2500 licenseFile: node_modules/ngx-markdown/LICENSE \u251c\u2500 ngx-window-token@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/maxisam/ngx-window-token \u2502 \u251c\u2500 publisher: Sam Lin \u2502 \u251c\u2500 email: maxisam@gmail.com \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/ngx-window-token \u251c\u2500 node-libs-browser@2.2.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/node-libs-browser \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/node-libs-browser \u2502 \u2514\u2500 licenseFile: node_modules/node-libs-browser/LICENSE \u251c\u2500 nodejs@0.0.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/nodejs \u251c\u2500 normalize-path@3.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/normalize-path \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/normalize-path \u2502 \u2514\u2500 licenseFile: node_modules/normalize-path/LICENSE \u251c\u2500 numbro@2.3.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/BenjaminVanRyseghem/numbro \u2502 \u251c\u2500 publisher: Benjamin Van Ryseghem \u2502 \u251c\u2500 email: benjamin@vanryseghem.com \u2502 \u251c\u2500 url: https://benjamin.vanryseghem.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/numbro \u2502 \u2514\u2500 licenseFile: node_modules/numbro/LICENSE \u251c\u2500 object-assign@4.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/object-assign \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/object-assign \u2502 \u2514\u2500 licenseFile: node_modules/object-assign/license \u251c\u2500 once@1.4.0 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/once \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/once \u2502 \u2514\u2500 licenseFile: node_modules/once/LICENSE \u251c\u2500 os-browserify@0.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/CoderPuppy/os-browserify \u2502 \u251c\u2500 publisher: CoderPuppy \u2502 \u251c\u2500 email: coderpup@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/os-browserify \u2502 \u2514\u2500 licenseFile: node_modules/os-browserify/LICENSE \u251c\u2500 p-limit@2.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/p-limit \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/p-limit \u2502 \u2514\u2500 licenseFile: node_modules/p-limit/license \u251c\u2500 p-map@4.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/p-map \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: https://sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/p-map \u2502 \u2514\u2500 licenseFile: node_modules/p-map/license \u251c\u2500 p-try@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/p-try \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/p-try \u2502 \u2514\u2500 licenseFile: node_modules/p-try/license \u251c\u2500 pako@1.0.11 \u2502 \u251c\u2500 licenses: (MIT AND Zlib) \u2502 \u251c\u2500 repository: https://github.com/nodeca/pako \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pako \u2502 \u2514\u2500 licenseFile: node_modules/pako/LICENSE \u251c\u2500 parse-asn1@5.1.6 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/parse-asn1 \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/parse-asn1 \u2502 \u2514\u2500 licenseFile: node_modules/parse-asn1/LICENSE \u251c\u2500 path-browserify@0.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/path-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/path-browserify \u2502 \u2514\u2500 licenseFile: node_modules/path-browserify/LICENSE \u251c\u2500 path-exists@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/path-exists \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/path-exists \u2502 \u2514\u2500 licenseFile: node_modules/path-exists/license \u251c\u2500 path-is-absolute@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/path-is-absolute \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/path-is-absolute \u2502 \u2514\u2500 licenseFile: node_modules/path-is-absolute/license \u251c\u2500 path-parse@1.0.6 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jbgutierrez/path-parse \u2502 \u251c\u2500 publisher: Javier Blanco \u2502 \u251c\u2500 email: http://jbgutierrez.info \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/path-parse \u2502 \u2514\u2500 licenseFile: node_modules/path-parse/LICENSE \u251c\u2500 pbkdf2@3.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/pbkdf2 \u2502 \u251c\u2500 publisher: Daniel Cousens \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pbkdf2 \u2502 \u2514\u2500 licenseFile: node_modules/pbkdf2/LICENSE \u251c\u2500 php-date-formatter@1.3.6 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/kartik-v/php-date-formatter \u2502 \u251c\u2500 publisher: Kartik Visweswaran \u2502 \u251c\u2500 email: kartikv2@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/php-date-formatter \u2502 \u2514\u2500 licenseFile: node_modules/php-date-formatter/LICENSE.md \u251c\u2500 picomatch@2.2.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/picomatch \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/picomatch \u2502 \u2514\u2500 licenseFile: node_modules/picomatch/LICENSE \u251c\u2500 pify@2.3.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/pify \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pify \u2502 \u2514\u2500 licenseFile: node_modules/pify/license \u251c\u2500 pikaday@1.8.0 \u2502 \u251c\u2500 licenses: (0BSD OR MIT) \u2502 \u251c\u2500 repository: https://github.com/Pikaday/Pikaday \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pikaday \u2502 \u2514\u2500 licenseFile: node_modules/pikaday/LICENSE \u251c\u2500 pinkie-promise@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/floatdrop/pinkie-promise \u2502 \u251c\u2500 publisher: Vsevolod Strukchinsky \u2502 \u251c\u2500 email: floatdrop@gmail.com \u2502 \u251c\u2500 url: github.com/floatdrop \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pinkie-promise \u2502 \u2514\u2500 licenseFile: node_modules/pinkie-promise/license \u251c\u2500 pinkie@2.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/floatdrop/pinkie \u2502 \u251c\u2500 publisher: Vsevolod Strukchinsky \u2502 \u251c\u2500 email: floatdrop@gmail.com \u2502 \u251c\u2500 url: github.com/floatdrop \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pinkie \u2502 \u2514\u2500 licenseFile: node_modules/pinkie/license \u251c\u2500 pkg-dir@4.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/pkg-dir \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pkg-dir \u2502 \u2514\u2500 licenseFile: node_modules/pkg-dir/license \u251c\u2500 prismjs@1.23.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/PrismJS/prism \u2502 \u251c\u2500 publisher: Lea Verou \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/prismjs \u2502 \u2514\u2500 licenseFile: node_modules/prismjs/LICENSE \u251c\u2500 process-nextick-args@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/calvinmetcalf/process-nextick-args \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/process-nextick-args \u2502 \u2514\u2500 licenseFile: node_modules/process-nextick-args/license.md \u251c\u2500 process@0.11.10 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/shtylman/node-process \u2502 \u251c\u2500 publisher: Roman Shtylman \u2502 \u251c\u2500 email: shtylman@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/process \u2502 \u2514\u2500 licenseFile: node_modules/process/LICENSE \u251c\u2500 progress@2.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/visionmedia/node-progress \u2502 \u251c\u2500 publisher: TJ Holowaychuk \u2502 \u251c\u2500 email: tj@vision-media.ca \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/progress \u2502 \u2514\u2500 licenseFile: node_modules/progress/LICENSE \u251c\u2500 promise-inflight@1.0.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/iarna/promise-inflight \u2502 \u251c\u2500 publisher: Rebecca Turner \u2502 \u251c\u2500 email: me@re-becca.org \u2502 \u251c\u2500 url: http://re-becca.org/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/promise-inflight \u2502 \u2514\u2500 licenseFile: node_modules/promise-inflight/LICENSE \u251c\u2500 prompts@2.4.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/terkelg/prompts \u2502 \u251c\u2500 publisher: Terkel Gjervig \u2502 \u251c\u2500 email: terkel@terkel.com \u2502 \u251c\u2500 url: https://terkel.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/prompts \u2502 \u2514\u2500 licenseFile: node_modules/prompts/license \u251c\u2500 prr@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/rvagg/prr \u2502 \u251c\u2500 publisher: Rod Vagg \u2502 \u251c\u2500 email: rod@vagg.org \u2502 \u251c\u2500 url: https://github.com/rvagg \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/prr \u2502 \u2514\u2500 licenseFile: node_modules/prr/LICENSE.md \u251c\u2500 pseudomap@1.0.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/pseudomap \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/pseudomap \u2502 \u2514\u2500 licenseFile: node_modules/pseudomap/LICENSE \u251c\u2500 public-encrypt@4.0.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/publicEncrypt \u2502 \u251c\u2500 publisher: Calvin Metcalf \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/public-encrypt \u2502 \u2514\u2500 licenseFile: node_modules/public-encrypt/LICENSE \u251c\u2500 punycode@2.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/bestiejs/punycode.js \u2502 \u251c\u2500 publisher: Mathias Bynens \u2502 \u251c\u2500 url: https://mathiasbynens.be/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/punycode \u2502 \u2514\u2500 licenseFile: node_modules/punycode/LICENSE-MIT.txt \u251c\u2500 querystring-es3@0.2.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/mike-spainhower/querystring \u2502 \u251c\u2500 publisher: Irakli Gozalishvili \u2502 \u251c\u2500 email: rfobic@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/querystring-es3 \u2502 \u2514\u2500 licenseFile: node_modules/querystring-es3/License.md \u251c\u2500 querystring@0.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Gozala/querystring \u2502 \u251c\u2500 publisher: Irakli Gozalishvili \u2502 \u251c\u2500 email: rfobic@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/querystring \u2502 \u2514\u2500 licenseFile: node_modules/querystring/License.md \u251c\u2500 randombytes@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/randombytes \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/randombytes \u2502 \u2514\u2500 licenseFile: node_modules/randombytes/LICENSE \u251c\u2500 randomfill@1.0.4 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/randomfill \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/randomfill \u2502 \u2514\u2500 licenseFile: node_modules/randomfill/LICENSE \u251c\u2500 readable-stream@2.3.7 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/nodejs/readable-stream \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/readable-stream \u2502 \u2514\u2500 licenseFile: node_modules/readable-stream/LICENSE \u251c\u2500 readdirp@3.5.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/paulmillr/readdirp \u2502 \u251c\u2500 publisher: Thorsten Lorenz \u2502 \u251c\u2500 email: thlorenz@gmx.de \u2502 \u251c\u2500 url: thlorenz.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/readdirp \u2502 \u2514\u2500 licenseFile: node_modules/readdirp/LICENSE \u251c\u2500 rechoir@0.6.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/tkellen/node-rechoir \u2502 \u251c\u2500 publisher: Tyler Kellen \u2502 \u251c\u2500 url: http://goingslowly.com/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/rechoir \u2502 \u2514\u2500 licenseFile: node_modules/rechoir/LICENSE \u251c\u2500 repeating@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/sindresorhus/repeating \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/repeating \u2502 \u2514\u2500 licenseFile: node_modules/repeating/license \u251c\u2500 resolve@1.20.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/browserify/resolve \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/resolve \u2502 \u2514\u2500 licenseFile: node_modules/resolve/LICENSE \u251c\u2500 rimraf@2.7.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/rimraf \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/rimraf \u2502 \u2514\u2500 licenseFile: node_modules/rimraf/LICENSE \u251c\u2500 ripemd160@2.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/ripemd160 \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ripemd160 \u2502 \u2514\u2500 licenseFile: node_modules/ripemd160/LICENSE \u251c\u2500 rxjs-compat@6.6.6 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/rxjs-compat \u2502 \u2514\u2500 licenseFile: node_modules/rxjs-compat/LICENSE.txt \u251c\u2500 rxjs@6.6.6 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/reactivex/rxjs \u2502 \u251c\u2500 publisher: Ben Lesh \u2502 \u251c\u2500 email: ben@benlesh.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/rxjs \u2502 \u2514\u2500 licenseFile: node_modules/rxjs/LICENSE.txt \u251c\u2500 safe-buffer@5.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/feross/safe-buffer \u2502 \u251c\u2500 publisher: Feross Aboukhadijeh \u2502 \u251c\u2500 email: feross@feross.org \u2502 \u251c\u2500 url: http://feross.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/safe-buffer \u2502 \u2514\u2500 licenseFile: node_modules/safe-buffer/LICENSE \u251c\u2500 safer-buffer@2.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/ChALkeR/safer-buffer \u2502 \u251c\u2500 publisher: Nikita Skovoroda \u2502 \u251c\u2500 email: chalkerx@gmail.com \u2502 \u251c\u2500 url: https://github.com/ChALkeR \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/safer-buffer \u2502 \u2514\u2500 licenseFile: node_modules/safer-buffer/LICENSE \u251c\u2500 sass-loader@7.3.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack-contrib/sass-loader \u2502 \u251c\u2500 publisher: J. Tangelder \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/sass-loader \u2502 \u2514\u2500 licenseFile: node_modules/sass-loader/LICENSE \u251c\u2500 save-svg-as-png@1.4.17 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/exupero/saveSvgAsPng \u2502 \u251c\u2500 publisher: Eric Shull \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/save-svg-as-png \u2502 \u2514\u2500 licenseFile: node_modules/save-svg-as-png/LICENSE \u251c\u2500 schema-utils@2.7.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/schema-utils \u2502 \u251c\u2500 publisher: webpack Contrib \u2502 \u251c\u2500 url: https://github.com/webpack-contrib \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/schema-utils \u2502 \u2514\u2500 licenseFile: node_modules/schema-utils/LICENSE \u251c\u2500 select@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/zenorocha/select \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/select \u2502 \u2514\u2500 licenseFile: node_modules/select/readme.md \u251c\u2500 semver@5.7.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/node-semver \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/semver \u2502 \u2514\u2500 licenseFile: node_modules/semver/LICENSE \u251c\u2500 serialize-javascript@5.0.1 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/yahoo/serialize-javascript \u2502 \u251c\u2500 publisher: Eric Ferraiuolo \u2502 \u251c\u2500 email: edf@ericf.me \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/serialize-javascript \u2502 \u2514\u2500 licenseFile: node_modules/serialize-javascript/LICENSE \u251c\u2500 setimmediate@1.0.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/YuzuJS/setImmediate \u2502 \u251c\u2500 publisher: YuzuJS \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/setimmediate \u2502 \u2514\u2500 licenseFile: node_modules/setimmediate/LICENSE.txt \u251c\u2500 sha.js@2.4.11 \u2502 \u251c\u2500 licenses: (MIT AND BSD-3-Clause) \u2502 \u251c\u2500 repository: https://github.com/crypto-browserify/sha.js \u2502 \u251c\u2500 publisher: Dominic Tarr \u2502 \u251c\u2500 email: dominic.tarr@gmail.com \u2502 \u251c\u2500 url: dominictarr.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/sha.js \u2502 \u2514\u2500 licenseFile: node_modules/sha.js/LICENSE \u251c\u2500 shallow-clone@3.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jonschlinkert/shallow-clone \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/shallow-clone \u2502 \u2514\u2500 licenseFile: node_modules/shallow-clone/LICENSE \u251c\u2500 shelljs@0.8.4 \u2502 \u251c\u2500 licenses: BSD-3-Clause \u2502 \u251c\u2500 repository: https://github.com/shelljs/shelljs \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/shelljs \u2502 \u2514\u2500 licenseFile: node_modules/shelljs/LICENSE \u251c\u2500 sisteransi@1.0.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/terkelg/sisteransi \u2502 \u251c\u2500 publisher: Terkel Gjervig \u2502 \u251c\u2500 email: terkel@terkel.com \u2502 \u251c\u2500 url: https://terkel.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/sisteransi \u2502 \u2514\u2500 licenseFile: node_modules/sisteransi/license \u251c\u2500 sl-blip@1.0.0 \u2502 \u251c\u2500 licenses: UNKNOWN \u2502 \u251c\u2500 repository: none \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/sl-blip \u251c\u2500 source-list-map@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/source-list-map \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/source-list-map \u2502 \u2514\u2500 licenseFile: node_modules/source-list-map/LICENSE \u251c\u2500 source-map-support@0.5.19 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/evanw/node-source-map-support \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/source-map-support \u2502 \u2514\u2500 licenseFile: node_modules/source-map-support/LICENSE.md \u251c\u2500 ssri@8.0.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/ssri \u2502 \u251c\u2500 publisher: Kat March\u00e1n \u2502 \u251c\u2500 email: kzm@sykosomatic.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ssri \u2502 \u2514\u2500 licenseFile: node_modules/ssri/LICENSE.md \u251c\u2500 stream-browserify@2.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/browserify/stream-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/stream-browserify \u2502 \u2514\u2500 licenseFile: node_modules/stream-browserify/LICENSE \u251c\u2500 stream-http@2.8.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jhiesey/stream-http \u2502 \u251c\u2500 publisher: John Hiesey \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/stream-http \u2502 \u2514\u2500 licenseFile: node_modules/stream-http/LICENSE \u251c\u2500 string_decoder@1.1.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/nodejs/string_decoder \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/string_decoder \u2502 \u2514\u2500 licenseFile: node_modules/string_decoder/LICENSE \u251c\u2500 strip-ansi@3.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/strip-ansi \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/strip-ansi \u2502 \u2514\u2500 licenseFile: node_modules/strip-ansi/license \u251c\u2500 supports-color@2.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/chalk/supports-color \u2502 \u251c\u2500 publisher: Sindre Sorhus \u2502 \u251c\u2500 email: sindresorhus@gmail.com \u2502 \u251c\u2500 url: sindresorhus.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/supports-color \u2502 \u2514\u2500 licenseFile: node_modules/supports-color/license \u251c\u2500 tapable@1.1.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/tapable \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/tapable \u2502 \u2514\u2500 licenseFile: node_modules/tapable/LICENSE \u251c\u2500 terser-webpack-plugin@4.2.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack-contrib/terser-webpack-plugin \u2502 \u251c\u2500 publisher: webpack Contrib Team \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/terser-webpack-plugin \u2502 \u2514\u2500 licenseFile: node_modules/terser-webpack-plugin/LICENSE \u251c\u2500 terser@5.5.1 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/terser/terser \u2502 \u251c\u2500 publisher: Mihai Bazon \u2502 \u251c\u2500 email: mihai.bazon@gmail.com \u2502 \u251c\u2500 url: http://lisperator.net/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/terser \u2502 \u2514\u2500 licenseFile: node_modules/terser/LICENSE \u251c\u2500 text-encoding@0.7.0 \u2502 \u251c\u2500 licenses: (Unlicense OR Apache-2.0) \u2502 \u251c\u2500 repository: https://github.com/inexorabletash/text-encoding \u2502 \u251c\u2500 publisher: Joshua Bell \u2502 \u251c\u2500 email: inexorabletash@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/text-encoding \u2502 \u2514\u2500 licenseFile: node_modules/text-encoding/LICENSE.md \u251c\u2500 timers-browserify@2.0.12 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jryans/timers-browserify \u2502 \u251c\u2500 publisher: J. Ryan Stinnett \u2502 \u251c\u2500 email: jryans@gmail.com \u2502 \u251c\u2500 url: https://convolv.es/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/timers-browserify \u2502 \u2514\u2500 licenseFile: node_modules/timers-browserify/LICENSE.md \u251c\u2500 tiny-emitter@2.1.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/scottcorgan/tiny-emitter \u2502 \u251c\u2500 publisher: Scott Corgan \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/tiny-emitter \u2502 \u2514\u2500 licenseFile: node_modules/tiny-emitter/LICENSE \u251c\u2500 to-arraybuffer@1.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/jhiesey/to-arraybuffer \u2502 \u251c\u2500 publisher: John Hiesey \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/to-arraybuffer \u2502 \u2514\u2500 licenseFile: node_modules/to-arraybuffer/LICENSE \u251c\u2500 to-regex-range@5.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/micromatch/to-regex-range \u2502 \u251c\u2500 publisher: Jon Schlinkert \u2502 \u251c\u2500 url: https://github.com/jonschlinkert \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/to-regex-range \u2502 \u2514\u2500 licenseFile: node_modules/to-regex-range/LICENSE \u251c\u2500 ts-helpers@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/ngParty/ts-helpers \u2502 \u251c\u2500 publisher: Martin Hochel \u2502 \u251c\u2500 email: hochelmartin@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/ts-helpers \u2502 \u2514\u2500 licenseFile: node_modules/ts-helpers/LICENSE \u251c\u2500 tslib@2.1.0 \u2502 \u251c\u2500 licenses: 0BSD \u2502 \u251c\u2500 repository: https://github.com/Microsoft/tslib \u2502 \u251c\u2500 publisher: Microsoft Corp. \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/tslib \u2502 \u2514\u2500 licenseFile: node_modules/tslib/LICENSE.txt \u251c\u2500 tty-browserify@0.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/tty-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/tty-browserify \u2502 \u2514\u2500 licenseFile: node_modules/tty-browserify/LICENSE \u251c\u2500 typedoc-default-themes@0.12.9 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/TypeStrong/typedoc-default-themes \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/typedoc-default-themes \u2502 \u2514\u2500 licenseFile: node_modules/typedoc-default-themes/LICENSE \u251c\u2500 typedoc-neo-theme@1.1.0 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/google/typedoc-neo-theme \u2502 \u251c\u2500 publisher: Nick Felker, based on work by Sebastian Lenz \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/typedoc-neo-theme \u2502 \u2514\u2500 licenseFile: node_modules/typedoc-neo-theme/LICENSE \u251c\u2500 typedoc@0.16.11 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/TypeStrong/TypeDoc \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/typedoc \u2502 \u2514\u2500 licenseFile: node_modules/typedoc/LICENSE \u251c\u2500 typescript@4.1.5 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/Microsoft/TypeScript \u2502 \u251c\u2500 publisher: Microsoft Corp. \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/typescript \u2502 \u2514\u2500 licenseFile: node_modules/typescript/LICENSE.txt \u251c\u2500 uglify-js@3.13.2 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/mishoo/UglifyJS \u2502 \u251c\u2500 publisher: Mihai Bazon \u2502 \u251c\u2500 email: mihai.bazon@gmail.com \u2502 \u251c\u2500 url: http://lisperator.net/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/uglify-js \u2502 \u2514\u2500 licenseFile: node_modules/uglify-js/LICENSE \u251c\u2500 unique-filename@1.1.1 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/iarna/unique-filename \u2502 \u251c\u2500 publisher: Rebecca Turner \u2502 \u251c\u2500 email: me@re-becca.org \u2502 \u251c\u2500 url: http://re-becca.org/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/unique-filename \u2502 \u2514\u2500 licenseFile: node_modules/unique-filename/LICENSE \u251c\u2500 unique-slug@2.0.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/iarna/unique-slug \u2502 \u251c\u2500 publisher: Rebecca Turner \u2502 \u251c\u2500 email: me@re-becca.org \u2502 \u251c\u2500 url: http://re-becca.org \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/unique-slug \u2502 \u2514\u2500 licenseFile: node_modules/unique-slug/LICENSE \u251c\u2500 universalify@0.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/RyanZim/universalify \u2502 \u251c\u2500 publisher: Ryan Zimmerman \u2502 \u251c\u2500 email: opensrc@ryanzim.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/universalify \u2502 \u2514\u2500 licenseFile: node_modules/universalify/LICENSE \u251c\u2500 uri-js@4.4.1 \u2502 \u251c\u2500 licenses: BSD-2-Clause \u2502 \u251c\u2500 repository: https://github.com/garycourt/uri-js \u2502 \u251c\u2500 publisher: Gary Court \u2502 \u251c\u2500 email: gary.court@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/uri-js \u2502 \u2514\u2500 licenseFile: node_modules/uri-js/LICENSE \u251c\u2500 url@0.11.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/defunctzombie/node-url \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/url \u2502 \u2514\u2500 licenseFile: node_modules/url/LICENSE \u251c\u2500 util-deprecate@1.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/TooTallNate/util-deprecate \u2502 \u251c\u2500 publisher: Nathan Rajlich \u2502 \u251c\u2500 email: nathan@tootallnate.net \u2502 \u251c\u2500 url: http://n8.io/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/util-deprecate \u2502 \u2514\u2500 licenseFile: node_modules/util-deprecate/LICENSE \u251c\u2500 util@0.11.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/defunctzombie/node-util \u2502 \u251c\u2500 publisher: Joyent \u2502 \u251c\u2500 url: http://www.joyent.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/util \u2502 \u2514\u2500 licenseFile: node_modules/util/LICENSE \u251c\u2500 valid-url@1.0.9 \u2502 \u251c\u2500 licenses: MIT* \u2502 \u251c\u2500 repository: https://github.com/ogt/valid-url \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/valid-url \u2502 \u2514\u2500 licenseFile: node_modules/valid-url/LICENSE \u251c\u2500 viz.js@1.8.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/mdaines/viz.js \u2502 \u251c\u2500 publisher: Mike Daines \u2502 \u251c\u2500 email: mdaines@fastmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/viz.js \u2502 \u2514\u2500 licenseFile: node_modules/viz.js/LICENSE \u251c\u2500 vm-browserify@1.1.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/vm-browserify \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/vm-browserify \u2502 \u2514\u2500 licenseFile: node_modules/vm-browserify/LICENSE \u251c\u2500 watchpack-chokidar2@2.0.1 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/watchpack \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u2514\u2500 path: /Users/munja/git/dcfrontend/node_modules/watchpack-chokidar2 \u251c\u2500 watchpack@1.7.5 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/watchpack \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/watchpack \u2502 \u2514\u2500 licenseFile: node_modules/watchpack/LICENSE \u251c\u2500 web-animations-js@2.3.2 \u2502 \u251c\u2500 licenses: Apache-2.0 \u2502 \u251c\u2500 repository: https://github.com/web-animations/web-animations-js \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/web-animations-js \u2502 \u2514\u2500 licenseFile: node_modules/web-animations-js/README.md \u251c\u2500 webpack-sources@2.2.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/webpack-sources \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/webpack-sources \u2502 \u2514\u2500 licenseFile: node_modules/webpack-sources/LICENSE \u251c\u2500 webpack@4.44.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/webpack/webpack \u2502 \u251c\u2500 publisher: Tobias Koppers @sokra \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/webpack \u2502 \u2514\u2500 licenseFile: node_modules/webpack/LICENSE \u251c\u2500 wordwrap@1.0.0 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/substack/node-wordwrap \u2502 \u251c\u2500 publisher: James Halliday \u2502 \u251c\u2500 email: mail@substack.net \u2502 \u251c\u2500 url: http://substack.net \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/wordwrap \u2502 \u2514\u2500 licenseFile: node_modules/wordwrap/LICENSE \u251c\u2500 wrappy@1.0.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/npm/wrappy \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/wrappy \u2502 \u2514\u2500 licenseFile: node_modules/wrappy/LICENSE \u251c\u2500 xtend@4.0.2 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/Raynos/xtend \u2502 \u251c\u2500 publisher: Raynos \u2502 \u251c\u2500 email: raynos2@gmail.com \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/xtend \u2502 \u2514\u2500 licenseFile: node_modules/xtend/LICENSE \u251c\u2500 yallist@2.1.2 \u2502 \u251c\u2500 licenses: ISC \u2502 \u251c\u2500 repository: https://github.com/isaacs/yallist \u2502 \u251c\u2500 publisher: Isaac Z. Schlueter \u2502 \u251c\u2500 email: i@izs.me \u2502 \u251c\u2500 url: http://blog.izs.me/ \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/yallist \u2502 \u2514\u2500 licenseFile: node_modules/yallist/LICENSE \u251c\u2500 zone.js@0.10.3 \u2502 \u251c\u2500 licenses: MIT \u2502 \u251c\u2500 repository: https://github.com/angular/angular \u2502 \u251c\u2500 publisher: Brian Ford \u2502 \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/zone.js \u2502 \u2514\u2500 licenseFile: node_modules/zone.js/LICENSE \u2514\u2500 zone@0.3.4 \u251c\u2500 licenses: Custom: https://api.dartlang.org/apidocs/channels/stable/dartdoc-viewer/dart-async.Zone \u251c\u2500 repository: https://github.com/strongloop/zone \u251c\u2500 path: /Users/munja/git/dcfrontend/node_modules/zone \u2514\u2500 licenseFile: node_modules/zone/LICENSE.md","title":"Overview"},{"location":"locking-mechanism/","text":"Locking Mechanism \u00b6 In any multi-user application a locking mechanism is necessary to avoid conflicts when the same table is updated by two people or processes. In Data Controller this is handled using the DCLIB.MPE_LOCKANYTABLE table, specifically using the mp_lockanytable macro. This macro is invoked whenever a process requires an exclusive lock on a table - first to mark the table as locked, and again to mark it as unlocked. The logic flow is demonstrated below: Notice above the red box - this situation can occur in unusual circumstances (such as a system shutdown or OS error). If you are waiting more than a minute or two for a table to be unlocked, then it is advised to follow the process below. Unlock Process \u00b6 Before proceeding with an unlock, the first step should be to understand why the process is locked. By opening the MPE_LOCKANYTABLE table it will be possible to see which user performed the lock, and when. Simply filter the table where LOCK_STATUS_CD='LOCKED' . If an unlock is deemed necessary, simply open this table in the EDIT menu, and change the value of LOCK_STATUS_CD from LOCKED to UNLOCKED . Scalability \u00b6 This locking mechanism does not scale well if the table remains in SAS dataset (.sas7bdat) form. If you are deploying Data Controller for usage beyond 10-20 users then you are advised to put the control tables (DC library) in a database. Third Party Applications \u00b6 Third party SAS apps may also make use of this locking table. This is handled by simply: Ensuring the DC library is assigned in the Service Using the mp_lockanytable macro to perform the lock Using the mp_lockanytable macro to perform the unlock Performing appropriate error handling to ensure an unlock if there are any issues in the service","title":"Locking Mechanism"},{"location":"locking-mechanism/#locking-mechanism","text":"In any multi-user application a locking mechanism is necessary to avoid conflicts when the same table is updated by two people or processes. In Data Controller this is handled using the DCLIB.MPE_LOCKANYTABLE table, specifically using the mp_lockanytable macro. This macro is invoked whenever a process requires an exclusive lock on a table - first to mark the table as locked, and again to mark it as unlocked. The logic flow is demonstrated below: Notice above the red box - this situation can occur in unusual circumstances (such as a system shutdown or OS error). If you are waiting more than a minute or two for a table to be unlocked, then it is advised to follow the process below.","title":"Locking Mechanism"},{"location":"locking-mechanism/#unlock-process","text":"Before proceeding with an unlock, the first step should be to understand why the process is locked. By opening the MPE_LOCKANYTABLE table it will be possible to see which user performed the lock, and when. Simply filter the table where LOCK_STATUS_CD='LOCKED' . If an unlock is deemed necessary, simply open this table in the EDIT menu, and change the value of LOCK_STATUS_CD from LOCKED to UNLOCKED .","title":"Unlock Process"},{"location":"locking-mechanism/#scalability","text":"This locking mechanism does not scale well if the table remains in SAS dataset (.sas7bdat) form. If you are deploying Data Controller for usage beyond 10-20 users then you are advised to put the control tables (DC library) in a database.","title":"Scalability"},{"location":"locking-mechanism/#third-party-applications","text":"Third party SAS apps may also make use of this locking table. This is handled by simply: Ensuring the DC library is assigned in the Service Using the mp_lockanytable macro to perform the lock Using the mp_lockanytable macro to perform the unlock Performing appropriate error handling to ensure an unlock if there are any issues in the service","title":"Third Party Applications"},{"location":"macros/","text":"Data Controller Macros \u00b6 \"Under the hood\" of Data Controller, SAS Macros are used for dynamic loading of all kinds of data thanks to the SAS ACCESS engines, including (but not limited to): Base (v9) SPDE CAS TERADATA POSTGRES NETEZZA ORACLE REDSHIFT OLEDB Native pass through is also available for optimised data loads in the following engines: Microsoft SQL SERVER Amazon REDSHIFT PostgreSQL The macros work dynamically, taking data types / lengths etc from the table metadata at runtime. Data Controller macros are available for unlimited (internal) use by licenced customers. They are currently in use, in production, in dozens of SAS environments globally and have been battle tested on large data volumes as well as some more esoteric gotchas such as: Short numerics WLATIN1 vs UTF-8 High numerical precision Long strings High column volume New data types in CAS (Type 6 as well as 1 & 2) Multiple load types are supported (full REPLACE, regular UPDATE, SCD2 loads, even BITEMPORAL). Composite keys are of course possible, so are retained keys (and the max key value can be table or data driven). Keys are taken from the staging table, so they could be based on an md5 hash, a UUID, or whatever you choose. It just needs to fit within the constraints of a SAS data step (so, max 32767 width for a character variable, 8 bytes numerical precision). A column (eg PROCESSED_DTTM) may be nominated to retain the current timestamp when doing any type of upload. If the stage table has columns that are not in the base table, the extra columns are ignored. If the base table has columns that are not in the stage table, the process aborts. There is also a locking mechanism to avoid conflict where multiple users (or jobs) are trying to load the same table at the same time. If the loader cannot get a lock, it will keep trying for a configurable amount of time, until it does. In the process of data discovery and comparing the hashes of the data values there are checks at every step of the way - the macro will abort if there are any WARNINGs or ERRORs or anything else awry. Some of these checks may be turned off for performance (eg the check for uniqueness of the business key in the staging table). All dataloads are tracked in an output table, which shows the the number of observations added / modified / deleted, as well as the user identity performing the load, the timestamp, the library / table being loaded, and a descriptive (user provided) message for the load. The macros are fully documented with Doxygen, similar to the SASjs Macro Core Library . The minimum amount of information needed to load a table is: Staging Library (default WORK) Staging Table Base Library Base Table Business Key fields Load Type An invocation of the loader macro might look something like this: A single (one year) subscription to data controller provides perpetual usage of the macros. Contact Allan Bowe for pricing details.","title":"Macros"},{"location":"macros/#data-controller-macros","text":"\"Under the hood\" of Data Controller, SAS Macros are used for dynamic loading of all kinds of data thanks to the SAS ACCESS engines, including (but not limited to): Base (v9) SPDE CAS TERADATA POSTGRES NETEZZA ORACLE REDSHIFT OLEDB Native pass through is also available for optimised data loads in the following engines: Microsoft SQL SERVER Amazon REDSHIFT PostgreSQL The macros work dynamically, taking data types / lengths etc from the table metadata at runtime. Data Controller macros are available for unlimited (internal) use by licenced customers. They are currently in use, in production, in dozens of SAS environments globally and have been battle tested on large data volumes as well as some more esoteric gotchas such as: Short numerics WLATIN1 vs UTF-8 High numerical precision Long strings High column volume New data types in CAS (Type 6 as well as 1 & 2) Multiple load types are supported (full REPLACE, regular UPDATE, SCD2 loads, even BITEMPORAL). Composite keys are of course possible, so are retained keys (and the max key value can be table or data driven). Keys are taken from the staging table, so they could be based on an md5 hash, a UUID, or whatever you choose. It just needs to fit within the constraints of a SAS data step (so, max 32767 width for a character variable, 8 bytes numerical precision). A column (eg PROCESSED_DTTM) may be nominated to retain the current timestamp when doing any type of upload. If the stage table has columns that are not in the base table, the extra columns are ignored. If the base table has columns that are not in the stage table, the process aborts. There is also a locking mechanism to avoid conflict where multiple users (or jobs) are trying to load the same table at the same time. If the loader cannot get a lock, it will keep trying for a configurable amount of time, until it does. In the process of data discovery and comparing the hashes of the data values there are checks at every step of the way - the macro will abort if there are any WARNINGs or ERRORs or anything else awry. Some of these checks may be turned off for performance (eg the check for uniqueness of the business key in the staging table). All dataloads are tracked in an output table, which shows the the number of observations added / modified / deleted, as well as the user identity performing the load, the timestamp, the library / table being loaded, and a descriptive (user provided) message for the load. The macros are fully documented with Doxygen, similar to the SASjs Macro Core Library . The minimum amount of information needed to load a table is: Staging Library (default WORK) Staging Table Base Library Base Table Business Key fields Load Type An invocation of the loader macro might look something like this: A single (one year) subscription to data controller provides perpetual usage of the macros. Contact Allan Bowe for pricing details.","title":"Data Controller Macros"},{"location":"privacy/","text":"Welcome to our Privacy Policy \u00b6 Your privacy is critically important to us. Bowe IO Ltd is located at: Bowe IO Ltd 29 Oldfield Rd Cumbria LA23 2AZ United Kingdom It is Bowe IO Ltd's policy to respect your privacy regarding any information we may collect while operating our website. This Privacy Policy applies to https://datacontroller.io and subdomains (hereinafter, \"us\", \"we\", or \"https://datacontroller.io\"). We respect your privacy and are committed to protecting personally identifiable information you may provide us through the Website. We have adopted this privacy policy (\"Privacy Policy\") to explain what information may be collected on our Website, how we use this information, and under what circumstances we may disclose the information to third parties. This Privacy Policy applies only to information we collect through the Website and does not apply to our collection of information from other sources. This Privacy Policy, together with the Terms and conditions posted on our Website, set forth the general rules and policies governing your use of our Website. Depending on your activities when visiting our Website, you may be required to agree to additional terms and conditions. Gathering of Personally-Identifying Information \u00b6 Certain visitors to Bowe IO Ltd's websites choose to interact with Bowe IO Ltd in ways that require Bowe IO Ltd to gather personally-identifying information. The amount and type of information that Bowe IO Ltd gathers depends on the nature of the interaction. For example, we ask visitors who sign up for a blog at https://datacontroller.io to provide a username and email address. Security \u00b6 The security of your Personal Information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage is 100% secure. While we strive to use commercially acceptable means to protect your Personal Information, we cannot guarantee its absolute security. Links To External Sites \u00b6 Our Service may contain links to external sites that are not operated by us. If you click on a third party link, you will be directed to that third party's site. We strongly advise you to review the Privacy Policy and terms and conditions of every site you visit. We have no control over, and assume no responsibility for the content, privacy policies or practices of any third party sites, products or services. Aggregated Statistics \u00b6 Bowe IO Ltd may collect statistics about the behavior of visitors to its website. Bowe IO Ltd may display this information publicly or provide it to others. However, Bowe IO Ltd does not disclose your personally-identifying information. Cookies \u00b6 To enrich and perfect your online experience, Bowe IO Ltd uses \"Cookies\", similar technologies and services provided by others to display personalized content, appropriate advertising and store your preferences on your computer. A cookie is a string of information that a website stores on a visitor's computer, and that the visitor's browser provides to the website each time the visitor returns. Bowe IO Ltd uses cookies to help Bowe IO Ltd identify and track visitors, their usage of https://datacontroller.io, and their website access preferences. Bowe IO Ltd visitors who do not wish to have cookies placed on their computers should set their browsers to refuse cookies before using Bowe IO Ltd's websites, with the drawback that certain features of Bowe IO Ltd's websites may not function properly without the aid of cookies. By continuing to navigate our website without changing your cookie settings, you hereby acknowledge and agree to Bowe IO Ltd's use of cookies. Privacy Policy Changes \u00b6 Although most changes are likely to be minor, Bowe IO Ltd may change its Privacy Policy from time to time, and in Bowe IO Ltd's sole discretion. Bowe IO Ltd encourages visitors to frequently check this page for any changes to its Privacy Policy. Your continued use of this site after any change in this Privacy Policy will constitute your acceptance of such change.","title":"Privacy Policy"},{"location":"privacy/#welcome-to-our-privacy-policy","text":"Your privacy is critically important to us. Bowe IO Ltd is located at: Bowe IO Ltd 29 Oldfield Rd Cumbria LA23 2AZ United Kingdom It is Bowe IO Ltd's policy to respect your privacy regarding any information we may collect while operating our website. This Privacy Policy applies to https://datacontroller.io and subdomains (hereinafter, \"us\", \"we\", or \"https://datacontroller.io\"). We respect your privacy and are committed to protecting personally identifiable information you may provide us through the Website. We have adopted this privacy policy (\"Privacy Policy\") to explain what information may be collected on our Website, how we use this information, and under what circumstances we may disclose the information to third parties. This Privacy Policy applies only to information we collect through the Website and does not apply to our collection of information from other sources. This Privacy Policy, together with the Terms and conditions posted on our Website, set forth the general rules and policies governing your use of our Website. Depending on your activities when visiting our Website, you may be required to agree to additional terms and conditions.","title":"Welcome to our Privacy Policy"},{"location":"privacy/#gathering-of-personally-identifying-information","text":"Certain visitors to Bowe IO Ltd's websites choose to interact with Bowe IO Ltd in ways that require Bowe IO Ltd to gather personally-identifying information. The amount and type of information that Bowe IO Ltd gathers depends on the nature of the interaction. For example, we ask visitors who sign up for a blog at https://datacontroller.io to provide a username and email address.","title":"Gathering of Personally-Identifying Information"},{"location":"privacy/#security","text":"The security of your Personal Information is important to us, but remember that no method of transmission over the Internet, or method of electronic storage is 100% secure. While we strive to use commercially acceptable means to protect your Personal Information, we cannot guarantee its absolute security.","title":"Security"},{"location":"privacy/#links-to-external-sites","text":"Our Service may contain links to external sites that are not operated by us. If you click on a third party link, you will be directed to that third party's site. We strongly advise you to review the Privacy Policy and terms and conditions of every site you visit. We have no control over, and assume no responsibility for the content, privacy policies or practices of any third party sites, products or services.","title":"Links To External Sites"},{"location":"privacy/#aggregated-statistics","text":"Bowe IO Ltd may collect statistics about the behavior of visitors to its website. Bowe IO Ltd may display this information publicly or provide it to others. However, Bowe IO Ltd does not disclose your personally-identifying information.","title":"Aggregated Statistics"},{"location":"privacy/#cookies","text":"To enrich and perfect your online experience, Bowe IO Ltd uses \"Cookies\", similar technologies and services provided by others to display personalized content, appropriate advertising and store your preferences on your computer. A cookie is a string of information that a website stores on a visitor's computer, and that the visitor's browser provides to the website each time the visitor returns. Bowe IO Ltd uses cookies to help Bowe IO Ltd identify and track visitors, their usage of https://datacontroller.io, and their website access preferences. Bowe IO Ltd visitors who do not wish to have cookies placed on their computers should set their browsers to refuse cookies before using Bowe IO Ltd's websites, with the drawback that certain features of Bowe IO Ltd's websites may not function properly without the aid of cookies. By continuing to navigate our website without changing your cookie settings, you hereby acknowledge and agree to Bowe IO Ltd's use of cookies.","title":"Cookies"},{"location":"privacy/#privacy-policy-changes","text":"Although most changes are likely to be minor, Bowe IO Ltd may change its Privacy Policy from time to time, and in Bowe IO Ltd's sole discretion. Bowe IO Ltd encourages visitors to frequently check this page for any changes to its Privacy Policy. Your continued use of this site after any change in this Privacy Policy will constitute your acceptance of such change.","title":"Privacy Policy Changes"},{"location":"roadmap/","text":"Roadmap \u00b6 Overview \u00b6 On this page you can find details of the Features that have currently been requested, that we agree would add value to the product, and are therefore in our development roadmap. Where customers are paying for the new Features (eg with our discounted Developer Days offer), then those Features will always take priority. Where funding is not available, new Features will be addressed during the Bench Time of our developers, and will always be performed after Bug Fixes. If you would like to see a new Feature added to Data Controller, then let's have a chat! Requested Features \u00b6 Where features are requested, whether there is budget or not, we will describe the work below and provide estimates. The following features are currently requested, and awaiting budget: Ability to set 'number of approvals' to zero, enabling instant updates (4 days) Ability to restore previous versions Ability to import complex excel data using Excel Maps (10.5 days) Ability to make automated submissions using an API Set Approvals to Zero \u00b6 The following changes are necessary to implement this feature: Adjust restriction on MPE_TABLES allowing 0 in NUM_APPROVALS_REQD Refactor editors/postdata enabling execution from editors/stagedata Additions to the test suite Pre-flight checks to ensure the SUBMITTER has APPROVAL rights prior to submit Log handling Updates to documentation Release Notes Complex Excel Uploads \u00b6 When Excel data arrives in multiple ranges, or individual cells, and the cells vary in terms of their column or row identifier, made more \"interesting\" with the use of merged cells - a rules engine becomes necessary! This feature enables the use of \"EXCEL MAPS\". It will enable multiple tables to be loaded in a single import, and that data can be scattered across multiple sheets / cells / ranges, accessed via the rules described further below. The backend SAS tables must still exist, but the column names do not need to appear in the excel file. To drive the behaviour, a new configuration table must be added to the control library - MPE_EXCEL_MAP. The columns are defined as follows: XLMAP_ID - a unique reference for the excel map XLMAP_LIB - the library of the target table for the data item or range XLMAP_DS - the target table for the data item or range XLMAP_COL - the target column for the data item or range XLMAP_SHEET - the sheet name in which to capture the data. Rules start with a forward slash (/). Example values: Sheet2 - an absolute reference /FIRST - the first tab in the workbook XLMAP_START - the rule used to find the top left of the range. Use \"R1C1\" notation to move the target. Example values: ABSOLUTE F4 - an absolute reference MATCH P R[0]C[2] |My Test - search column P for the string \"My Test\" then move 2 columns right MATCH 7 R[-2]C[-1] |Top Banana - search row 7 for the string \"Top Banana\" then move 2 rows up and 1 column left XLMAP_FINISH - The rule used to find the end of the range. Leave blank for individual cells. Example values: BLANKROW - search down until a blank row is found, then choose the row above it LASTDOWN - The last non blank cell below the start cell RIGHT 3 - select 3 more cells to the right (4 selected in total) To illustrate with an example - consider the following excel. The yellow cells need to be imported. The data will be imported into two SAS tables - the cells on the left will go into a table with multiple rows, and the cells on the right will be entered as a single row. The XLMAP_ID will also be added to both tables, and the tables will need to have had their keys and quality rules defined in Data Controller in the usual way. The MPE_EXCEL_MAP configuration entries would be as follows: XLMAP_ID XLMAP_LIB XLMAP_DS XLMAP_COL XLMAP_SHEET XLMAP_START XLMAP_FINISH MAP01 MYLIB DS1 MI_ITEM Current Month MATCH B R[1]C[0] |ITEM LASTDOWN MAP01 MYLIB DS1 MI_AMT Current Month MATCH C R[1]C[0] |AMOUNT LASTDOWN MAP01 MYLIB DS2 TMI Current Month ABSOLUTE F6 MAP01 MYLIB DS2 CB Current Month MATCH F R[2]C[0] |CASH BALANCE MAP01 MYLIB DS2 RENT Current Month MATCH E R[0]C[2] |Rent/mortgage MAP01 MYLIB DS2 CELL Current Month MATCH E R[0]C[2] |Cell phone To import the excel, the end user simply needs to navigate to the UPLOAD tab, select the appropriate map (eg MAP01), and upload. This will stage two tables (MYLIB.DS1 and MYLIB.DS2) which will go through the usual approval process and quality checks. A copy of the source excel file will be attached to each upload. Estimates \u00b6 Component Estimate (days) Description Frontend 1 Build ExcelMap page with dropdown (and fetching rules), plus drag & drop modal for excel capture Frontend 1 Create staged (unsubmitted) page with support for multiple tables Frontend 2 Create standalone framework utility for rules engine (utils folder), /FIRST sheet rule and Absolute rule Frontend 2 Implement MATCH rule (with BLANKROW, LASTDOWN and {DIRECTION + INTEGER} finish rules) Frontend 0.5 Developer documentation Frontend 2 Cypress tests Backend 0.5 Prep MPE_EXCEL_MAP table, including validations, integrate with DCLIB and add to CI build Backend 1 Create services to fetch Excel Maps and rules (only those the user has permissions for), corresponding SASjs tests, and update developer docs Backend 0.5 Publish online documentation for the overall Excel Maps feature Total: 10.5 days API Submissions \u00b6 Described here . Delivered Features \u00b6 Below are some examples of Features that have been requested (and delivered) into Data Controller. Column Level Security \u00b6 The columns that can be VIEWed or EDITed are now configurable. See docs Support for Special SAS Missing Numerics \u00b6 It is now possible to VIEW and EDIT special SAS missings, eg .a through to .z and ._ Ability to View & Edit Formats \u00b6 Format Catalogs can now be viewed, filtered, exported and edited. See docs Change Tracking Information in a Single Transaction Table \u00b6 Now available in mpe_audit Dynamic Filtering \u00b6 Previously, if a user filtered on, say, \"region\", and then filtered on \"store\", they would see stores for ALL regions (not just the region/regions already selected in the filter). Solution We added a checkbox to the top left of the filter dialog (default ON) for \"Dynamic Where Clause\". Whilst enabled, whenever a list of values is requested, it is filtered using every filter clause EXCEPT the one currently being modified. See documentation . Available from v.3.12. Dynamic Cell Validation \u00b6 When editing a value in a grid, the values presented to the user should be filtered according to additional rules, based on the values of other cells in the same row. Solution We provided two new config item in the MPE_VALIDATIONS table - to links an editable column to a HOOK script via a web service. The configuration would like like so: In this way, the entire record can be sent to SAS, for processing by the hook script, before returning the desired list of values. The HOOK_SCRIPT can be either a SAS program on a filesystem (identified by a \".sas\" extension) or the path to a registered SAS Service (STP or JES). The latter is identified by the absence of an extension. This approach provides maximum flexibility for delivering bespoke values in the edit grid dropdown. See documentation . Available from v.3.12. Row Level Security \u00b6 Row level security is provided by various products in both SAS 9 and Viya, based on the logged in user identity. This is problematic for the EDIT page, which - by necessity - operates under system account credentials. It is also the case that some customers need row level security but the data access engine does not support that. Therefore, there was a need to configure such a feature within the Data Controller product. Solution A new table (MPE_ROW_LEVEL_SECURITY) was added to the data controller library to allow complex rules to be applied based on the SAS group and the target table. Documentation is here Available from v.3.12. Formula Preservation \u00b6 Data Controller uses an OEM licence with the excellent sheetJS library. This enables us to read pretty much any version of Excel at breakneck speeds. By default, Data Controller will use the data model of the target table when extracting data, eg to determine whether a column should be character, numeric, date, datetime or time. Formats used to be ignored and only the cell values would be extracted when formulas are being used. Now, it is possible to extract and retain the actual formula itself, so it can be re-used when downloading the data again later. Solution A new table (MPE_EXCEL_CONFIG) was be added to the data controller library to allow the column with the formula to be specified. See documentation Available from v.3.12. Configurable Locale \u00b6 When importing spreadsheets with ambiguous dates (eg 01/02 or 02/01) the ANYDTDTM. informat was using the locale of the browser (en_us) instead of that of the client's actual country, resulting in incorrect dates being loaded. This is due to the default behaviour of the SAS Stored Process server. Solution We added a new config item so that the locale can be explicitly set for all Data Controller users. Restricted Viewer \u00b6 Data Controller relies on metadata permissions (in SAS 9) or authorization rules (in Viya) to determine who can see which table. We had a customer who was using Data Controller to provide data access to a company wide audience, most of whom did not have access to SAS client tools (such as Enterprise Guide) and so had not been set up in metadata before. It was necessary to find a way to restrict the tables which certain groups could see, without having to tweak permissions in SAS Management Console. Solution We added a new access level in the MPE_SECURITY table so that access could be restricted at both TABLE and LIBRARY level.","title":"Overview"},{"location":"roadmap/#roadmap","text":"","title":"Roadmap"},{"location":"roadmap/#overview","text":"On this page you can find details of the Features that have currently been requested, that we agree would add value to the product, and are therefore in our development roadmap. Where customers are paying for the new Features (eg with our discounted Developer Days offer), then those Features will always take priority. Where funding is not available, new Features will be addressed during the Bench Time of our developers, and will always be performed after Bug Fixes. If you would like to see a new Feature added to Data Controller, then let's have a chat!","title":"Overview"},{"location":"roadmap/#requested-features","text":"Where features are requested, whether there is budget or not, we will describe the work below and provide estimates. The following features are currently requested, and awaiting budget: Ability to set 'number of approvals' to zero, enabling instant updates (4 days) Ability to restore previous versions Ability to import complex excel data using Excel Maps (10.5 days) Ability to make automated submissions using an API","title":"Requested Features"},{"location":"roadmap/#set-approvals-to-zero","text":"The following changes are necessary to implement this feature: Adjust restriction on MPE_TABLES allowing 0 in NUM_APPROVALS_REQD Refactor editors/postdata enabling execution from editors/stagedata Additions to the test suite Pre-flight checks to ensure the SUBMITTER has APPROVAL rights prior to submit Log handling Updates to documentation Release Notes","title":"Set Approvals to Zero"},{"location":"roadmap/#complex-excel-uploads","text":"When Excel data arrives in multiple ranges, or individual cells, and the cells vary in terms of their column or row identifier, made more \"interesting\" with the use of merged cells - a rules engine becomes necessary! This feature enables the use of \"EXCEL MAPS\". It will enable multiple tables to be loaded in a single import, and that data can be scattered across multiple sheets / cells / ranges, accessed via the rules described further below. The backend SAS tables must still exist, but the column names do not need to appear in the excel file. To drive the behaviour, a new configuration table must be added to the control library - MPE_EXCEL_MAP. The columns are defined as follows: XLMAP_ID - a unique reference for the excel map XLMAP_LIB - the library of the target table for the data item or range XLMAP_DS - the target table for the data item or range XLMAP_COL - the target column for the data item or range XLMAP_SHEET - the sheet name in which to capture the data. Rules start with a forward slash (/). Example values: Sheet2 - an absolute reference /FIRST - the first tab in the workbook XLMAP_START - the rule used to find the top left of the range. Use \"R1C1\" notation to move the target. Example values: ABSOLUTE F4 - an absolute reference MATCH P R[0]C[2] |My Test - search column P for the string \"My Test\" then move 2 columns right MATCH 7 R[-2]C[-1] |Top Banana - search row 7 for the string \"Top Banana\" then move 2 rows up and 1 column left XLMAP_FINISH - The rule used to find the end of the range. Leave blank for individual cells. Example values: BLANKROW - search down until a blank row is found, then choose the row above it LASTDOWN - The last non blank cell below the start cell RIGHT 3 - select 3 more cells to the right (4 selected in total) To illustrate with an example - consider the following excel. The yellow cells need to be imported. The data will be imported into two SAS tables - the cells on the left will go into a table with multiple rows, and the cells on the right will be entered as a single row. The XLMAP_ID will also be added to both tables, and the tables will need to have had their keys and quality rules defined in Data Controller in the usual way. The MPE_EXCEL_MAP configuration entries would be as follows: XLMAP_ID XLMAP_LIB XLMAP_DS XLMAP_COL XLMAP_SHEET XLMAP_START XLMAP_FINISH MAP01 MYLIB DS1 MI_ITEM Current Month MATCH B R[1]C[0] |ITEM LASTDOWN MAP01 MYLIB DS1 MI_AMT Current Month MATCH C R[1]C[0] |AMOUNT LASTDOWN MAP01 MYLIB DS2 TMI Current Month ABSOLUTE F6 MAP01 MYLIB DS2 CB Current Month MATCH F R[2]C[0] |CASH BALANCE MAP01 MYLIB DS2 RENT Current Month MATCH E R[0]C[2] |Rent/mortgage MAP01 MYLIB DS2 CELL Current Month MATCH E R[0]C[2] |Cell phone To import the excel, the end user simply needs to navigate to the UPLOAD tab, select the appropriate map (eg MAP01), and upload. This will stage two tables (MYLIB.DS1 and MYLIB.DS2) which will go through the usual approval process and quality checks. A copy of the source excel file will be attached to each upload.","title":"Complex Excel Uploads"},{"location":"roadmap/#estimates","text":"Component Estimate (days) Description Frontend 1 Build ExcelMap page with dropdown (and fetching rules), plus drag & drop modal for excel capture Frontend 1 Create staged (unsubmitted) page with support for multiple tables Frontend 2 Create standalone framework utility for rules engine (utils folder), /FIRST sheet rule and Absolute rule Frontend 2 Implement MATCH rule (with BLANKROW, LASTDOWN and {DIRECTION + INTEGER} finish rules) Frontend 0.5 Developer documentation Frontend 2 Cypress tests Backend 0.5 Prep MPE_EXCEL_MAP table, including validations, integrate with DCLIB and add to CI build Backend 1 Create services to fetch Excel Maps and rules (only those the user has permissions for), corresponding SASjs tests, and update developer docs Backend 0.5 Publish online documentation for the overall Excel Maps feature Total: 10.5 days","title":"Estimates"},{"location":"roadmap/#api-submissions","text":"Described here .","title":"API Submissions"},{"location":"roadmap/#delivered-features","text":"Below are some examples of Features that have been requested (and delivered) into Data Controller.","title":"Delivered Features"},{"location":"roadmap/#column-level-security","text":"The columns that can be VIEWed or EDITed are now configurable. See docs","title":"Column Level Security"},{"location":"roadmap/#support-for-special-sas-missing-numerics","text":"It is now possible to VIEW and EDIT special SAS missings, eg .a through to .z and ._","title":"Support for Special SAS Missing Numerics"},{"location":"roadmap/#ability-to-view-edit-formats","text":"Format Catalogs can now be viewed, filtered, exported and edited. See docs","title":"Ability to View &amp; Edit Formats"},{"location":"roadmap/#change-tracking-information-in-a-single-transaction-table","text":"Now available in mpe_audit","title":"Change Tracking Information in a Single Transaction Table"},{"location":"roadmap/#dynamic-filtering","text":"Previously, if a user filtered on, say, \"region\", and then filtered on \"store\", they would see stores for ALL regions (not just the region/regions already selected in the filter). Solution We added a checkbox to the top left of the filter dialog (default ON) for \"Dynamic Where Clause\". Whilst enabled, whenever a list of values is requested, it is filtered using every filter clause EXCEPT the one currently being modified. See documentation . Available from v.3.12.","title":"Dynamic Filtering"},{"location":"roadmap/#dynamic-cell-validation","text":"When editing a value in a grid, the values presented to the user should be filtered according to additional rules, based on the values of other cells in the same row. Solution We provided two new config item in the MPE_VALIDATIONS table - to links an editable column to a HOOK script via a web service. The configuration would like like so: In this way, the entire record can be sent to SAS, for processing by the hook script, before returning the desired list of values. The HOOK_SCRIPT can be either a SAS program on a filesystem (identified by a \".sas\" extension) or the path to a registered SAS Service (STP or JES). The latter is identified by the absence of an extension. This approach provides maximum flexibility for delivering bespoke values in the edit grid dropdown. See documentation . Available from v.3.12.","title":"Dynamic Cell Validation"},{"location":"roadmap/#row-level-security","text":"Row level security is provided by various products in both SAS 9 and Viya, based on the logged in user identity. This is problematic for the EDIT page, which - by necessity - operates under system account credentials. It is also the case that some customers need row level security but the data access engine does not support that. Therefore, there was a need to configure such a feature within the Data Controller product. Solution A new table (MPE_ROW_LEVEL_SECURITY) was added to the data controller library to allow complex rules to be applied based on the SAS group and the target table. Documentation is here Available from v.3.12.","title":"Row Level Security"},{"location":"roadmap/#formula-preservation","text":"Data Controller uses an OEM licence with the excellent sheetJS library. This enables us to read pretty much any version of Excel at breakneck speeds. By default, Data Controller will use the data model of the target table when extracting data, eg to determine whether a column should be character, numeric, date, datetime or time. Formats used to be ignored and only the cell values would be extracted when formulas are being used. Now, it is possible to extract and retain the actual formula itself, so it can be re-used when downloading the data again later. Solution A new table (MPE_EXCEL_CONFIG) was be added to the data controller library to allow the column with the formula to be specified. See documentation Available from v.3.12.","title":"Formula Preservation"},{"location":"roadmap/#configurable-locale","text":"When importing spreadsheets with ambiguous dates (eg 01/02 or 02/01) the ANYDTDTM. informat was using the locale of the browser (en_us) instead of that of the client's actual country, resulting in incorrect dates being loaded. This is due to the default behaviour of the SAS Stored Process server. Solution We added a new config item so that the locale can be explicitly set for all Data Controller users.","title":"Configurable Locale"},{"location":"roadmap/#restricted-viewer","text":"Data Controller relies on metadata permissions (in SAS 9) or authorization rules (in Viya) to determine who can see which table. We had a customer who was using Data Controller to provide data access to a company wide audience, most of whom did not have access to SAS client tools (such as Enterprise Guide) and so had not been set up in metadata before. It was necessary to find a way to restrict the tables which certain groups could see, without having to tweak permissions in SAS Management Console. Solution We added a new access level in the MPE_SECURITY table so that access could be restricted at both TABLE and LIBRARY level.","title":"Restricted Viewer"},{"location":"row-level-security/","text":"Row Level Security \u00b6 Row level security is implemented through the configuration of filter queries, that are applied at backend. This provides a very flexible way to restrict rows - you can restrict rows for any table in SAS, be that a dataset or a database. See also: Column Level Security Configuration \u00b6 The columns in MPE_ROW_LEVEL_SECURITY should be configured as follows: RLS_SCOPE \u00b6 Determines whether the rule applies to the VIEW page, the EDIT page, or ALL pages. RLS_GROUP \u00b6 The SAS Group to which the rule applies. The user could also be a member of a DC group . If a user is in none of these groups, no rules apply. If the user is in multiple groups, then the rules for each are applied with an OR condition. RLS_LIBREF \u00b6 The library of the target table against which the rule will be applied RLS_TABLE \u00b6 The target table against which the rule will be applied RLS_GROUP_LOGIC \u00b6 When creating multiple subgroups (identified by SUBGROUP_ID) this determines whether those groups are joined using an AND, or an OR condition. This value should be the same for the entire query (unique per RLS_SCOPE/RLS_GROUP/RLS_LIBREF/RLS_TABLE combination). RLS_SUBGROUP_LOGIC \u00b6 This determines how individual clauses are joined at subgroup level (identified by SUBGROUP_ID). Valid values: AND, OR. RLS_SUBGROUP_ID \u00b6 This variable is an integer, and used to divide a complex filter into numerous subgroups. RLS_VARIABLE_NM \u00b6 This is the name of the variable against which a filter value will be applied RLS_OPERATOR \u00b6 The available operator will depend on whether the column is character or numeric. Example values: = < > <= >= BETWEEN CONTAINS NE (not equal) NOT IN RLS_RAW_VALUE \u00b6 This is the value used to the right of the operator. It is important to enter the values in the correct format, else validation failures will ensue (the backend will reject incorrect syntax to avoid the risk of SAS code injection). The format depends on the operator, and the variable type. All character values MUST be enclosed in single quotes (eg 'example') IN and NOT IN must be wrapped in brackets BETWEEN must contain an AND If there are invalid values, an error message will be shown, identifying which value was invalid. If you would like to inspect the validation routine, take a look at mp_filtercheck.sas . RLS_ACTIVE \u00b6 If you would like this rule to be applied, be sure this value is set to 1. Example Config \u00b6 Example values as follows: RLS_SCOPE:$4 RLS_GROUP:$64 RLS_LIBREF:$8 RLS_TABLE:$32 RLS_GROUP_LOGIC:$3. RLS_SUBGROUP_LOGIC:$3. RLS_SUBGROUP_ID:8. RLS_VARIABLE_NM:$32 RLS_OPERATOR_NM:$16 RLS_RAW_VALUE:$4000 RLS_ACTIVE:8. EDIT Group 1 MYLIB MYDS AND AND 1 VAR_1 = Some text value 1 ALL Group 1 MYLIB MYDS AND AND 1 VAR_2 IN this 1 ALL Group 1 MYLIB MYDS AND AND 1 VAR_2 IN or 1 VIEW Group 1 MYLIB MYDS AND AND 1 VAR_2 IN that 1 ALL Group 1 MYLIB MYDS AND AND 1 VAR_3 < 42 1 ALL Group 2 MYLIB MYDS AND AND 1 VAR_4 Contains ;%badmacro() 1 If a user is in Group 2, and querying an EDIT table, the query will look like this: select * from mylib.myds where ( var_4 CONTAINS ';%badmacro()' ) If the user is in both Group 1 AND Group 2, querying a VIEW-only table, the filter will be as follows: select * from mylib.myds where (var_2 IN ('this','or','that') AND var_3 < 42 ) OR ( var_4 CONTAINS ';%badmacro()' )","title":"Row Level Security"},{"location":"row-level-security/#row-level-security","text":"Row level security is implemented through the configuration of filter queries, that are applied at backend. This provides a very flexible way to restrict rows - you can restrict rows for any table in SAS, be that a dataset or a database. See also: Column Level Security","title":"Row Level Security"},{"location":"row-level-security/#configuration","text":"The columns in MPE_ROW_LEVEL_SECURITY should be configured as follows:","title":"Configuration"},{"location":"row-level-security/#rls_scope","text":"Determines whether the rule applies to the VIEW page, the EDIT page, or ALL pages.","title":"RLS_SCOPE"},{"location":"row-level-security/#rls_group","text":"The SAS Group to which the rule applies. The user could also be a member of a DC group . If a user is in none of these groups, no rules apply. If the user is in multiple groups, then the rules for each are applied with an OR condition.","title":"RLS_GROUP"},{"location":"row-level-security/#rls_libref","text":"The library of the target table against which the rule will be applied","title":"RLS_LIBREF"},{"location":"row-level-security/#rls_table","text":"The target table against which the rule will be applied","title":"RLS_TABLE"},{"location":"row-level-security/#rls_group_logic","text":"When creating multiple subgroups (identified by SUBGROUP_ID) this determines whether those groups are joined using an AND, or an OR condition. This value should be the same for the entire query (unique per RLS_SCOPE/RLS_GROUP/RLS_LIBREF/RLS_TABLE combination).","title":"RLS_GROUP_LOGIC"},{"location":"row-level-security/#rls_subgroup_logic","text":"This determines how individual clauses are joined at subgroup level (identified by SUBGROUP_ID). Valid values: AND, OR.","title":"RLS_SUBGROUP_LOGIC"},{"location":"row-level-security/#rls_subgroup_id","text":"This variable is an integer, and used to divide a complex filter into numerous subgroups.","title":"RLS_SUBGROUP_ID"},{"location":"row-level-security/#rls_variable_nm","text":"This is the name of the variable against which a filter value will be applied","title":"RLS_VARIABLE_NM"},{"location":"row-level-security/#rls_operator","text":"The available operator will depend on whether the column is character or numeric. Example values: = < > <= >= BETWEEN CONTAINS NE (not equal) NOT IN","title":"RLS_OPERATOR"},{"location":"row-level-security/#rls_raw_value","text":"This is the value used to the right of the operator. It is important to enter the values in the correct format, else validation failures will ensue (the backend will reject incorrect syntax to avoid the risk of SAS code injection). The format depends on the operator, and the variable type. All character values MUST be enclosed in single quotes (eg 'example') IN and NOT IN must be wrapped in brackets BETWEEN must contain an AND If there are invalid values, an error message will be shown, identifying which value was invalid. If you would like to inspect the validation routine, take a look at mp_filtercheck.sas .","title":"RLS_RAW_VALUE"},{"location":"row-level-security/#rls_active","text":"If you would like this rule to be applied, be sure this value is set to 1.","title":"RLS_ACTIVE"},{"location":"row-level-security/#example-config","text":"Example values as follows: RLS_SCOPE:$4 RLS_GROUP:$64 RLS_LIBREF:$8 RLS_TABLE:$32 RLS_GROUP_LOGIC:$3. RLS_SUBGROUP_LOGIC:$3. RLS_SUBGROUP_ID:8. RLS_VARIABLE_NM:$32 RLS_OPERATOR_NM:$16 RLS_RAW_VALUE:$4000 RLS_ACTIVE:8. EDIT Group 1 MYLIB MYDS AND AND 1 VAR_1 = Some text value 1 ALL Group 1 MYLIB MYDS AND AND 1 VAR_2 IN this 1 ALL Group 1 MYLIB MYDS AND AND 1 VAR_2 IN or 1 VIEW Group 1 MYLIB MYDS AND AND 1 VAR_2 IN that 1 ALL Group 1 MYLIB MYDS AND AND 1 VAR_3 < 42 1 ALL Group 2 MYLIB MYDS AND AND 1 VAR_4 Contains ;%badmacro() 1 If a user is in Group 2, and querying an EDIT table, the query will look like this: select * from mylib.myds where ( var_4 CONTAINS ';%badmacro()' ) If the user is in both Group 1 AND Group 2, querying a VIEW-only table, the filter will be as follows: select * from mylib.myds where (var_2 IN ('this','or','that') AND var_3 < 42 ) OR ( var_4 CONTAINS ';%badmacro()' )","title":"Example Config"},{"location":"videos/","text":"Data Controller Videos \u00b6 A collection of videos made in relation to Data Controller. Some of them were recorded on earlier versions, hence the slight UI differences. Explainer Videos \u00b6 Data Controller - a Customer Story \u00b6 An illustration of the utility of Data Controller for Data & Analytics teams in regulated industries. Use Case Video - Manual Overrides \u00b6 A 1 minute video illustrating the value of using of Data Controller to make manual overrides. Explainer Videos \u00b6 A short explainer video showing the core functionality of the product. A full length explainer video for the SAS User Group UK & Ireland Column Level Security \u00b6 Restrict which columns are visible in VIEW, or editable in EDIT Full Table Search \u00b6 Data Controller for SAS\u00ae enables full text search on Global CASLIB tables (and SAS 9 tables too) Excel to Viya CAS Table \u00b6 Loading an Excel file into a 5 million row CASLIB table Data Viewer \u00b6 Data Controller for SAS\u00ae isn't just for editing (and approving) data - it can also be used to query and download! Data Lineage \u00b6 Data Lineage is one of the most powerful features of DI Studio generated ETL. This tool queries it and makes a graphical output to help DI Developers, Data Modellers, and Business Analysts understand the data from both Source to Target and Target to Source. It is possible to share the URL to any lineage diagram, and export in PNG, SVG and CSV formats. Lineage can be viewed forwards or backwards. This feature is only available on the SAS 9 version of Data Controller. Table Level \u00b6 Table level lineage shows tables (colour coded per library) and associated jobs (with links to metadata definitions). The extraction method is built with proc metadata and runs extremely fast. Column Level \u00b6 Column level lineage shows the transformations and any business logic applied to each variable during the flow. Data items are distinguished between files, database tables, and SAS datasets. The extraction is a little slower than table level lineage due to the additional detail, however the impact is lessened for second and subsequent requests thanks to backend caching. Email Alerts \u00b6 Adding Email Alerts in Data Controller is a case of updating the MPE_ALERTS table (to say which alerts you wish to send) and the MPE_EMAILS table (only if your emails are not stored in metadata) Deploying Data Controller \u00b6 The SAS 9 evaluation version of the Data Controller comes packaged in a single SPK, which can be deployed in under 30 seconds! Uploading a CSV and Downloading Datalines \u00b6 This video demonstrates 2 features in 50 seconds! 1 - Excel uploads. Data Controller will let you drag a spreadsheet into any target table without having to specify variable formats etc in advance. Changes are routed through the usual approval process with audit trail. 2 - Audit trail with original excel. Download a copy of the exact excel that was uploaded. Locked Datasets \u00b6 In unix environments, when attempting to edit a locked table, users are notified with regard to which PID contains the lock. Uploading a Password Protected Excel File \u00b6 With Data Controller you can upload password protected excel files into SAS. These are opened in the browser (thanks to our OEM licence of SheetJS) and the underlying data is extracted automatically.","title":"Videos"},{"location":"videos/#data-controller-videos","text":"A collection of videos made in relation to Data Controller. Some of them were recorded on earlier versions, hence the slight UI differences.","title":"Data Controller Videos"},{"location":"videos/#explainer-videos","text":"","title":"Explainer Videos"},{"location":"videos/#data-controller-a-customer-story","text":"An illustration of the utility of Data Controller for Data & Analytics teams in regulated industries.","title":"Data Controller - a Customer Story"},{"location":"videos/#use-case-video-manual-overrides","text":"A 1 minute video illustrating the value of using of Data Controller to make manual overrides.","title":"Use Case Video - Manual Overrides"},{"location":"videos/#explainer-videos_1","text":"A short explainer video showing the core functionality of the product. A full length explainer video for the SAS User Group UK & Ireland","title":"Explainer Videos"},{"location":"videos/#column-level-security","text":"Restrict which columns are visible in VIEW, or editable in EDIT","title":"Column Level Security"},{"location":"videos/#full-table-search","text":"Data Controller for SAS\u00ae enables full text search on Global CASLIB tables (and SAS 9 tables too)","title":"Full Table Search"},{"location":"videos/#excel-to-viya-cas-table","text":"Loading an Excel file into a 5 million row CASLIB table","title":"Excel to Viya CAS Table"},{"location":"videos/#data-viewer","text":"Data Controller for SAS\u00ae isn't just for editing (and approving) data - it can also be used to query and download!","title":"Data Viewer"},{"location":"videos/#data-lineage","text":"Data Lineage is one of the most powerful features of DI Studio generated ETL. This tool queries it and makes a graphical output to help DI Developers, Data Modellers, and Business Analysts understand the data from both Source to Target and Target to Source. It is possible to share the URL to any lineage diagram, and export in PNG, SVG and CSV formats. Lineage can be viewed forwards or backwards. This feature is only available on the SAS 9 version of Data Controller.","title":"Data Lineage"},{"location":"videos/#table-level","text":"Table level lineage shows tables (colour coded per library) and associated jobs (with links to metadata definitions). The extraction method is built with proc metadata and runs extremely fast.","title":"Table Level"},{"location":"videos/#column-level","text":"Column level lineage shows the transformations and any business logic applied to each variable during the flow. Data items are distinguished between files, database tables, and SAS datasets. The extraction is a little slower than table level lineage due to the additional detail, however the impact is lessened for second and subsequent requests thanks to backend caching.","title":"Column Level"},{"location":"videos/#email-alerts","text":"Adding Email Alerts in Data Controller is a case of updating the MPE_ALERTS table (to say which alerts you wish to send) and the MPE_EMAILS table (only if your emails are not stored in metadata)","title":"Email Alerts"},{"location":"videos/#deploying-data-controller","text":"The SAS 9 evaluation version of the Data Controller comes packaged in a single SPK, which can be deployed in under 30 seconds!","title":"Deploying Data Controller"},{"location":"videos/#uploading-a-csv-and-downloading-datalines","text":"This video demonstrates 2 features in 50 seconds! 1 - Excel uploads. Data Controller will let you drag a spreadsheet into any target table without having to specify variable formats etc in advance. Changes are routed through the usual approval process with audit trail. 2 - Audit trail with original excel. Download a copy of the exact excel that was uploaded.","title":"Uploading a CSV and Downloading Datalines"},{"location":"videos/#locked-datasets","text":"In unix environments, when attempting to edit a locked table, users are notified with regard to which PID contains the lock.","title":"Locked Datasets"},{"location":"videos/#uploading-a-password-protected-excel-file","text":"With Data Controller you can upload password protected excel files into SAS. These are opened in the browser (thanks to our OEM licence of SheetJS) and the underlying data is extracted automatically.","title":"Uploading a Password Protected Excel File"},{"location":"viewboxes/","text":"ViewBoxes \u00b6 Often when editing (or examining) raw data, it is helpful to see it alongside related information in other tables. With ViewBoxes you can align up to 6 other tables in front of your main grid, in both the VIEW and EDIT menu. Each individual viewbox has the following features: Choose the columns to display (and which order) Resize individual boxes (or reset to original) Full filtering capability (complex clauses) Minimise / Restore all, or individually Reposition - manually, or snap to grid Open in Editor (if an editable table) Primary Key highlighting Frontend sorting Search all data Open in Viewer All of the above information (except search and frontend sort) is stored in the URL - so you can share a link to a complex ViewBox setup with a colleague, who can then open the same view of the data.","title":"ViewBoxes"},{"location":"viewboxes/#viewboxes","text":"Often when editing (or examining) raw data, it is helpful to see it alongside related information in other tables. With ViewBoxes you can align up to 6 other tables in front of your main grid, in both the VIEW and EDIT menu. Each individual viewbox has the following features: Choose the columns to display (and which order) Resize individual boxes (or reset to original) Full filtering capability (complex clauses) Minimise / Restore all, or individually Reposition - manually, or snap to grid Open in Editor (if an editable table) Primary Key highlighting Frontend sorting Search all data Open in Viewer All of the above information (except search and frontend sort) is stored in the URL - so you can share a link to a complex ViewBox setup with a colleague, who can then open the same view of the data.","title":"ViewBoxes"},{"location":"tables/mpe_audit/","text":"MPE_AUDIT \u00b6 The MPE_AUDIT table contains all deletions, modifications and additions to data in Data Controller (or using the underlying macros ). The underlying utility is open source and documented here . Columns \u00b6 LOAD_REF (PK). This is supplied to the bitemporal_dataloader() macro at backend, and corresponds to the unique folder in which the staged data resides. LIBREF (PK). The target libref. DSN (PK). The target table name. KEY_HASH (PK). This is a pipe seperated md5() hash of the primary key values - it uniquely identifies a single record. TGTVAR_NM (PK). Target variable name (32 chars) PROCESSED_DTTM. The timestamp at which the record was processed. MOVE_TYPE. Either (A)ppended, (D)eleted or (M)odified IS_PK. Set to 1 if the variable is part of the primary key. IS_DIFF. For modified records, is 1 for a change and 0 for no change. Set to -1 for appends / deletes. TGTVAR_TYPE. Either (C)haracter or (N)umeric OLDVAL_NUM. Old (numeric) value NEWVAL_NUM. New (numeric) value OLDVAL_CHAR. Old (character) value NEWVAL_CHAR. New (character) value","title":"MPE_AUDIT"},{"location":"tables/mpe_audit/#mpe_audit","text":"The MPE_AUDIT table contains all deletions, modifications and additions to data in Data Controller (or using the underlying macros ). The underlying utility is open source and documented here .","title":"MPE_AUDIT"},{"location":"tables/mpe_audit/#columns","text":"LOAD_REF (PK). This is supplied to the bitemporal_dataloader() macro at backend, and corresponds to the unique folder in which the staged data resides. LIBREF (PK). The target libref. DSN (PK). The target table name. KEY_HASH (PK). This is a pipe seperated md5() hash of the primary key values - it uniquely identifies a single record. TGTVAR_NM (PK). Target variable name (32 chars) PROCESSED_DTTM. The timestamp at which the record was processed. MOVE_TYPE. Either (A)ppended, (D)eleted or (M)odified IS_PK. Set to 1 if the variable is part of the primary key. IS_DIFF. For modified records, is 1 for a change and 0 for no change. Set to -1 for appends / deletes. TGTVAR_TYPE. Either (C)haracter or (N)umeric OLDVAL_NUM. Old (numeric) value NEWVAL_NUM. New (numeric) value OLDVAL_CHAR. Old (character) value NEWVAL_CHAR. New (character) value","title":"Columns"},{"location":"tables/mpe_column_level_security/","text":"MPE_COLUMN_LEVEL_SECURITY \u00b6 The MPE_COLUMN_LEVEL_SECURITY table is used to configure which groups can VIEW or EDIT particular columns within a table. More details are available in the user guide Columns \u00b6 TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 CLS_SCOPE char(4) : Either VIEW, EDIT or ALL \ud83d\udd11 CLS_GROUP char(64) : The group to which the rule applies \ud83d\udd11 CLS_LIBREF char(8) : The libref to which the rule applies \ud83d\udd11 CLS_TABLE char(32) : The table to which the rule applies \ud83d\udd11 CLS_VARIABLE_NM char(32) : The variable to VIEW or EDIT CLS_ACTIVE num : Whether the rule is active or not CLS_HIDE num : Whether the column should be hidden in EDIT mode","title":"MPE_COLUMN_LEVEL_SECURITY"},{"location":"tables/mpe_column_level_security/#mpe_column_level_security","text":"The MPE_COLUMN_LEVEL_SECURITY table is used to configure which groups can VIEW or EDIT particular columns within a table. More details are available in the user guide","title":"MPE_COLUMN_LEVEL_SECURITY"},{"location":"tables/mpe_column_level_security/#columns","text":"TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 CLS_SCOPE char(4) : Either VIEW, EDIT or ALL \ud83d\udd11 CLS_GROUP char(64) : The group to which the rule applies \ud83d\udd11 CLS_LIBREF char(8) : The libref to which the rule applies \ud83d\udd11 CLS_TABLE char(32) : The table to which the rule applies \ud83d\udd11 CLS_VARIABLE_NM char(32) : The variable to VIEW or EDIT CLS_ACTIVE num : Whether the rule is active or not CLS_HIDE num : Whether the column should be hidden in EDIT mode","title":"Columns"},{"location":"tables/mpe_config/","text":"MPE_CONFIG \u00b6 The MPE_CONFIG table enables global system options. Further detail on each option can be found in the description of the option itself, or on the options page. The table is SCD2 controlled for ease of rollback and version management. Columns \u00b6 \ud83d\udd11 TX_FROM num : SCD2 open datetime \ud83d\udd11 VAR_SCOPE char(10) : A short code for grouping sets of options \ud83d\udd11 VAR_NAME char(32) : The name of the option VAR_VALUE char(5000) : The value of the option VAR_ACTIVE num : Whether the rule should be used (1) or ignored (0). Setting rules to 0 is a convenient way to turn them off without deleting them. VAR_DESC char(300) : A short description of the option. TX_TO num : SCD2 close datetime","title":"MPE_CONFIG"},{"location":"tables/mpe_config/#mpe_config","text":"The MPE_CONFIG table enables global system options. Further detail on each option can be found in the description of the option itself, or on the options page. The table is SCD2 controlled for ease of rollback and version management.","title":"MPE_CONFIG"},{"location":"tables/mpe_config/#columns","text":"\ud83d\udd11 TX_FROM num : SCD2 open datetime \ud83d\udd11 VAR_SCOPE char(10) : A short code for grouping sets of options \ud83d\udd11 VAR_NAME char(32) : The name of the option VAR_VALUE char(5000) : The value of the option VAR_ACTIVE num : Whether the rule should be used (1) or ignored (0). Setting rules to 0 is a convenient way to turn them off without deleting them. VAR_DESC char(300) : A short description of the option. TX_TO num : SCD2 close datetime","title":"Columns"},{"location":"tables/mpe_datacatalog_libs/","text":"MPE_DATACATALOG_LIBS \u00b6 The MPE_DATACATALOG_LIBS table catalogs library attributes such as engine, paths, permissions, owners & schemas. More frequently changing attributes (such as size and number of tables) are stored in MPE_DATASTATUS_LIBS . To ignore additional librefs, or to trigger a scan, see the Refresh Data Catalog instructions . Columns \u00b6 TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) ENGINE char(32) : The engine used to connect to the library LIBNAME char(256) : The Library Name (from metadata if SAS 9) PATHS char(8192) : The directories used (BASE engine only) PERMS char(500) : The directory permissions (BASE engine only) OWNERS char(500) : The directory owners (BASE engine only) SCHEMAS char(500) : The library schema (DB engines) LIBID char(17) : The Library Id (from metadata if SAS 9)","title":"MPE_DATACATALOG_LIBS"},{"location":"tables/mpe_datacatalog_libs/#mpe_datacatalog_libs","text":"The MPE_DATACATALOG_LIBS table catalogs library attributes such as engine, paths, permissions, owners & schemas. More frequently changing attributes (such as size and number of tables) are stored in MPE_DATASTATUS_LIBS . To ignore additional librefs, or to trigger a scan, see the Refresh Data Catalog instructions .","title":"MPE_DATACATALOG_LIBS"},{"location":"tables/mpe_datacatalog_libs/#columns","text":"TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) ENGINE char(32) : The engine used to connect to the library LIBNAME char(256) : The Library Name (from metadata if SAS 9) PATHS char(8192) : The directories used (BASE engine only) PERMS char(500) : The directory permissions (BASE engine only) OWNERS char(500) : The directory owners (BASE engine only) SCHEMAS char(500) : The library schema (DB engines) LIBID char(17) : The Library Id (from metadata if SAS 9)","title":"Columns"},{"location":"tables/mpe_datacatalog_tabs/","text":"MPE_DATACATALOG_TABS \u00b6 The MPE_DATACATALOG_TABS table catalogs attributes such as number of variables, compression status, and primary key fields. More frequently changing attributes (such as size modification date and number of observations) are stored in MPE_DATASTATUS_TABS . To trigger a scan, see the Refresh Data Catalog instructions . Columns \u00b6 TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) \ud83d\udd11 DSN char(64) : The library member name MEMTYPE char(8) : The member type DBMS_MEMTYPE char(32) : The DBMS Member Type MEMLABEL char(512) : The Data Set Label TYPEMEM char(8) : The Data Set Type NVAR num : The number of variables COMPRESS char(8) : The compression routine PK_FIELDS char(512) : The list of primary key fields. These are deduced from the table constraints. A Primary key column is identified by being in a constraint (or index) that is both UNIQUE and NOT NULL.","title":"MPE_DATACATALOG_TABS"},{"location":"tables/mpe_datacatalog_tabs/#mpe_datacatalog_tabs","text":"The MPE_DATACATALOG_TABS table catalogs attributes such as number of variables, compression status, and primary key fields. More frequently changing attributes (such as size modification date and number of observations) are stored in MPE_DATASTATUS_TABS . To trigger a scan, see the Refresh Data Catalog instructions .","title":"MPE_DATACATALOG_TABS"},{"location":"tables/mpe_datacatalog_tabs/#columns","text":"TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) \ud83d\udd11 DSN char(64) : The library member name MEMTYPE char(8) : The member type DBMS_MEMTYPE char(32) : The DBMS Member Type MEMLABEL char(512) : The Data Set Label TYPEMEM char(8) : The Data Set Type NVAR num : The number of variables COMPRESS char(8) : The compression routine PK_FIELDS char(512) : The list of primary key fields. These are deduced from the table constraints. A Primary key column is identified by being in a constraint (or index) that is both UNIQUE and NOT NULL.","title":"Columns"},{"location":"tables/mpe_datacatalog_vars/","text":"MPE_DATACATALOG_VARS \u00b6 The MPE_DATACATALOG_VARS table catalogs variable attributes such as primary key status, not null constraints and index usage. To trigger a scan, see the Refresh Data Catalog instructions . Columns \u00b6 TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) \ud83d\udd11 DSN char(64) : The library member name \ud83d\udd11 NAME char(64) : The variable name MEMTYPE char(8) : The member type TYPE char(16) : The column type LENGTH num : The column length VARNUM num : The column position in the table LABEL char(256) : The column label FORMAT char(49) : The SAS format associated with the column IDXUSAGE char(9) : The column index type NOTNULL char(3) : The NOT NULL status PK_IND num : A flag to say whether the column is part of the primary key (1=PK, 0=Not PK). A Primary key column is identified by being in a constraint (or index) that is both UNIQUE and NOT NULL.","title":"MPE_DATACATALOG_VARS"},{"location":"tables/mpe_datacatalog_vars/#mpe_datacatalog_vars","text":"The MPE_DATACATALOG_VARS table catalogs variable attributes such as primary key status, not null constraints and index usage. To trigger a scan, see the Refresh Data Catalog instructions .","title":"MPE_DATACATALOG_VARS"},{"location":"tables/mpe_datacatalog_vars/#columns","text":"TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) \ud83d\udd11 DSN char(64) : The library member name \ud83d\udd11 NAME char(64) : The variable name MEMTYPE char(8) : The member type TYPE char(16) : The column type LENGTH num : The column length VARNUM num : The column position in the table LABEL char(256) : The column label FORMAT char(49) : The SAS format associated with the column IDXUSAGE char(9) : The column index type NOTNULL char(3) : The NOT NULL status PK_IND num : A flag to say whether the column is part of the primary key (1=PK, 0=Not PK). A Primary key column is identified by being in a constraint (or index) that is both UNIQUE and NOT NULL.","title":"Columns"},{"location":"tables/mpe_datastatus_libs/","text":"MPE_DATASTATUS_LIBS \u00b6 The MPE_DATASTATUS_LIBS table captures frequently changing SAS library attributes such as size (if filesystem based) and the number of tables. To trigger a scan, see the Refresh Data Catalog instructions . Columns \u00b6 TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) LIBSIZE num : The size of the library (in bytes), displayed with the SIZEKMG. format. Only applicable to BASE engine libraries. TABLE_CNT num : The number of tables in the library.","title":"MPE_DATASTATUS_LIBS"},{"location":"tables/mpe_datastatus_libs/#mpe_datastatus_libs","text":"The MPE_DATASTATUS_LIBS table captures frequently changing SAS library attributes such as size (if filesystem based) and the number of tables. To trigger a scan, see the Refresh Data Catalog instructions .","title":"MPE_DATASTATUS_LIBS"},{"location":"tables/mpe_datastatus_libs/#columns","text":"TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) LIBSIZE num : The size of the library (in bytes), displayed with the SIZEKMG. format. Only applicable to BASE engine libraries. TABLE_CNT num : The number of tables in the library.","title":"Columns"},{"location":"tables/mpe_datastatus_tabs/","text":"MPE_DATASTATUS_TABS \u00b6 The MPE_DATASTATUS_TABS table captures frequently changing SAS table attributes such as size (if filesystem based), modification date, and the number of observations. To trigger a scan, see the Refresh Data Catalog instructions . Columns \u00b6 TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) \ud83d\udd11 DSN char(64) : The library member name FILESIZE num : The size of the table (in bytes), displayed with the SIZEKMG. format. Only applicable to BASE engine libraries. CRDATE num : Creation date of the table MODATE num : Modification date of the table NOBS num : Number of Observations. Note - if the table is a SAS dataset then this includes deleted rows. To remove deleted rows from a SAS dataset, it must be re-created.","title":"MPE_DATASTATUS_TABS"},{"location":"tables/mpe_datastatus_tabs/#mpe_datastatus_tabs","text":"The MPE_DATASTATUS_TABS table captures frequently changing SAS table attributes such as size (if filesystem based), modification date, and the number of observations. To trigger a scan, see the Refresh Data Catalog instructions .","title":"MPE_DATASTATUS_TABS"},{"location":"tables/mpe_datastatus_tabs/#columns","text":"TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) \ud83d\udd11 DSN char(64) : The library member name FILESIZE num : The size of the table (in bytes), displayed with the SIZEKMG. format. Only applicable to BASE engine libraries. CRDATE num : Creation date of the table MODATE num : Modification date of the table NOBS num : Number of Observations. Note - if the table is a SAS dataset then this includes deleted rows. To remove deleted rows from a SAS dataset, it must be re-created.","title":"Columns"},{"location":"tables/mpe_lockanytable/","text":"MPE_LOCKANYTABLE \u00b6 The MPE_LOCKANYTABLE table provides a mechanism for a process to secure a logical 'lock' on an object to avoid conflicts when running the application with multiple users in parallel. The underlying utility is open source and documented here . For more information, see the locking mechanism guide . Columns \u00b6 \ud83d\udd11 LOCK_LIB char(8) : SAS Libref (8 chars) \ud83d\udd11 LOCK_DS char(32) : The dataset name LOCK_STATUS_CD char(10) : Either LOCKED or UNLOCKED LOCK_USER_NM char(100) : The logged-in user who performed the lock or unlock LOCK_REF char(200) : Description of the lock purpose LOCK_PID char(10) : The value of the automatic sysjobid macro variable LOCK_START_DTTM num : The timestamp when the record was LOCKED LOCK_END_DTTM num : The timestamp when the record was UNLOCKED. This is set to missing whilst the record is locked.","title":"MPE_LOCKANYTABLE"},{"location":"tables/mpe_lockanytable/#mpe_lockanytable","text":"The MPE_LOCKANYTABLE table provides a mechanism for a process to secure a logical 'lock' on an object to avoid conflicts when running the application with multiple users in parallel. The underlying utility is open source and documented here . For more information, see the locking mechanism guide .","title":"MPE_LOCKANYTABLE"},{"location":"tables/mpe_lockanytable/#columns","text":"\ud83d\udd11 LOCK_LIB char(8) : SAS Libref (8 chars) \ud83d\udd11 LOCK_DS char(32) : The dataset name LOCK_STATUS_CD char(10) : Either LOCKED or UNLOCKED LOCK_USER_NM char(100) : The logged-in user who performed the lock or unlock LOCK_REF char(200) : Description of the lock purpose LOCK_PID char(10) : The value of the automatic sysjobid macro variable LOCK_START_DTTM num : The timestamp when the record was LOCKED LOCK_END_DTTM num : The timestamp when the record was UNLOCKED. This is set to missing whilst the record is locked.","title":"Columns"},{"location":"tables/mpe_review/","text":"MPE_REVIEW \u00b6 The MPE_REVIEW table tracks Approval and Rejection events. This is useful for checking the history where tables require more than 1 approval. A user may only review a submit once (accept or reject). Columns \u00b6 \ud83d\udd11 TABLE_ID char(32) : A unique code for the submission, and corresponds to the folder in which the staged data resides. \ud83d\udd11 REVIEWED_BY_NM char(100) : User id that made the final approval / rejection BASE_TABLE char(41) NOT NULL : The LIBREF.MEMBER of the table being reviewed REVIEW_STATUS_CD char(10) NOT NULL : Either APPROVED or REJECTED. REVIEWED_ON_DTTM num NOT NULL : Timestamp of the approval / rejection REVIEW_REASON_TXT char(400) : Reason for rejection (for approvals, no reason is requested)","title":"MPE_REVIEW"},{"location":"tables/mpe_review/#mpe_review","text":"The MPE_REVIEW table tracks Approval and Rejection events. This is useful for checking the history where tables require more than 1 approval. A user may only review a submit once (accept or reject).","title":"MPE_REVIEW"},{"location":"tables/mpe_review/#columns","text":"\ud83d\udd11 TABLE_ID char(32) : A unique code for the submission, and corresponds to the folder in which the staged data resides. \ud83d\udd11 REVIEWED_BY_NM char(100) : User id that made the final approval / rejection BASE_TABLE char(41) NOT NULL : The LIBREF.MEMBER of the table being reviewed REVIEW_STATUS_CD char(10) NOT NULL : Either APPROVED or REJECTED. REVIEWED_ON_DTTM num NOT NULL : Timestamp of the approval / rejection REVIEW_REASON_TXT char(400) : Reason for rejection (for approvals, no reason is requested)","title":"Columns"},{"location":"tables/mpe_submit/","text":"MPE_SUBMIT \u00b6 The MPE_SUBMIT table tracks the status of submitted modifications - ie SUBMITTED, APPROVED, or REJECTED. It is unique on TABLE_ID. A record is created whenever a submit is submitted. Columns \u00b6 \ud83d\udd11 TABLE_ID char(32) : A unique code for the submission, and corresponds to the folder in which the staged data resides. SUBMIT_STATUS_CD char(10) : Either SUBMITTED, APPROVED, or REJECTED. Remains SUBMITTED until the final approval, or first rejection. BASE_LIB char(8) : The LIBREF of the table being updated BASE_DS char(32) : The name of the dataset (or format catalog) being updated SUBMITTED_BY_NM (100) : The username of the submitter SUBMITTED_ON_DTTM num : The timestamp of the submission SUBMITTED_REASON_TXT char(400) : The description provided by the submitter INPUT_OBS num : The number of observations staged INPUT_VARS num : The number of variables staged NUM_OF_APPROVALS_REQUIRED num : Taken from MPE_TABLES at the time of submission NUM_OF_APPROVALS_REMAINING num : Decreased by 1 with every approval, set to 0 on rejection. REVIEWED_BY_NM char(100) : User id that made the final approval / rejection REVIEWED_ON_DTTM num : Timestamp of the final approval / rejection","title":"MPE_SUBMIT"},{"location":"tables/mpe_submit/#mpe_submit","text":"The MPE_SUBMIT table tracks the status of submitted modifications - ie SUBMITTED, APPROVED, or REJECTED. It is unique on TABLE_ID. A record is created whenever a submit is submitted.","title":"MPE_SUBMIT"},{"location":"tables/mpe_submit/#columns","text":"\ud83d\udd11 TABLE_ID char(32) : A unique code for the submission, and corresponds to the folder in which the staged data resides. SUBMIT_STATUS_CD char(10) : Either SUBMITTED, APPROVED, or REJECTED. Remains SUBMITTED until the final approval, or first rejection. BASE_LIB char(8) : The LIBREF of the table being updated BASE_DS char(32) : The name of the dataset (or format catalog) being updated SUBMITTED_BY_NM (100) : The username of the submitter SUBMITTED_ON_DTTM num : The timestamp of the submission SUBMITTED_REASON_TXT char(400) : The description provided by the submitter INPUT_OBS num : The number of observations staged INPUT_VARS num : The number of variables staged NUM_OF_APPROVALS_REQUIRED num : Taken from MPE_TABLES at the time of submission NUM_OF_APPROVALS_REMAINING num : Decreased by 1 with every approval, set to 0 on rejection. REVIEWED_BY_NM char(100) : User id that made the final approval / rejection REVIEWED_ON_DTTM num : Timestamp of the final approval / rejection","title":"Columns"},{"location":"tables/mpe_tables/","text":"MPE_DATASTATUS_TABS \u00b6 The MPE_TABLES table defines the tables that are EDITABLE - along with attributes such as load type, number of approvals, and hook scripts. A more detailed breakdown of the columns / features is available in the configuration section. Columns \u00b6 TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) \ud83d\udd11 DSN char(64) : The library member name NUM_OF_APPROVALS_REQUIRED num : The number of approvals required (against staged data) before the base table is updated. LOADTYPE char(12) : The update method. See config BUSKEY char(1000) : The logical key. See config VAR_TXFROM char(32) : The SCD2 start column of the base table. See config VAR_TXTO char(32) : The SCD2 end column of the base table. See config VAR_BUSFROM char(32) : The bitemporal business start column of the base table. See config VAR_BUSTO char(32) : The bitemporal business end column of the base table. See config VAR_PROCESSED char(32) : A column to contain the batch load time. See config CLOSE_VARS char(500) : Close out unloaded records for a key section. See config PRE_EDIT_HOOK char(200) : Run SAS code before an EDIT. See config POST_EDIT_HOOK char(200) : Run SAS code after an EDIT. See config PRE_APPROVE_HOOK char(200) : Run SAS code before an APPROVE. See config POST_APPROVE_HOOK char(200) : Run SAS code after final approval (and dataload). See config SIGNOFF_COLS char(200) : For marking final approval. See config SIGNOFF_HOOK char(200) : Run SAS code after signoff. See config NOTES char(1000) : Additional notes. See config RK_UNDERLYING char(1000) : The key on which the retained key is generated. See config AUDIT_LIBDS char(41) : Configure alternative audit history tracking tables (or switch off audit history). See config","title":"MPE_TABLES"},{"location":"tables/mpe_tables/#mpe_datastatus_tabs","text":"The MPE_TABLES table defines the tables that are EDITABLE - along with attributes such as load type, number of approvals, and hook scripts. A more detailed breakdown of the columns / features is available in the configuration section.","title":"MPE_DATASTATUS_TABS"},{"location":"tables/mpe_tables/#columns","text":"TX_FROM num : SCD2 open datetime \ud83d\udd11 TX_TO num : SCD2 close datetime \ud83d\udd11 LIBREF char(8) : SAS Libref (8 chars) \ud83d\udd11 DSN char(64) : The library member name NUM_OF_APPROVALS_REQUIRED num : The number of approvals required (against staged data) before the base table is updated. LOADTYPE char(12) : The update method. See config BUSKEY char(1000) : The logical key. See config VAR_TXFROM char(32) : The SCD2 start column of the base table. See config VAR_TXTO char(32) : The SCD2 end column of the base table. See config VAR_BUSFROM char(32) : The bitemporal business start column of the base table. See config VAR_BUSTO char(32) : The bitemporal business end column of the base table. See config VAR_PROCESSED char(32) : A column to contain the batch load time. See config CLOSE_VARS char(500) : Close out unloaded records for a key section. See config PRE_EDIT_HOOK char(200) : Run SAS code before an EDIT. See config POST_EDIT_HOOK char(200) : Run SAS code after an EDIT. See config PRE_APPROVE_HOOK char(200) : Run SAS code before an APPROVE. See config POST_APPROVE_HOOK char(200) : Run SAS code after final approval (and dataload). See config SIGNOFF_COLS char(200) : For marking final approval. See config SIGNOFF_HOOK char(200) : Run SAS code after signoff. See config NOTES char(1000) : Additional notes. See config RK_UNDERLYING char(1000) : The key on which the retained key is generated. See config AUDIT_LIBDS char(41) : Configure alternative audit history tracking tables (or switch off audit history). See config","title":"Columns"}]}